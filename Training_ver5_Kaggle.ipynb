{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "RESNET MODULE 2016/2/7\n",
    "CONVOLUTION MODULE 2016/2/6\n",
    "batch_normalization 적용\n",
    "3/14일 model save and restore 적용\n",
    "n_train=300 이 코드 수정하기 \n",
    "def Batch_random 에 valideation and test validate 하는 함수에 오류를 일부로 구현-->나중에 고치기 \n",
    "\n",
    "수정사항\n",
    "\n",
    "def divide_images(images , labels,batch_size):\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    image = images[ -batch_size :  ] \n",
    "    label = labels[ -batch_size :  ]\n",
    "    list_images.append(image)\n",
    "    list_labels.append(label)\n",
    "\n",
    "    return list_images,list_labels\n",
    "    2017_4/7 ver 3로 바꿈\n",
    "\n",
    "\n",
    "\n",
    "수정사항 \n",
    "tf.cond을 만들어서 처리한다.\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images_cls(path_img_list , label_num ):\n",
    "    n_paths = len(path_img_list)\n",
    "    cls=np.zeros([n_paths])\n",
    "    cls=np.full_like(cls, label_num)\n",
    "    list_imgs=[]\n",
    "    for i , path in  enumerate(path_img_list):\n",
    "        msg = \"\\r progress {0} /{1}\".format(str(i),n_paths)\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        img=np.load(path)\n",
    "        list_imgs.append(img)\n",
    "    images=np.asarray(list_imgs)\n",
    "\n",
    "    return images , cls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Using multiProc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img=np.load(path)\n",
    "    return img\n",
    "def load_images_cls_multiproc(path_img_list , label_num ):\n",
    "    n_paths = len(path_img_list)\n",
    "    cls=np.zeros([n_paths])\n",
    "    cls=np.full_like(cls, label_num)\n",
    "    list_imgs=[]\n",
    "    pool=Pool()\n",
    "    count=0\n",
    "    for img in  pool.imap( load_img,path_img_list):\n",
    "        msg = \"\\r progress {0} /{1}\".format(str(count),n_paths)\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "        list_imgs.append(img)\n",
    "        count+=1\n",
    "    images=np.asarray(list_imgs)\n",
    "\n",
    "    return images , cls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Training , Validation , Test "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#cifar_data_format\n",
    "file_locate='/home/user01/notebook/KimLABs/cifar_dataset/npy/'\n",
    "ori_img_row = 32\n",
    "ori_img_col = 32\n",
    "in_ch =3\n",
    "n_classes=10\n",
    "img_size_cropped=28\n",
    "batch_size=60\n",
    "#for cifar_dataset\n",
    "start=time.time()\n",
    "train_imgs_list,train_labs_list=load_train_all()\n",
    "print time.time()-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_=[1,2,3]\n",
    "list_2=[3,4,5]\n",
    "type(list_) is list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_locate ='/ssd/n_vs_ab/type1/1/' #Folder data saved#WB_eye_15_PRE_A_B_C_incepAx3/\n",
    "ori_img_row = 224\n",
    "ori_img_col = 224\n",
    "in_ch =3\n",
    "n_classes=3\n",
    "img_size_cropped=214\n",
    "batch_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def crawl_folder(folder_path): #search_str 찾고자 하는 string \n",
    "    search_path_list=[]\n",
    "    fileList = os.walk(folder_path).next()[2]\n",
    "    subFolder_list = os.walk(folder_path).next()[1]\n",
    "    if(len(fileList)!=0):\n",
    "        for j in range(len(fileList)):\n",
    "            search_path_list.append(folder_path+'/'+fileList[j])\n",
    "    if len(subFolder_list)==0:\n",
    "        return search_path_list\n",
    "    else: \n",
    "        for i in range(len(subFolder_list)):\n",
    "            search_path_list.extend(crawl_folder(folder_path+'/'+subFolder_list[i] ))\n",
    "        return search_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_1_paths=crawl_folder('/ssd/cervical/GMM_224x224/train/Type_1//')\n",
    "train_2_paths=crawl_folder('/ssd/cervical/GMM_224x224/train/Type_2//')\n",
    "train_3_paths=crawl_folder('/ssd/cervical/GMM_224x224/train/Type_3//')\n",
    "add_1_paths=crawl_folder('/ssd/cervical/GMM_224x224/additional/Type_1//')\n",
    "add_2_paths=crawl_folder('/ssd/cervical/GMM_224x224/additional/Type_2//')\n",
    "add_3_paths=crawl_folder('/ssd/cervical/GMM_224x224/additional/Type_3//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1187\n",
      "3563\n",
      "1975\n",
      "248\n",
      "780\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "print len(add_1_paths)\n",
    "print len(add_2_paths)\n",
    "print len(add_3_paths)\n",
    "print len(train_1_paths)\n",
    "print len(train_2_paths)\n",
    "print len(train_3_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_type1_paths=[]\n",
    "training_type2_paths=[]\n",
    "training_type3_paths=[]\n",
    "test_type1_paths=[]\n",
    "test_type2_paths=[]\n",
    "test_type3_paths=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_type1_paths.extend(add_1_paths);training_type1_paths.extend(train_1_paths)\n",
    "training_type2_paths.extend(add_2_paths);training_type2_paths.extend(train_2_paths)\n",
    "training_type3_paths.extend(add_3_paths);training_type3_paths.extend(train_3_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_type1_paths=training_type1_paths[-100:]\n",
    "training_type1_paths=training_type1_paths[:-100]\n",
    "test_type2_paths=training_type2_paths[-100:]\n",
    "training_type2_paths=training_type2_paths[:-100]\n",
    "test_type3_paths=training_type3_paths[-100:]\n",
    "training_type3_paths=training_type3_paths[:-100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " progress 2324 /2325"
     ]
    }
   ],
   "source": [
    "train_type_1 , cls_type_1 = load_images_cls(training_type1_paths , 0)\n",
    "train_type_2 , cls_type_2 = load_images_cls(training_type2_paths , 1)\n",
    "train_type_3 , cls_type_3 = load_images_cls(training_type3_paths , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cls2onehot(n_classes,list_cls):\n",
    "    tmp_list=[]\n",
    "    size=len(list_cls)\n",
    "    ret_onehot=np.zeros([size,n_classes])\n",
    "    for i , cls in enumerate(list_cls):\n",
    "        cls=int(cls)\n",
    "        ret_onehot[i,cls]=1\n",
    "    return ret_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " progress 2324 /2325"
     ]
    }
   ],
   "source": [
    "test_type_1 , test_cls_type_1 = load_images_cls(training_type1_paths , 0)\n",
    "test_type_2 , test_cls_type_2 = load_images_cls(training_type2_paths , 1)\n",
    "test_type_3 , test_cls_type_3 = load_images_cls(training_type3_paths , 2)\n",
    "test_type_1_lab=cls2onehot(n_classes, test_cls_type_1)\n",
    "test_type_2_lab=cls2onehot(n_classes, test_cls_type_2)\n",
    "test_type_3_lab=cls2onehot(n_classes, test_cls_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lab_type_1=cls2onehot(n_classes, cls_type_1)\n",
    "lab_type_2=cls2onehot(n_classes, cls_type_2)\n",
    "lab_type_3=cls2onehot(n_classes, cls_type_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_type_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Variable , and placeholder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_= tf.placeholder(\"float\",shape=[batch_size,ori_img_row , ori_img_col , in_ch],  name = 'x-input')\n",
    "y_= tf.placeholder(\"float\",shape=[batch_size , n_classes] , name = 'y-input')\n",
    "y_cls = tf.argmax(y_ , axis = 1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "#x_image= tf.reshape(x_,[-1,ori_img_row,ori_img_col,in_ch])\n",
    "phase_train= tf.placeholder(tf.bool , name='phase_train')\n",
    "bn_flag = tf.placeholder(tf.bool , name='bn_flag')\n",
    "bn_decay = tf.placeholder(\"float\")\n",
    "\n",
    "place_info={}\n",
    "place_info['x_']=x_\n",
    "place_info['y_']=y_\n",
    "place_info['keep_prob']=keep_prob\n",
    "place_info['phase_train']=phase_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image ProPrecessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function takes a single image as input,\n",
    "# and a boolean whether to build the training or testing graph.\n",
    "def pre_processing(image ):\n",
    "    def training(image):\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, in_ch])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        #image = tf.minimum(image, 1.0)\n",
    "        #image = tf.maximum(image, 0.0)\n",
    "        return image\n",
    "    def testing(image):\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,target_height=img_size_cropped,target_width=img_size_cropped)\n",
    "        return image\n",
    "    image=tf.cond( phase_train , lambda : training(image) \\\n",
    "                  , lambda : testing(image) ,name='pre_processing')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(images, training):\n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PRE_PROCESSING(images, phase_train ,img_size_cropped  , device):\n",
    "    print \n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn( lambda image: pre_process_image(image, phase_train ,img_size_cropped  , device), images)\n",
    "    print 'distorted image\\'s shape is' , images.get_shape()\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "def bias_variable(shape , name):\n",
    "    initial = tf.constant(0.1 , shape=shape , )\n",
    "    return tf.Variable(initial , name=name)\n",
    "\n",
    "def conv2d(x,w,strides_ , name):\n",
    "    return tf.nn.conv2d(x,w, strides = strides_, padding='SAME' , name = name)\n",
    "\n",
    "def max_pool(x , ksize , strides , padding , name ):\n",
    "    return tf.nn.max_pool(x ,ksize , strides , padding ,name=name)\n",
    "def make_weights_biases(layer_name\n",
    "                        , w_name , b_name, ksize ,device_name , initializer='xavier',\\\n",
    "                        restore_flag =False , restore_path = './WB_save'):    \n",
    "    \"\"\"\n",
    "    Doc\n",
    "    the folder include weights and bises that will be restored is located in './WB_save'\n",
    "    if you want to change save path ,  change restore_path  \n",
    "    \"\"\"\n",
    "    if len(ksize)==4: # convolution filter shape [batch , row , col , color_ch]\n",
    "        out_ch=ksize[3]\n",
    "    elif len(ksize)==2: #fully connected layer shape [in_ch , output_ch]\n",
    "        out_ch=ksize[1]\n",
    "    with tf.device(device_name):\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            if restore_flag==False:\n",
    "                print layer_name+' make weigths and biases'\n",
    "\n",
    "                try:\n",
    "                    w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "                except:\n",
    "                    scope.reuse_variables()\n",
    "                    w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())        \n",
    "                try:\n",
    "                    b_conv = bias_variable([out_ch] , name=b_name)\n",
    "                except:\n",
    "                    scope.reuse_variables()\n",
    "                    b_conv = bias_variable([out_ch],name=b_name)\n",
    "                return w_conv , b_conv\n",
    "            elif restore_flag == True:\n",
    "                print layer_name+' load weigths and biases'\n",
    "                try:\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1:0\n",
    "                        if layer_name+'_'+w_name == name:\n",
    "                            print layer_name+'_'+w_name+'was restored!!'\n",
    "                            w_conv = tf.Variable(np.load(path) , name = w_name)\n",
    "                except:\n",
    "                    scope.reuse_variables()\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1\n",
    "                        if layer_name+'_'+w_name == name:\n",
    "                            print layer_name+'_'+w_name+'was restored'\n",
    "                            w_conv = tf.Variable(np.load(path) , name = w_name)         \n",
    "                try:\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1\n",
    "                        if layer_name+'_'+b_name == name:\n",
    "                            print layer_name+'_'+b_name+'was restored!!'\n",
    "                            b_conv = tf.Variable(np.load(path),name = b_name)        \n",
    "                except:\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1\n",
    "                        if layer_name+'_'+b_name == name:\n",
    "                            print layer_name+'_'+b_name+'was restored'                            \n",
    "                            b_conv = tf.Variable(np.load(path),name = b_name)        \n",
    "                return w_conv , b_conv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_conv_info( x,w_conv,b_conv,c_strides,c_pooling ):\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['name']=name\n",
    "    conv_info['b_conv']=b_conv\n",
    "    \n",
    "    \"\"\"\n",
    "    conv_info={}\n",
    "    \n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['b_conv']=b_conv\n",
    "    \n",
    "    return conv_info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def batch_norm(x, bn_decay , train_flag):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        train_flag: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    \n",
    "    n_out = x.get_shape()[3] \n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                 name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                  name='gamma', trainable=True)\n",
    "    batch_mean, batch+\n",
    "    -3_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(bn_decay , name=\"EMA\")\n",
    "\n",
    "    def mean_var_with_update():\n",
    "        ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "    mean, var = tf.cond(train_flag,\n",
    "                        mean_var_with_update,\n",
    "                        lambda: (ema.average(batch_mean), ema.average(batch_var)) , name = 'bn_cond')\n",
    "    normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3 , name = 'batch_norm')\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bn(layer  , layer_name  ,  decay , restore_flag=False , restore_path ='./WB_save/' ):\n",
    "    #hyper parameter : decay \n",
    "    #\n",
    "    n_out = layer.get_shape()[3] \n",
    "    if restore_flag == False:\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "    elif restore_flag == True:\n",
    "        beta = tf.Variable(np.load(restore_path+layer_name+'_beta.npy') , name='beta')\n",
    "        gamma = tf.Variable(np.load(restore_path+layer_name+'_gamma.npy') , name ='gamma')\n",
    "        print layer_name+'beta was restored'\n",
    "        print layer_name+'gamma was restored'\n",
    "        \n",
    "    batch_mean, batch_var = tf.nn.moments(layer, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage( decay , name=\"EMA\")\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean=ema.average(batch_mean) ;ema_var=ema.average(batch_var) \n",
    "    layer_BN = tf.nn.batch_normalization(layer, batch_mean, batch_var, beta, gamma, 1e-3 , name = 'BN')    \n",
    "    layer_relu=tf.nn.relu(layer_BN ,name='bn_relu')\n",
    "    return layer_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convolution(conv_info , place_info , bn_flag , layer_name , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    place_info['x_']=x_\n",
    "    place_info['y_']=y_\n",
    "    place_info['keep_prob']=keep_prob\n",
    "    place_info['train_flag'] =train_flag\n",
    "    place_info['bn_flag'] =bn_flag\n",
    "    place_info['bn_decay'] = bn_decay\n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['name']=name\n",
    "    conv_info['b_conv']=b_conv    \n",
    "    \"\"\"\n",
    "    with tf.variable_scope(layer_name) as scope:\n",
    "        layer = tf.nn.conv2d(conv_info['x'] , conv_info['w_conv'] , conv_info['c_strides'] ,\\\n",
    "                             conv_info['c_pooling'] ,name='conv')+conv_info['b_conv']\n",
    "        if bn_flag==True:\n",
    "            layer_relu=bn(layer , layer_name , 0.999 , restore_flag , restore_path)\n",
    "        if bn_flag==False:\n",
    "            layer_relu=tf.nn.relu(layer ,name='no_bn_relu')\n",
    "        layer_drop = tf.nn.dropout(layer_relu,place_info['keep_prob'] , name='dropout')\n",
    "        return layer_drop        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PRE_LAYER(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    place_info['x_']=x_\n",
    "    place_info['y_']=y_\n",
    "    place_info['keep_prob']=keep_prob\n",
    "    place_info['train_flag'] =train_flag\n",
    "    place_info['bn_flag'] = train_flag\n",
    "    place_info['bn_decay'] = bn_decay\n",
    "    conv\n",
    "    \"\"\"\n",
    "    in_ch = x.get_shape()[3]\n",
    "    out_ch=n_nodes\n",
    "    c_ksize=[7,7 , in_ch, out_ch]\n",
    "    c_pooling ='SAME'\n",
    "    c_strides=[1,2,2,1] # when downsampling featrue map , set strides parameter,[1,2,2,1]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W' ,'B' , c_ksize ,device_ ,'xavier',restore_flag ,  restore_path )\n",
    "    conv_info=make_conv_info(x, w_conv, b_conv, c_strides, c_pooling)\n",
    "    layer1=convolution(conv_info , place_info , bn_flag , layer_name+'_L' , restore_flag , restore_path)   \n",
    "    p_ksize=[1,3,3,1]\n",
    "    p_strides=[1,2,2,1]\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer2 = tf.nn.max_pool(layer1 ,p_ksize, c_strides , c_pooling , name='maxpool')\n",
    "    print layer2.get_shape()\n",
    "    return layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RES_2(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    out_ch1 , out_ch2 = n_nodes\n",
    "    out_ch1 , out_ch2=n_nodes\n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['name']=name\n",
    "    conv_info['b_conv']=b_conv\n",
    "    문제는 형이 변할때인데 이미지가 축소할때 기본의  x는 이미지를 살려서 패치를 해야 한다,\n",
    "    그것을 텐서 플로어를 이용해서 해야 한다는 것이다.    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"만약 입력한 영상의 row와 또는 col이 layer2의 row 또는 col과 다르다면 padding 을 시켜야 한다.\n",
    "    넘어갈때는 폴링을 시키는것이 아니라 1x1 conv 에 1,2,2,1 스트라이드를 시키는지는 정확히 모르겠다\n",
    "    또 논문에 보면 차원이 늘어날때 extra padding 이라고 하는데 단순히 zeropadding을 뒤에 붙이는건지는\n",
    "    잘 모르겠다. 어짜피 뒤에 있는 레이어와 더해져 문제 될것 같지는 않은데 잘 모르겠다.\n",
    "    \"\"\"\n",
    "\n",
    "    #pad_row=int((x.get_shape()[1]-layer2.get_shape()[1])/2)\n",
    "    #pad_col=int((x.get_shape()[2]-layer2.get_shape()[2])/2)\n",
    "\n",
    "    \"\"\"add padding \n",
    "    아직 구현 미완료\n",
    "    x_padded=tf.pad(x,paddings=[[pad_col,pad_col],[pad_row,pad_row]],mode=\"CONSTANT\",name=layer_name+'x_padded')\n",
    "    x_padded=tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1],padding='SAME' , name=layer_name+'x_padded')\n",
    "    x_ch=int(x_padded.get_shape()[3])\n",
    "    print x_padded.get_shape()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #여기에 batch  가 들어가야 한다.\n",
    "\n",
    "    \"\"\"\n",
    "    여기에만 Batch Normalization 을 추가하는 게 좋을까 \n",
    "    아니면 다른곳에도 batch normalization 을 추가하는게 좋을까?\n",
    "    그리고 이것을 어떻게 수식으로 표현할수 있을까?\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    in_ch = x.get_shape()[3]\n",
    "\n",
    "    out_ch1,out_ch2=n_nodes\n",
    "    out_ch_shortcut = out_ch2\n",
    "    \n",
    "    c_ksize1=[3,3 , in_ch   , out_ch1]\n",
    "    c_ksize2=[3,3 , out_ch1 , out_ch2]\n",
    "    c_ksize_shortcut = [1,1,in_ch,out_ch2]\n",
    "    \n",
    "    c_strides1=strides # when downsampling featrue map , set strides parameter,[1,2,2,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    c_strides_shortcut=strides\n",
    "    \n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='SAME'\n",
    "    c_pooling_shortcut=\"SAME\"\n",
    "    \n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+'_1', 'W' ,'B' ,c_ksize1 ,device_ ,'xavier',restore_flag , restore_path )\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+'_2', 'W' ,'B' , c_ksize2 ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    w_conv_shortcut , b_conv_shortcut =make_weights_biases(layer_name+'shortcut', 'W' ,'B' , c_ksize_shortcut ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)    \n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag ,layer_name+'_L1' , restore_flag , restore_path)   \n",
    "\n",
    "    conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info_2 , place_info , bn_flag, layer_name+'_L2' , restore_flag , restore_path)\n",
    "\n",
    "    conv_info_shortcut = make_conv_info(x, w_conv_shortcut, b_conv_shortcut, c_strides_shortcut, c_pooling_shortcut)\n",
    "    layer_shortcut=convolution(conv_info_shortcut , place_info , bn_flag , layer_name+'Lshortcut' , restore_flag , restore_path)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_sum=tf.add(layer2 ,layer_shortcut , name=\"add\")    \n",
    "        layer_sum_relu=tf.nn.relu(layer_sum , name=layer_name+\"relu\")    \n",
    "    print layer_sum_relu.get_shape()\n",
    "\n",
    "    return layer_sum_relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BOTTLENECT(x , device_,layer_name,n_nodes , strides , bn_flag , restore_flag  , restore_path ):\n",
    "    \"\"\"\n",
    "    usage:\n",
    "    n_nodes=(n_nodes[0],n_nodes[1],n_nodes[2])\n",
    "    out_ch1 , out_ch2 , out_ch3 = n_nodes\n",
    "    \"\"\"\n",
    "    \"\"\"만약 입력한 영상의 row와 또는 col이 layer2의 row 또는 col과 다르다면 padding 을 시켜야 한다.\n",
    "    넘어갈때는 폴링을 시키는것이 아니라 1x1 conv 에 1,2,2,1 스트라이드를 시키는지는 정확히 모르겠다\n",
    "    또 논문에 보면 차원이 늘어날때 extra padding 이라고 하는데 단순히 zeropadding을 뒤에 붙이는건지는\n",
    "    잘 모르겠다. 어짜피 뒤에 있는 레이어와 더해져 문제 될것 같지는 않은데 잘 모르겠다.\n",
    "    \"\"\"\n",
    "\n",
    "    #pad_row=int((x.get_shape()[1]-layer2.get_shape()[1])/2)\n",
    "    #pad_col=int((x.get_shape()[2]-layer2.get_shape()[2])/2)\n",
    "\n",
    "    \"\"\"add padding \n",
    "    아직 구현 미완료\n",
    "    x_padded=tf.pad(x,paddings=[[pad_col,pad_col],[pad_row,pad_row]],mode=\"CONSTANT\",name=layer_name+'x_padded')\n",
    "    x_padded=tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1],padding='SAME' , name=layer_name+'x_padded')\n",
    "    x_ch=int(x_padded.get_shape()[3])\n",
    "    print x_padded.get_shape()\n",
    "\n",
    "    \"\"\"\n",
    "    ############################# layer4 #############################\n",
    "\n",
    "    #여기에 batch  가 들어가야 한다.\n",
    "\n",
    "    \"\"\"\n",
    "    여기에만 Batch Normalization 을 추가하는 게 좋을까 \n",
    "    아니면 다른곳에도 batch normalization 을 추가하는게 좋을까?\n",
    "    그리고 이것을 어떻게 수식으로 표현할수 있을까?\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #############################layer1#############################\n",
    "    in_ch = x.get_shape()[3]\n",
    "    \n",
    "    out_ch1,out_ch2,out_ch3=n_nodes\n",
    "    c_ksize1=[1,1 , in_ch   , out_ch1]\n",
    "    c_ksize2=[3,3 , out_ch1 , out_ch2]\n",
    "    c_ksize3=[1,1 , out_ch2 , out_ch3]\n",
    "    c_ksize_shortcut=[1,1,in_ch,out_ch3]\n",
    "    \n",
    "    c_pooling1=\"SAME\";c_strides1=strides;\n",
    "    c_pooling2=\"SAME\";c_strides2=[1,1,1,1];\n",
    "    c_pooling3=\"SAME\";c_strides3=[1,1,1,1];\n",
    "    c_pooling_shortcut=\"SAME\";c_strides_shortcut=strides;\n",
    "    \n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+'_1', 'W' ,'B' ,c_ksize1 ,device_ ,'xavier',restore_flag , restore_path  )\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+'_2', 'W' ,'B' ,c_ksize2 ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+'_3', 'W' ,'B' ,c_ksize3 ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    w_conv_shortcut , b_conv_shortcut =make_weights_biases(layer_name+'_shortcut', 'W' ,'B' ,c_ksize_shortcut,device_,'xavier',restore_flag,restore_path)\n",
    "    \n",
    "    \n",
    "    conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1) \n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info_2, place_info , bn_flag , layer_name+'_L2',restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_3=make_conv_info(layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "    layer3=convolution(conv_info_3, place_info , bn_flag , layer_name+'_L3',restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_shortcut = make_conv_info(x, w_conv_shortcut, b_conv_shortcut, c_strides_shortcut, c_pooling_shortcut)\n",
    "    layer_shortcut=convolution(conv_info_shortcut , place_info , bn_flag , layer_name+'_Lshortcut',restore_flag , restore_path)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope: \n",
    "        layer_sum=tf.add(layer3 ,layer_shortcut , name=\"sum\")\n",
    "    print layer_sum.get_shape()\n",
    "    return layer_sum\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTION_NET_V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_A(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\" \n",
    "        standard = 32;32;64;96\n",
    "        out_ch1 , out_ch2 , out_ch3 , out_ch4 =n_nodes   \n",
    "        out_ch1=n_nodes[0]\n",
    "        c_ksize1=[1,1 , in_ch   , out_ch1]\n",
    "        c_strides1=strides;c_pooling1=\"SAME\"\n",
    "        w_conv1 , b_conv1 =make_weights_biases\\\n",
    "        (layer_name+'_1', 'W' ,'B' ,c_ksize1 ,device_ ,'xavier',restore_flag , restore_path  )\n",
    "        conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "        layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_1_bn' ,restore_flag , restore_path)\n",
    "\n",
    "    \"\"\"    \n",
    "    with tf.device(device_):\n",
    "        out_ch1=32;out_ch2=32;out_ch3=64;out_ch4 =96\n",
    "        in_ch=x.get_shape()[3]\n",
    "        \n",
    "        ################################## layer 1 ##################################  \n",
    "        c_ksize1=[3,3,in_ch , out_ch1]\n",
    "        c_strides1=[1,2,2,1]\n",
    "        c_pooling1='VALID'\n",
    "        w_conv1 , b_conv1 =make_weights_biases(layer_name+'_1' , 'W' ,'B', c_ksize1 , device_,'xavier',restore_flag,  restore_path)\n",
    "        conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "        layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)        \n",
    "        ################################## layer 2 ##################################  \n",
    "        c_ksize2=[3,3,out_ch1,out_ch2]\n",
    "        w_conv2 , b_conv2= make_weights_biases(layer_name+'_2' , 'W' ,'B', c_ksize2 , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides2=[1,1,1,1];c_pooling2='VALID'\n",
    "        conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "        layer2=convolution(conv_info_2 , place_info , bn_flag , layer_name+'_L2' ,restore_flag , restore_path)\n",
    "        ################################## layer 3 ##################################  \n",
    "        c_ksize3=[3,3,out_ch2 , out_ch3]\n",
    "        w_conv3 , b_conv3= make_weights_biases(layer_name+'_3' , 'W' ,'B' ,c_ksize3 , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_pooling3='SAME'\n",
    "        conv_info_3=make_conv_info(layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "        layer3=convolution(conv_info_3 , place_info , bn_flag , layer_name+'_L3' ,restore_flag , restore_path)\n",
    "        ################################## layer 4 ##################################  \n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv4 , b_conv4= make_weights_biases(layer_name+'_4' , 'W' ,'B', c_ksize4 , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides4=[1,2,2,1]\n",
    "        c_pooling4='VALID'\n",
    "        conv_info_4=make_conv_info(layer3, w_conv4, b_conv4, c_strides4, c_pooling4)\n",
    "        layer4=convolution(conv_info_4 , place_info , bn_flag , layer_name+'_L4' ,restore_flag , restore_path)\n",
    "        ################################## layer 4 brach ##################################          \n",
    "        b_p_ksize4=[1,3,3,1]\n",
    "        b_p_strides4=[1,2,2,1]\n",
    "        b_p_padding4 ='VALID'\n",
    "        with tf.variable_scope('b_'+layer_name+'_4') as scope:\n",
    "            b_layer4=tf.nn.max_pool(layer3 , b_p_ksize4, b_p_strides4, b_p_padding4 ,name='max_pool') #b is branch\n",
    "            b_layer4_relu=tf.nn.relu(b_layer4 , name = 'relu')\n",
    "        with tf.variable_scope(layer_name+'_end') as scope:\n",
    "            concat_layer=tf.concat(3 , [layer4 , b_layer4_relu] , name='CONCAT')\n",
    "        return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_B(x,device_,layer_name , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    stardard =>64,64,64,96 \n",
    "    b_out_ch1,b_out_ch2=64, 96\n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #################################################################################\n",
    "        out_ch1=64;out_ch2=64;out_ch3=64;out_ch4=96; \n",
    "        ##############################right side layer 1##################################\n",
    "        c_ksize1=[1,1,in_ch,out_ch1]\n",
    "        w_conv1 , b_conv1=make_weights_biases(layer_name+'_1' , 'W' ,'B', c_ksize1 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides1=[1,1,1,1]\n",
    "        c_pooling1='SAME'\n",
    "        conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "        layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)\n",
    "        ##############################right side layer 2##################################\n",
    "        c_ksize2=[7,1,out_ch1 , out_ch2]\n",
    "        w_conv2 , b_conv2= make_weights_biases(layer_name+'_2' , 'W' ,'B',c_ksize2 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_pooling2='SAME'\n",
    "        conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "        layer2=convolution(conv_info_2 , place_info , bn_flag , layer_name+'_L2' ,restore_flag , restore_path)\n",
    "        ##############################right side layer 3##################+################\n",
    "        c_ksize3=[1,7,out_ch2 , out_ch3]\n",
    "        w_conv3 , b_conv3= make_weights_biases(layer_name+'_3' , 'W' ,'B',c_ksize3 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_pooling3='SAME'\n",
    "        conv_info_3=make_conv_info(layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "        layer3=convolution(conv_info_3 , place_info , bn_flag , layer_name+'_L3' ,restore_flag , restore_path)\n",
    "        ##############################right side layer 4##################################\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv4 , b_conv4= make_weights_biases(layer_name+'_4' , 'W' ,'B', c_ksize4 , device_ ,'xavier',restore_flag,restore_path)\n",
    "        c_strides4=[1,1,1,1]\n",
    "        c_pooling4='VALID'\n",
    "        conv_info_4=make_conv_info(layer3, w_conv4, b_conv4, c_strides4, c_pooling4)\n",
    "        layer4=convolution(conv_info_4 , place_info , bn_flag , layer_name+'_L4' ,restore_flag , restore_path)\n",
    "        ##############################left side##################################\n",
    "        b_out_ch1=64;b_out_ch2=96\n",
    "        ##############################layer_1_branch####################################\n",
    "        \n",
    "        b_c_ksize1=[1,1,in_ch , b_out_ch1]\n",
    "        b_w_conv1 , b_b_conv1 =make_weights_biases('b_'+layer_name+'_1', 'W' , 'B', b_c_ksize1 ,device_,'xavier',restore_flag,restore_path)\n",
    "        b_c_strides1=[1,1,1,1]\n",
    "        b_c_pooling1='SAME'\n",
    "        b_conv_info1=make_conv_info(x, b_w_conv1, b_b_conv1, b_c_strides1, b_c_pooling1)\n",
    "        b_layer_1=convolution(b_conv_info1 , place_info , bn_flag , 'b_'+layer_name+'_L1' ,restore_flag , restore_path)\n",
    "        ##############################layer_2_branch####################################'b_'+\n",
    "        \n",
    "        b_c_ksize2=[3,3,b_out_ch1 , b_out_ch2]\n",
    "        b_w_conv2 , b_b_conv2= make_weights_biases('b_'+layer_name+'_2' , 'W' , 'B',b_c_ksize2 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        b_c_strides2=[1,1,1,1]\n",
    "        b_c_pooling2='VALID'\n",
    "        b_conv_info_2=make_conv_info(b_layer_1, b_w_conv2, b_b_conv2, b_c_strides2, b_c_pooling2)\n",
    "        b_layer_2=convolution(b_conv_info_2 , place_info , bn_flag , 'b_'+layer_name+'_L2' ,restore_flag , restore_path)        \n",
    "        ##############################concatenate layers###########################\n",
    "        with tf.variable_scope(layer_name+'end') as scope:\n",
    "            concat_layer=tf.concat(3 , [layer4 , b_layer_2] , name=\"CONCAT\")\n",
    "    return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_C( x , device_,layer_name , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    out_ch = n_nodes\n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #########################################################################\n",
    "        out_ch = 192\n",
    "        c_ksize=[3,3,in_ch,out_ch]\n",
    "        w_conv_1 , b_conv_1 =make_weights_biases(layer_name+'_1' , 'W' , 'B',c_ksize , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides=[1,1,1,1]\n",
    "        c_pooling='SAME'\n",
    "        conv_info=make_conv_info(x,w_conv_1 , b_conv_1, c_strides, c_pooling)\n",
    "        layer=convolution(conv_info , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)\n",
    "\n",
    "        #########################################################################\n",
    "        \n",
    "        b_p_ksize=[1,2,2,1]\n",
    "        b_p_strides=[1,1,1,1]\n",
    "        b_p_pooling='SAME'\n",
    "        with tf.variable_scope(layer_name+'_L2') as scope:\n",
    "            b_layer = tf.nn.max_pool(layer , b_p_ksize , b_p_strides , b_p_pooling,name='max_pool' )\n",
    "            b_layer_relu = tf.nn.relu(b_layer,name='relu')\n",
    "        #########################################################################\n",
    "        with tf.variable_scope(layer_name+'end') as scope:        \n",
    "            concat_layer=tf.concat(3,[layer , b_layer_relu] , name = 'concat')\n",
    "    return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_A(x , device_,layer_name, place_info  , bn_flag  , restore_flag , restore_path):\n",
    "\n",
    "    \"\"\"\n",
    "    out_ch1,out_ch2=n_nodes\n",
    "    input X shape is [n_batch , row , col, out_ch]\n",
    "    35 x 35 grid\n",
    "    \"\"\"\n",
    "    #######################################layer1##########################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1=64 ;c_strides1=[1,1,1,1];c_ksize1=[1,1,in_ch,out_ch1];c_pooling1='SAME'\n",
    "    out_ch2=96 ;c_strides2=[1,1,1,1];c_ksize2=[3,3,out_ch1,out_ch2];c_pooling2='SAME'\n",
    "             \n",
    "    w_conv1 , b_conv1 = make_weights_biases(layer_name+'_1', 'W', 'B',c_ksize1,device_,'xavier',restore_flag,restore_path)\n",
    "    w_conv2 , b_conv2 = make_weights_biases(layer_name+'_2' ,'W' ,'B',c_ksize2,device_,'xavier',restore_flag,restore_path)\n",
    "    \n",
    "    conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1',restore_flag , restore_path)\n",
    "    conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info_2 , place_info , bn_flag , layer_name+'_L2',restore_flag , restore_path)\n",
    "    ####################################layer_1_branch#############################################                     \n",
    "\n",
    "    b1_p_ksize=[1,2,2,1];b1_p_strides=[1,1,1,1];b1_p_pooling='SAME'\n",
    "    with tf.variable_scope('b1_'+layer_name+'_1') as scope:\n",
    "        b1_layer1      =tf.nn.avg_pool(x, b1_p_ksize , b1_p_strides,b1_p_pooling ,name='avg_pool')\n",
    "        b1_layer1_relu =tf.nn.relu(b1_layer1,name='relu')\n",
    "    b1_out_ch=96\n",
    "    b1_c_ksize=[1,1, in_ch , b1_out_ch]\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling ='SAME'\n",
    "    b1_w_conv,b1_b_conv=make_weights_biases('b1_'+layer_name,'W','B',b1_c_ksize , device_ ,'xavier',restore_flag,  restore_path)                \n",
    "    b1_conv_info=make_conv_info(b1_layer1_relu,b1_w_conv,b1_b_conv,b1_c_strides, b1_c_pooling)\n",
    "    b1_layer=convolution(b1_conv_info , place_info , bn_flag , 'b1_'+layer_name+'_L' ,restore_flag,  restore_path)\n",
    "\n",
    "    ####################################layer_2_branch#############################################                     \n",
    "\n",
    "    b2_out_ch=96;b2_c_ksize=[1,1,in_ch,b2_out_ch];b2_c_strides=[1,1,1,1];b2_c_pooling='SAME'\n",
    "    b2_w_conv , b2_b_conv=make_weights_biases('b2_'+layer_name,'W','B',b2_c_ksize , device_ ,'xavier',restore_flag, restore_path)\n",
    "    b2_conv_info=make_conv_info(x, b2_w_conv, b2_b_conv, b2_c_strides, b2_c_pooling)\n",
    "    b2_layer=convolution(b2_conv_info , place_info , bn_flag , 'b2_'+layer_name+'_L',restore_flag,  restore_path)\n",
    "    ####################################layer_3_branch#############################################                     \n",
    "\n",
    "    b3_out_ch1=64;b3_c_ksize1 =[1,1,     in_ch , b3_out_ch1];b3_c_strides1=[1,1,1,1];b3_c_pooling1='SAME'\n",
    "    b3_out_ch2=96;b3_c_ksize2 =[3,3,b3_out_ch1 , b3_out_ch2];b3_c_strides2=[1,1,1,1];b3_c_pooling2='SAME'\n",
    "    b3_out_ch3=96;b3_c_ksize3 =[3,3,b3_out_ch2 , b3_out_ch3];b3_c_strides3=[1,1,1,1];b3_c_pooling3='SAME'\n",
    "    \n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('b3_'+layer_name+'_1','W','B',b3_c_ksize1 , device_ ,'xavier',restore_flag,  restore_path)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('b3_'+layer_name+'_2','W','B',b3_c_ksize2 , device_ ,'xavier',restore_flag,  restore_path)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('b3_'+layer_name+'_3','W','B',b3_c_ksize3 , device_ ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info1=make_conv_info(x, b3_w_conv1, b3_b_conv1, b3_c_strides1, b3_c_pooling1)\n",
    "    b3_layer_1=convolution(b3_conv_info1 , place_info , bn_flag ,'b3_'+layer_name+'_L1' ,restore_flag,  restore_path)\n",
    "    b3_conv_info2=make_conv_info(b3_layer_1, b3_w_conv2, b3_b_conv2, b3_c_strides2, b3_c_pooling2)    \n",
    "    b3_layer_2=convolution(b3_conv_info2 , place_info , bn_flag ,'b3_'+layer_name+'_L2' ,restore_flag, restore_path)\n",
    "    b3_conv_info3=make_conv_info(b3_layer_2, b3_w_conv3, b3_b_conv3, b3_c_strides3, b3_c_pooling3)\n",
    "    b3_layer_3=convolution(b3_conv_info3 , place_info , bn_flag , 'b3_'+layer_name+'_L3' ,restore_flag,  restore_path)\n",
    "\n",
    "    #################################################################################                     \n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_concat=tf.concat(3,[layer2,b1_layer ,b2_layer,b3_layer_3 ],name = 'concat')\n",
    "        print layer_concat\n",
    "    return layer_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_B(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "\n",
    "    \"\"\"\n",
    "    for 17 X 17 grid \n",
    "    \"\"\"\n",
    "    in_ch =x.get_shape()[3]\n",
    "    out_ch1 =192 ; out_ch2=224; out_ch3 =256\n",
    "    c_ksize1 = [1,1, in_ch  ,out_ch1]\n",
    "    c_ksize2 = [1,7, out_ch1,out_ch2]\n",
    "    c_ksize3 = [7,1, out_ch2,out_ch3]\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases( layer_name+'_1','W' ,'B', c_ksize1 , device)\n",
    "    w_conv2 , b_conv2 =make_weights_biases( layer_name+'_2','W' ,'B', c_ksize2 , device)\n",
    "    w_conv3 , b_conv3 =make_weights_biases( layer_name+'_3','W' ,'B', c_ksize3 , device)\n",
    "    \n",
    "    c_strides1 =[1,1,1,1]\n",
    "    c_strides2 =[1,1,1,1]\n",
    "    c_strides3 =[1,1,1,1]\n",
    "    \n",
    "    c_pooling1 ='SAME'\n",
    "    c_pooling2 ='SAME'\n",
    "    c_pooling3 ='SAME'\n",
    "\n",
    "    conv_info1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer_1=convolution(conv_info_1 , place_info , bn_flag ,layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2=make_conv_info(layer_1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer_2=convolution(conv_info2 , place_info , bn_flag ,layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info3=make_conv_info(x, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "    layer_3=convolution(conv_info3 , place_info , bn_flag ,layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "\n",
    "    #####################################layer_1_branch############################################ \n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling ='SAME'\n",
    "    with tf.variable_scope(layer_name+'b1_layer1') as scope:\n",
    "        b1_layer1      =tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling ,name='conv')\n",
    "        b1_layer1_relu =tf.nn.relu(b1_layer1,name='relu')\n",
    "\n",
    "    b1_out_ch2 = 128\n",
    "    b1_c_ksize2=[1,1,in_ch,b1_out_ch]\n",
    "    b1_w_conv2 , b1_b_conv2 = make_weights_biases('b1_'+layer_name,'W','B',b1_c_ksize, device )\n",
    "    b1_c_strides2=[1,1,1,1]\n",
    "    b1_c_pooling2='SAME'\n",
    "    b1_conv_info2=make_conv_info(b1_layer1_relu , b1_w_conv2, b1_b_conv2, b1_c_strides2, b1_c_pooling2)\n",
    "    b1_layer2=convolution(b1_conv_info2 , place_info , bn_flag ,layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    #####################################layer_2_branch############################################ \n",
    "    b2_out_ch=384\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv =make_weights_biases('b2_'+layer_name,'W','B',b2_c_ksize , device)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "    b2_conv_info=make_conv_info(x , b2_w_conv, b1_b_conv, b2_c_strides, b2_c_pooling)\n",
    "    b2_layer=convolution(b2_conv_info , place_info , bn_flag ,layer_name+'_L' ,'xavier',restore_flag,  restore_path)\n",
    "    #####################################layer_3_branch############################################ \n",
    "\n",
    "\n",
    "    b3_out_ch1=192; b3_out_ch2 =192; b3_out_ch3=224 ; b3_out_ch4=224 ; b3_out_ch5 =256\n",
    "    b3_c_ksize1=[1,1,in_ch,b3_out_ch1]\n",
    "    b3_c_ksize2=[1,7,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3=[7,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4=[1,7,b3_out_ch3 , b3_out_ch4]\n",
    "    b3_c_ksize5=[7,1,b3_out_ch4 , b3_out_ch5]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1=make_weights_biases('b3_'+layer_name+'_1','W','B',b3_c_ksize1, device)\n",
    "    b3_w_conv2 , b3_b_conv2=make_weights_biases('b3_'+layer_name+'_2','W','B',b3_c_ksize2, device)\n",
    "    b3_w_conv3 , b3_b_conv3=make_weights_biases('b3_'+layer_name+'_3','W','B',b3_c_ksize3, device)\n",
    "    b3_w_conv4 , b3_b_conv4=make_weights_biases('b3_'+layer_name+'_4','W','B',b3_c_ksize4, device)\n",
    "    b3_w_conv5 , b3_b_conv5=make_weights_biases('b3_'+layer_name+'_5','W','B',b3_c_ksize5, device)\n",
    "    \n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4=[1,1,1,1]\n",
    "    b3_c_strides5=[1,1,1,1]\n",
    "    \n",
    "    b3_c_pooling1=\"SAME\"\n",
    "    b3_c_pooling2=\"SAME\"\n",
    "    b3_c_pooling3=\"SAME\"\n",
    "    b3_c_pooling4=\"SAME\"\n",
    "    b3_c_pooling5=\"SAME\"\n",
    "    \n",
    "    b3_conv_info1=make_conv_info(x , b3_w_conv1, b3_b_conv1, b3_c_strides1, b3_c_pooling1)\n",
    "    b3_layer1=convolution(b3_conv_info1 , place_info , bn_flag ,'b3_'+layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info2=make_conv_info(b3_layer1 , b3_w_conv2, b3_b_conv2, b3_c_strides2, b2_c_pooling)\n",
    "    b3_layer2=convolution(b3_conv_info2 , place_info , bn_flag ,'b3_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info3=make_conv_info(b3_layer2 , b3_w_conv3, b3_b_conv3, b3_c_strides3, b2_c_pooling)\n",
    "    b3_layer3=convolution(b3_conv_info3 , place_info , bn_flag ,'b3_'+layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info4=make_conv_info(b3_layer3 , b3_w_conv4, b3_b_conv4, b3_c_strides4, b2_c_pooling)\n",
    "    b3_layer4=convolution(b3_conv_info4 , place_info , bn_flag ,'b3_'+layer_name+'_L4' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info5=make_conv_info(b3_layer4 , b3_w_conv5, b3_b_conv5, b3_c_strides5, b2_c_pooling)\n",
    "    b3_layer5=convolution(b3_conv_info5 , place_info , bn_flag ,'b3_'+layer_name+'_L5' ,'xavier',restore_flag,  restore_path)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_concat=tf.concat(3, [layer_3 , b1_layer2 ,b2_layer ,b3_layer5] ,name='concat')\n",
    "    return layer_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_C(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "\n",
    "    \"\"\"\n",
    "    for 8 X 8 grid modules\n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1 = 384 ; out_ch2_a =256 ;out_ch2_b = 256\n",
    "    c_ksize1 = [1,1,in_ch , out_ch1]\n",
    "    c_ksize2_a = [1,3,out_ch1 , out_ch2_a]\n",
    "    c_ksize2_b = [3,1,out_ch1 , out_ch2_b]\n",
    "    w_conv1 ,b_conv1=make_weights_biases(layer_name+'_1','W','B', c_ksize1 ,device)\n",
    "    w_conv2_a ,b_conv2_a=make_weights_biases(layer_name+'_2_a','W','B', c_ksize2_a ,device)\n",
    "    w_conv2_b ,b_conv2_b=make_weights_biases(layer_name+'_2_b','_W_b','_B_b', c_ksize2_b ,device)\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2_a=[1,1,1,1]\n",
    "    c_strides2_b=[1,1,1,1]\n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2_a='SAME'\n",
    "    c_pooling2_b='SAME'\n",
    "    conv_info1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag ,layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2_a=make_conv_info(layer_1, w_conv2_a, b_conv2_a, c_strides2_a, c_pooling2_a)\n",
    "    layer2_a=convolution(conv_info2_a , place_info , bn_flag ,layer_name+'_L2_a' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2_b=make_conv_info(layer_1, w_conv2_b, b_conv2_b, c_strides2_b, c_pooling2_b)\n",
    "    layer2_b=convolution(conv_info2_b , place_info , bn_flag ,layer_name+'_L2_b' ,'xavier',restore_flag,  restore_path)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize1=[1,2,2,1]\n",
    "    b1_p_strides1=[1,1,1,1]\n",
    "    b1_p_pooling1='SAME'\n",
    "    with tf.variable_scope('b1_'+layer_name+'_1') as scope:    \n",
    "        b1_layer1     = tf.nn.avg_pool(x , b1_p_ksize1 , b1_p_strides1 , b1_p_pooling1 , name='avg_pool')\n",
    "        b1_layer1_relu= tf.nn.relu(b1_layer1 , name='relu')\n",
    "\n",
    "    b1_out_ch2 =256\n",
    "    b1_c_ksize2=[1,1,in_ch , b1_out_ch]\n",
    "    b1_w_conv2 , b1_b_conv2= make_weights_biases('b1_'+layer_name+'_2', 'W' ,'B', b1_c_ksize , device)\n",
    "    b1_c_pooling2 = 'SAME';b1_c_strides = [1,1,1,1];\n",
    "    b1_conv_info2=make_conv_info(x, b1_w_conv2, b1_b_conv2, b1_c_strides, b1_c_pooling2)\n",
    "    b1_layer2=convolution(b1_conv_info2 , place_info , bn_flag ,'b1_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    ################################################################################# \n",
    "    b2_out_ch=256\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv= make_weights_biases('b2_'+layer_name , 'W' , 'B',b2_c_ksize , device)\n",
    "    b2_c_pooling = 'SAME';b2_c_strides=[1,1,1,1];\n",
    "    b2_conv_info=make_conv_info(x, b1_w_conv2, b1_b_conv2, b1_c_strides, b1_c_pooling2)\n",
    "    b2_layer2=convolution(b2_conv_info , place_info , bn_flag ,'b2_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=384;b3_out_ch2=448;b3_out_ch3=512;b3_out_ch4_a=256;b3_out_ch4_b=256\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[1,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4_a =[3,1,b3_out_ch3 , b3_out_ch4_a]\n",
    "    b3_c_ksize4_b =[1,3,b3_out_ch3, b3_out_ch4_b]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('b3_'+layer_name+'_1','W','B',b3_c_ksize1 , device)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('b3_'+layer_name+'_2','W','B',b3_c_ksize2 , device)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('b3_'+layer_name+'_3','W','B',b3_c_ksize3 , device)\n",
    "    b3_w_conv4_a , b3_b_conv4_a = make_weights_biases('b3_'+layer_name+'_4_a','W','B',b3_c_ksize4_a , device)\n",
    "    b3_w_conv4_b , b3_b_conv4_b = make_weights_biases('b3_'+layer_name+'_4_b','W','B',b3_c_ksize4_b , device)\n",
    "\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4_a=[1,1,1,1]\n",
    "    b3_c_strides4_b=[1,1,1,1]\n",
    "\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "    b3_c_pooling4_a='SAME'\n",
    "    b3_c_pooling4_b='SAME'\n",
    "    b3_conv_info1=make_conv_info(x, b3_w_conv1, b3_b_conv1, b3_c_strides1, b3_c_pooling1)\n",
    "    b3_layer1=convolution(b3_conv_info1 , place_info , bn_flag ,'b3_'+layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info2=make_conv_info(b3_layer1, b3_w_conv2, b3_b_conv2, b3_c_strides2, b3_c_pooling2)\n",
    "    b3_layer2=convolution(b3_conv_info2 , place_info , bn_flag ,'b3_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info3=make_conv_info(b3_layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "    b3_layer3=convolution(b3_conv_info3 , place_info , bn_flag ,'b3_'+layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info4=make_conv_info(b3_layer3, w_conv4, b_conv4, c_strides4, c_pooling4)\n",
    "    b3_layer4=convolution(b3_conv_info4 , place_info , bn_flag ,'b3_'+layer_name+'_L4' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info5=make_conv_info(b3_layer4, w_conv5, b_conv5, c_strides5, c_pooling5)\n",
    "    b3_layer5=convolution(b3_conv_info5 , place_info , bn_flag ,'b3_'+layer_name+'_L5' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "\n",
    "    #################################################################################  with tf.variable_scope(layer_name+'b3_layer5') as scope:    \n",
    "    with tf.variable_scope(layer_name+'_end') as scope:    \n",
    "        layer_concat = tf.concat(3 , [layer2_a,layer2_b,b1_layer2, b2_layer2,b3_layer5],name='concat')\n",
    "\n",
    "    return layer_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_A(x , device,layer_name , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    ####################################################################################\n",
    "    \"\"\"\n",
    "    usage:\n",
    "    x shape =[ n_batch , row , col , ch] \n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch = 384\n",
    "    c_ksize= [3,3,in_ch , out_ch]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W','B',c_ksize,device)\n",
    "    c_strides=[1,2,2,1]\n",
    "    c_pooling='VALID'\n",
    "    conv_info=make_conv_info(x, w_conv, b_conv, c_strides, c_pooling)\n",
    "    layer=convolution(conv_info , place_info , bn_flag ,layer_name+'_L',restore_flag,  restore_path)\n",
    "\n",
    "    ####################################################################################   \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    with tf.variable_scope('b1_'+layer_name+'_L') as scope:\n",
    "        b1_layer = tf.nn.max_pool(x,b1_p_ksize , b1_p_strides , b1_p_pooling, name='max_pool')\n",
    "        b1_layer_relu = tf.nn.relu(b1_layer , name='relu')\n",
    "    ####################################################################################\n",
    "    b2_out_ch1 = 192; b2_out_ch2=288 ;b2_out_ch3 = 256;\n",
    "    b2_c_ksize1=[1,1,in_ch,b2_out_ch1]\n",
    "    b2_c_ksize2=[3,3,b2_out_ch1,b2_out_ch2]\n",
    "    b2_c_ksize3=[3,3,b2_out_ch2,b2_out_ch3]\n",
    "    \n",
    "    b2_w_conv1 , b2_b_conv1 = make_weights_biases('b2_'+layer_name+'_1' ,'W' ,'B', b2_c_ksize1 , device)\n",
    "    b2_w_conv2 , b2_b_conv2 = make_weights_biases('b2_'+layer_name+'_2' ,'W' ,'B',b2_c_ksize2 , device)\n",
    "    b2_w_conv3 , b2_b_conv3 = make_weights_biases('b2_'+layer_name+'_3' ,'W' ,'B',b2_c_ksize3 , device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,2,2,1]\n",
    "    b2_c_pooling1='SAME'\n",
    "    b2_c_pooling2='SAME'\n",
    "    b2_c_pooling3='VALID'\n",
    "    \n",
    "    b2_conv_info1=make_conv_info(x, b2_w_conv1, b2_b_conv1, b2_c_strides1, b2_c_pooling1)\n",
    "    b2_layer1=convolution(b2_conv_info1 , place_info , bn_flag ,'b2_'+layer_name+'_L1' ,restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info2=make_conv_info(b2_layer1, b2_w_conv2, b2_b_conv2, b2_c_strides2, b2_c_pooling2)\n",
    "    b2_layer2=convolution(b2_conv_info2 , place_info , bn_flag ,'b2_'+layer_name+'_L2' ,restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv3, b2_b_conv3, b2_c_strides3, b2_c_pooling3)\n",
    "    b2_layer3=convolution(b2_conv_info3 , place_info , bn_flag ,'b2_'+layer_name+'_L3' ,restore_flag,  restore_path)\n",
    "    \n",
    "    ####################################################################################\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:    \n",
    "        layer_concat=tf.concat(3 ,[layer ,b1_layer_relu ,b2_layer3] ,name='concat')\n",
    "\n",
    "    \n",
    "    \n",
    "    return layer_concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_B(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=192 ; out_ch2=192;\n",
    "\n",
    "    c_ksize1 =[1,1,in_ch , out_ch1]\n",
    "    c_ksize2 =[3,3,out_ch1,out_ch2]\n",
    "    w_conv1, b_conv1 = make_weights_biases(layer_name+'_1','W','B',c_ksize1,device)\n",
    "    w_conv2, b_conv2 = make_weights_biases(layer_name+'_2','W','B',c_ksize2,device)\n",
    "    \n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,2,2,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='VALID'\n",
    "    conv_info1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer1=convolution(conv_info1 , place_info , bn_flag ,layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info2 , place_info , bn_flag ,layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    ####################################################################################\n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    with tf.variable_scope('b1_'+layer_name+'L') as scope:\n",
    "        b1_layer=tf.nn.max_pool(x ,b1_p_ksize , b1_p_strides , b1_p_pooling,name='max_pool')\n",
    "        b1_layer_relu = tf.nn.relu(b1_layer , name='relu')\n",
    "    ####################################################################################\n",
    "    b2_out_ch1=256 ; b2_out_ch2 = 256 ; b2_out_ch3=320 ; b2_out_ch4=320;\n",
    "    b2_c_ksize1 =[1,1,in_ch , b2_out_ch1]\n",
    "    b2_c_ksize2 =[1,7,b2_out_ch1 , b2_out_ch2]\n",
    "    b2_c_ksize3 =[7,1,b2_out_ch2 , b2_out_ch3]\n",
    "    b2_c_ksize4 =[3,3,b2_out_ch3 , b2_out_ch4]\n",
    "    \n",
    "    b2_w_conv1, b2_b_conv1 = make_weights_biases('b2_'+layer_name+'_1','W' ,'B',b2_c_ksize1,device)\n",
    "    b2_w_conv2, b2_b_conv2 = make_weights_biases('b2_'+layer_name+'_2','W' ,'B',b2_c_ksize2,device)\n",
    "    b2_w_conv3, b2_b_conv3 = make_weights_biases('b2_'+layer_name+'_3','W' ,'B',b2_c_ksize3,device)\n",
    "    b2_w_conv4, b2_b_conv4 = make_weights_biases('b2_'+layer_name+'_4','W' ,'B',b2_c_ksize4,device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,1,1,1]\n",
    "    b2_c_strides4=[1,2,2,1]\n",
    "    \n",
    "    b2_c_pooling1= 'SAME'\n",
    "    b2_c_pooling2= 'SAME'\n",
    "    b2_c_pooling3 = 'SAME'\n",
    "    b2_c_pooling4 = 'VALID'\n",
    "    \n",
    "    b2_conv_info1=make_conv_info(x, b2_w_conv1, b2_b_conv1, b2_c_strides1, b2_c_pooling1)\n",
    "    b2_layer1=convolution(b2_conv_info1 , place_info , bn_flag ,'b2_'+layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info2=make_conv_info(b2_layer1, b2_w_conv2, b2_b_conv2, b1_c_strides2, b1_c_pooling2)\n",
    "    b2_layer2=convolution(b2_conv_info2 , place_info , bn_flag ,'b2_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv3, b2_b_conv3, b2_c_strides3, b2_c_pooling3)\n",
    "    b2_layer3=convolution(b2_conv_info3 , place_info , bn_flag ,'b2_'+layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv4, b2_b_conv4, b2_c_strides4, b2_c_pooling4)\n",
    "    b2_layer3=convolution(b2_conv_info4 , place_info , bn_flag ,'b2_'+layer_name+'_L4' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv5, b2_b_conv5, b2_c_strides5, b2_c_pooling5)\n",
    "    b2_layer3=convolution(b2_conv_info5 , place_info , bn_flag ,'b2_'+layer_name+'_L5' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_concat_A=tf.concat(3,[layer2,b1_layer_relu,b2_layer3] ,name='concat')\n",
    "    return layer_concat_A\n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULLYCONNCECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FLAT(x , device_ , layer_name = \"FLAT\"):\n",
    "    with tf.variable_scope(layer_name) as scope:\n",
    "        with tf.device(device_):\n",
    "            row=int(x.get_shape()[1])\n",
    "            col=int(x.get_shape()[2])\n",
    "            ch=int(x.get_shape()[3])\n",
    "\n",
    "            res_x = tf.reshape(x , shape=[-1,row*col*ch] ,name='flat_layer');\n",
    "            return res_x\n",
    "            #connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_A(x , dropout_rate ,n_classes , device_ , layer_name , restore_flag , restore_path):\n",
    "    with tf.device(device_):    \n",
    "        fully_ch1=1024; fully_ch2=1024;\n",
    "        \n",
    "        fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "        fc_ksize2=[fully_ch1,fully_ch2]\n",
    "\n",
    "        w_fc1 ,b_fc1 = make_weights_biases(layer_name+'_1' , 'W' ,'B' ,fc_ksize1 ,  device_,'xavier',restore_flag , restore_path)\n",
    "        w_fc2 ,b_fc2 = make_weights_biases(layer_name+'_2' , 'W' ,'B' ,fc_ksize2 ,  device_,'xavier',restore_flag , restore_path)\n",
    "    \n",
    "        h_fc1=tf.matmul(x, w_fc1 ,name='h_fc1')+b_fc1\n",
    "        h_fc1=tf.nn.dropout(h_fc1 , dropout_rate , name='h_fc1_dropout')\n",
    "        h_fc2=tf.matmul(h_fc1 , w_fc2 ,name='h_fc2')+b_fc2\n",
    "        h_fc2=tf.nn.dropout(h_fc2 , dropout_rate,name='h_fc2_dropout')\n",
    "        end_fc=h_fc2\n",
    "\n",
    "        end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases('fc_end' , 'W' , 'B' ,end_ksize ,  device_)\n",
    "        y_conv = tf.matmul(end_fc , w_end ,name=layer_name+'y_conv')+b_end\n",
    "\n",
    "        print w_fc1.get_shape()\n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_B(x , n_classes , device_ , layer_name , restore_flag , restore_path):\n",
    "    with tf.device(device_):\n",
    "        end_ksize=[x.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases\\\n",
    "        (layer_name , 'W','B' , end_ksize ,  device_ ,'xavier',restore_flag , restore_path)\n",
    "        y_conv = tf.matmul(x , w_end , name=layer_name+'y_conv')+b_end\n",
    "        return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FC_C(x , dropout_rate,n_classes , device_ , layer_name , restore_flag , restore_path):\n",
    "    with tf.device(device_):    \n",
    "        fully_ch1=1024;\n",
    "        \n",
    "        fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "\n",
    "        w_fc1 ,b_fc1 = make_weights_biases(layer_name , 'W' ,'B' ,fc_ksize1 ,  device_,'xavier',restore_flag , restore_path)    \n",
    "        h_fc1=tf.matmul(x, w_fc1 ,name='h_fc1')+b_fc1\n",
    "        h_fc1=tf.nn.dropout(h_fc1 , dropout_rate , name='h_fc1_dropout')\n",
    "        end_fc=h_fc1\n",
    "        print end_fc\n",
    "        end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases(layer_name+'_end' , 'W' , 'B' ,end_ksize ,  device_,'xavier',restore_flag , restore_path)\n",
    "        y_conv = tf.matmul(end_fc , w_end , name=layer_name+'y_conv')+b_end\n",
    "\n",
    "        print w_fc1.get_shape()\n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AVG_POOL(x , ksize , strides ,pooling,layer_name,device_):\n",
    "    with tf.device(device_):\n",
    "        layer=tf.nn.avg_pool(x,ksize ,strides,pooling,name = layer_name+\"AVG_POOL\")\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MAX_POOL(x , ksize , strides,pooling,layer_name,device_):\n",
    "    with tf.device(device_):\n",
    "        layer=tf.nn.max_pool(x,ksize ,strides,pooling,name = layer_name+\"MAX_POOL\")\n",
    "    print layer\n",
    "    return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DROPOUT(x ,keep_prob , layer_name , device_):\n",
    "    with tf.device(device_):\n",
    "        drop_x=tf.nn.dropout(x , keep_prob , name=layer_name+'dropout')\n",
    "        return drop_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CONV_6(x , device_ , layer_name , n_nodes , kernel_size ,strides ,pooling):\n",
    "    \"\"\" \n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[0] \n",
    "    \n",
    "    \"\"\"\n",
    "    in_ch = x.get_shape()[3]\n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[1] \n",
    "    \n",
    "    \n",
    "    out_ch1=n_nodes\n",
    "    out_ch2=n_nodes\n",
    "    out_ch3=n_nodes\n",
    "    out_ch4=n_nodes\n",
    "    out_ch5=n_nodes\n",
    "    out_ch6=n_nodes\n",
    "    \n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    c_ksize4=[k_row,k_col , out_ch3 , out_ch4]\n",
    "    c_ksize5=[k_row,k_col , out_ch4 , out_ch5]\n",
    "    c_ksize6=[k_row,k_col , out_ch5 , out_ch6]\n",
    "    \n",
    "    c_strides1=strides\n",
    "    c_strides2=strides\n",
    "    c_strides3=strides\n",
    "    c_strides4=strides\n",
    "    c_strides5=strides\n",
    "    c_strides6=strides\n",
    "    \n",
    "    c_pooling1=pooling\n",
    "    c_pooling2=pooling\n",
    "    c_pooling3=pooling\n",
    "    c_pooling4=pooling\n",
    "    c_pooling5=pooling\n",
    "    c_pooling6=pooling\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1) , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2) , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3) , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "    w_conv4 , b_conv4= make_weights_biases(layer_name+str(4) , 'W4' ,'B4', c_ksize4 ,device_name = device_)\n",
    "    w_conv5 , b_conv5= make_weights_biases(layer_name+str(5) , 'W5' ,'B5', c_ksize5 ,device_name = device_)\n",
    "    w_conv6 , b_conv6= make_weights_biases(layer_name+str(6) , 'W6' ,'B6', c_ksize5 ,device_name = device_)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1,name='layer1_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='layer2_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='layer3_relu')\n",
    "    with tf.variable_scope(layer_name+'conv4') as scope:\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4,name='layer4')+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4,name='layer4_relu')\n",
    "    with tf.variable_scope(layer_name+'conv5') as scope:\n",
    "        layer5 = tf.nn.conv2d(layer4 , w_conv5 , c_strides5 , c_pooling5,name='layer5')+b_conv5\n",
    "        layer5 = tf.nn.relu(layer5,name='layer5_relu')\n",
    "    with tf.variable_scope(layer_name+'conv6') as scope:\n",
    "        layer6 = tf.nn.conv2d(layer5 , w_conv6 , c_strides6 , c_pooling6,name='layer6')+b_conv6\n",
    "        layer6 = tf.nn.relu(layer5,name='layer6_relu')\n",
    "\n",
    "    return layer6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CONV_5(x , device_ , layer_name , n_nodes , kernel_size ,strides ,pooling):\n",
    "    \"\"\" \n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[0] \n",
    "    \n",
    "    \"\"\"\n",
    "    in_ch = x.get_shape()[3]\n",
    "\n",
    "    c_kernel1,c_kernel2,c_kernel3,c_kernel4,c_kernel5 = kernel_size  \n",
    "    out_ch1,out_ch2,out_ch3,out_ch4,out_ch5=n_nodes\n",
    "\n",
    "    c_ksize1=[c_kernel1[0],c_kernel1[1] , in_ch   , out_ch1]\n",
    "    c_ksize2=[c_kernel2[0],c_kernel2[1] , out_ch1 , out_ch2]\n",
    "    c_ksize3=[c_kernel3[0],c_kernel3[1] , out_ch2 , out_ch3]\n",
    "    c_ksize4=[c_kernel4[0],c_kernel4[1] , out_ch3 , out_ch4]\n",
    "    c_ksize5=[c_kernel5[0],c_kernel5[1] , out_ch4 , out_ch5]\n",
    "    \n",
    "    c_strides1,c_strides2,c_strides3,c_strides4,c_strides5=strides\n",
    "    c_pooling1,c_pooling2,c_pooling3,c_pooling4,c_pooling5=pooling\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1), 'W1' ,'B1' , c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2), 'W2' ,'B2' , c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3), 'W3' ,'B3' , c_ksize3 ,device_name = device_)\n",
    "    w_conv4 , b_conv4= make_weights_biases(layer_name+str(4), 'W4' ,'B4' , c_ksize4 ,device_name = device_)\n",
    "    w_conv5 , b_conv5= make_weights_biases(layer_name+str(5), 'W5' ,'B5' , c_ksize5 ,device_name = device_)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1,name='layer1_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='layer2_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='layer3_relu')\n",
    "    with tf.variable_scope(layer_name+'conv4') as scope:\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4,name='layer4')+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4,name='layer4_relu')\n",
    "    with tf.variable_scope(layer_name+'conv5') as scope:\n",
    "        layer5 = tf.nn.conv2d(layer4 , w_conv5 , c_strides5 , c_pooling5,name='layer5')+b_conv5\n",
    "        layer5 = tf.nn.relu(layer5,name='layer4_relu')\n",
    "\n",
    "    return layer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CONV_3(x , device_ , layer_name , n_nodes , kernel_size ,strides,pooling):\n",
    "    \"\"\"\n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    \"\"\"\n",
    "    \n",
    "    in_ch = x.get_shape()[3]\n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[1]     \n",
    "    \n",
    "    c_ksize1=[k_row,k_col , in_ch   , n_nodes]\n",
    "    c_ksize2=[k_row,k_col , n_nodes , n_nodes]\n",
    "    c_ksize3=[k_row,k_col , n_nodes , n_nodes]\n",
    "    \n",
    "    c_strides1=strides\n",
    "    c_strides2=strides\n",
    "    c_strides3=strides\n",
    "        \n",
    "    c_pooling1=pooling\n",
    "    c_pooling2=pooling\n",
    "    c_pooling3=pooling\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1) , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2) , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3) , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "    \n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1,name='layer1_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='layer2_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='layer3_relu')\n",
    "    return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CONV_3_BN(x , device_ , layer_name , n_nodes , kernel_size ,strides,pooling,train_flag=True):\n",
    "    \"\"\"\n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    \"\"\"\n",
    "    \n",
    "    in_ch = x.get_shape()[3]\n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[1]     \n",
    "    \n",
    "    c_ksize1=[k_row,k_col , in_ch   , n_nodes]\n",
    "    c_ksize2=[k_row,k_col , n_nodes , n_nodes]\n",
    "    c_ksize3=[k_row,k_col , n_nodes , n_nodes]\n",
    "    \n",
    "    c_strides1=strides\n",
    "    c_strides2=strides\n",
    "    c_strides3=strides\n",
    "        \n",
    "    c_pooling1=pooling\n",
    "    c_pooling2=pooling\n",
    "    c_pooling3=pooling\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1) , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2) , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3) , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "    \n",
    "    \n",
    "    beta1, gamma1 = tf.Variable()\n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1_BN = batch_norm(layer1,n_nodes ,train_flag,layer_name+'bn')\n",
    "        layer1_relu = tf.nn.relu(layer1_BN,name='layer1_relu')\n",
    "        \n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1_relu , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2_BN = batch_norm(layer2,n_nodes ,train_flag,layer_name+'bn2')\n",
    "        layer2_relu = tf.nn.relu(layer2_BN,name='layer2_relu')\n",
    "        \n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2_relu , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3_BN=batch_norm(layer3,n_nodes ,train_flag,layer_name+'bn3')\n",
    "        layer3_relu = tf.nn.relu(layer3_BN,name='layer3_relu')\n",
    "    return layer3_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CONV_1(x , device_ , layer_name , n_nodes , kernel_size ,strides, pooling,  place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    \"\"\"\n",
    "    \n",
    "    in_ch = x.get_shape()[3]\n",
    "    out_ch=n_nodes\n",
    "    c_ksize=[kernel_size[0], kernel_size[1] , in_ch, out_ch]\n",
    "    c_pooling =pooling\n",
    "    c_strides=strides # when downsampling featrue map , set strides parameter,[1,2,2,1]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W' ,'B' , c_ksize ,device_ ,'xavier',restore_flag ,  restore_path )\n",
    "    conv_info=make_conv_info(x, w_conv, b_conv, c_strides, c_pooling)\n",
    "    layer1=convolution(conv_info , place_info , bn_flag , layer_name+'_L' , restore_flag , restore_path)   \n",
    "    print layer_name , layer1.get_shape()\n",
    "    return layer1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def batch_norm(x , decay, train_flag ):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        x shape: [n , row , col , ch]\n",
    "        n_out:       integer, depth of input maps\n",
    "        train_flag: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    \n",
    "    n_out=x.get_shape()[3]\n",
    "    with tf.variable_scope('bn'):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(train_flag,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    \"\"\"\n",
    "    return ret_train_img_list ,ret_train_lab_list \n",
    "    \n",
    "    \"\"\"\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    np_train_imgs=[]\n",
    "    np_train_labs=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    \n",
    "    ret_train_img_list.sort(key=natural_keys)\n",
    "    ret_train_lab_list.sort(key = natural_keys)\n",
    "    print 'check match image and label '\n",
    "    for i in range(len(ret_train_img_list)):\n",
    "        print ret_train_img_list[i] , ret_train_lab_list[i]\n",
    "    \n",
    "    for i  in range(len(ret_train_img_list)):\n",
    "        print str(i)+'th Image loading... waiting for minute....'\n",
    "        np_train_imgs.append(np.load(folder_path+ret_train_img_list[i]))\n",
    "        np_train_labs.append(np.load(folder_path+ret_train_lab_list[i]))\n",
    "    \n",
    "    return np_train_imgs ,np_train_labs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    \n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    \n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                \n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "                \n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "    \n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test_img(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col ):\n",
    "    left_top =(0,0)\n",
    "    right_top =(  img_row  - crop_img_row  , 0 )\n",
    "    center =  ((img_row  - crop_img_row)/2  , (img_col - crop_img_row)/2)\n",
    "    left_buttom = (0,(img_col - crop_img_row)/2 )\n",
    "    right_buttom =  (img_row  - crop_img_row , img_col - crop_img_row)\n",
    "    \n",
    "    left_top_images  = np_img[: , left_top[0]:crop_img_row+left_top[0] , left_top[1] : crop_img_col+left_top[1] , :  ]\n",
    "    right_top_images = np_img[: , right_top[0]:crop_img_row +right_top[0], right_top[1] : crop_img_col +right_top[1], :  ]\n",
    "    center_images    = np_img[: , center[0]:crop_img_row +center[0], center[1] : crop_img_col +center[1], :  ]\n",
    "    left_buttom_images=np_img[: , left_buttom[0]:crop_img_row +left_buttom[0], left_buttom[1] : crop_img_col +left_buttom[1], :  ]\n",
    "    right_buttom_images= np_img[: , right_buttom[0]:crop_img_row+right_buttom[0] , right_buttom[1] : crop_img_col +right_buttom[1] , :  ]\n",
    "\n",
    "    \n",
    "        \n",
    "    return left_top_images , right_top_images , center_images , left_buttom_images , right_buttom_images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TRAIN_STRUCTURE_A(y_conv , y_ , device_,learning_rate ):\n",
    "    \"\"\"\n",
    "    Return Value : cost , train_step ,correct_prediction , accuracy \n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "    #sm_conv= tf.nn.softmax(y_conv)\n",
    "        #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "        softmax=tf.nn.softmax(y_conv)\n",
    "        pred_cls = tf.argmax(softmax , axis = 1)\n",
    "        #regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "    with tf.device(device_):\n",
    "        #cost = cost+regular\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost) #1e-4\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "    tensor_info ={}\n",
    "    tensor_info['cost']=cost\n",
    "    tensor_info['train_step']=train_step\n",
    "    tensor_info['correct_prediction']=correct_prediction\n",
    "    tensor_info['accuracy']=accuracy\n",
    "    tensor_info['softmax']=softmax\n",
    "    tensor_info['pred_cls'] = pred_cls\n",
    "    return tensor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def START_SESS():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    return sess \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Terminal Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "def make_logdir(dirname):\n",
    "  \n",
    "\n",
    "    count=0\n",
    "    while(True):\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        elif not os.path.isdir(dirname + str(count)):\n",
    "            dirname=dirname+str(count)\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    print 'it is recorded at :'+str(count)\n",
    "\n",
    "    f=open(dirname+\"/log.txt\",'w')\n",
    "    return f,dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_acc_loss(step , val_acc , val_loss ,file_path):\n",
    "    \"\"\"\n",
    "    fp = File Pointer\n",
    "    \"\"\"\n",
    "    str_ = 'step:\\t'+str(step)+'\\tacc:\\t'+str(acc) +'\\tloss:\\t'+str(loss)+'\\n'\n",
    "    fp.write(str_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_TVT(divide_flag,file_locate):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data Image\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        \n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "        return train_img ,train_lab,val_img,val_lab,test_img,test_lab\n",
    "    if divide_flag == True:\n",
    "        print '트레이닝 파일이 여러개로 분할되어 있습니다. 분할된 트레이닝 파일에 대한 조치가 필요합니다'\n",
    "        train_images, train_labels =get_batch_list(file_locate)\n",
    "        #print train_images ,train_labels\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "        print \"the number of training image batch\",len(train_images)\n",
    "        print \"the number of training label batch\",len(train_labels)\n",
    "        print \"training Data Label\",np.shape(train_labels[0])\n",
    "        print \"training Data Image\",np.shape(train_images[0])\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        return train_images, train_labels,val_img,val_lab,test_img,test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_weights_biases(sess, save_folder):\n",
    "    \n",
    "    trainable_list=tf.trainable_variables()\n",
    "    save_paths=[]\n",
    "    for i,ele in enumerate(trainable_list): \n",
    "        #print ele\n",
    "        #print ele.name.replace('/' , '_')\n",
    "        np_=sess.run(ele)\n",
    "        #print 'name:',ele.name\n",
    "        np.save(save_folder+ele.name.replace('/' , '_').replace(':0' , '') , np_ )\n",
    " \n",
    "    print \"model was saved\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate(sess,img , lab ,tensor_info , place_info,tensorboard_info=None , step=None): #default\n",
    "    \"\"\"\n",
    "    return val_acc,  val_loss, train_acc, train_loss\n",
    "    tensorboard_info['writer']\n",
    "    tensorboard_info['merge']    \n",
    "    \"\"\"    \n",
    "    #print 'validate tensorboard' , tensorboard_info\n",
    "    if tensorboard_info ==None: #텐서 보드를 비활성 합니다.\n",
    "        print 'No tensorboard info'\n",
    "        acc ,loss = sess.run( [tensor_info['accuracy'],tensor_info['cost']] ,\\\n",
    "                             feed_dict={place_info['x_']:img , place_info['y_']: lab , place_info['keep_prob']: 1.0})    \n",
    "    else: # 텐서보드를 활성화 합니다\n",
    "        print 'tensorboard info'\n",
    "        summary,acc,loss = sess.run([tensorboard_info['merge'],tensor_info['accuracy'],tensor_info['cost']] ,\\\n",
    "                                    feed_dict={place_info['x_']:img , place_info['y_']:lab , place_info['keep_prob']: 1.0})        \n",
    "        tensorboard_info['writer'].add_summary(summary , step)\n",
    "        \n",
    "        \n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "def validate_extract_imgs(val_img , val_lab , train_img , train_lab ):\n",
    "    \"\"\"\n",
    "    extract patch from ori-image\n",
    "    \"\"\"\n",
    "    color_ch = in_ch\n",
    "    val_images  =extract_test_img(val_img , 128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    train_images=extract_test_img(train_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    val_acc, val_loss =validate_from_images(sess, val_images , val_lab , accuracy ,cost )\n",
    "    train_acc , train_loss =validate_from_images(sess, train_images , train_lab ,accuracy , cost)\n",
    "    return val_acc , val_loss, train_acc ,train_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_8_times(x):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x shape is [n_batch , row ,col , color_ch ]\n",
    "    x type is numpy \n",
    "    this code need too many time to run \n",
    "    we should find solution using parallel method to less run time maybe \n",
    "    \n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n_batch,row,col,ch=np.shape(x)\n",
    "    lr_x = np.flipud(x)\n",
    "\n",
    "    np_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "\n",
    "    np_lr_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    \n",
    "    \n",
    "\n",
    "    for batch_ind in range(n_batch):\n",
    "\n",
    "        rot90=np.rot90(x[batch_ind,:,:,:])\n",
    "        rot180=np.rot90(rot90)\n",
    "        rot270=np.rot90(rot180)\n",
    "\n",
    "        np_rot90[batch_ind,:,:,:] = rot90\n",
    "        np_rot180[batch_ind,:,:,:]=rot180\n",
    "        np_rot270[batch_ind,:,:,:]=rot270\n",
    "\n",
    "        lr_rot90=np.rot90(lr_x[batch_ind,:,:,:])\n",
    "        lr_rot180=np.rot90(lr_rot90)\n",
    "        lr_rot270=np.rot90(lr_rot180)\n",
    "\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot90\n",
    "        np_lr_rot180[batch_ind,:,:,:]=lr_rot180\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot270\n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OPEN_TENSORBOARD(sess,tensor_info , logdir ):\n",
    "    \n",
    "    tensorboard_info={}\n",
    "    tb_acc=tf.summary.scalar(\"accuarcy\" ,tensor_info['accuracy'] )\n",
    "    tb_loss=tf.summary.scalar(\"loss\" ,tensor_info['cost'] )\n",
    "    tb_merge = tf.summary.merge_all()\n",
    "    writer=tf.train.SummaryWriter(logdir , sess.graph )\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    tensorboard_info['writer']=writer\n",
    "    tensorboard_info['merge'] =tb_merge\n",
    "  \n",
    "    return tensorboard_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_crop(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "\n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "\n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "\n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "\n",
    "    return ret_images ,ret_labels\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_result(dirname , result):\n",
    "    \"\"\"\n",
    "     list_val_acc , list_val_loss , list_train_acc , list_train_loss\n",
    "    \"\"\"\n",
    "    np_val_acc=np.asarray(result[0])\n",
    "    np.save(dirname+'/val_acc' , np_val_acc)\n",
    "    np_val_loss=np.asarray(result[1])\n",
    "    np.save(dirname+'/val_loss' , np_val_loss)\n",
    "    \n",
    "    np_train_acc=np.asarray(result[2])\n",
    "    np.save(dirname+'/train_acc' , np_train_acc)\n",
    "    np_train_loss=np.asarray(result[3])\n",
    "    np.save(dirname+'/train_loss' , np_train_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_val(val_imgs = None,  val_labs=None):\n",
    "    \"\"\"\n",
    "    사용되는 글로벌 함수:\n",
    "    1.flie_locate\n",
    "    2.place_infro (divide_images)\n",
    "    \"\"\"\n",
    "    if val_imgs == None and val_labs ==None: \n",
    "        start_time=time.time()\n",
    "        val_img=np.load(file_locate + 'val_img.npy')\n",
    "        val_lab=np.load(file_locate + 'val_lab.npy')\n",
    "        val_imgs, val_labs = divide_images(val_img ,val_lab)\n",
    "        end_time=time.time()\n",
    "        print \"validate images , labels was loaded and divided with batch_size\"\n",
    "        print \"batch_size : \",batch_size\n",
    "        return val_imgs, val_labs\n",
    "    elif val_imgs != None and val_labs !=None:\n",
    "        return val_imgs  , val_labs\n",
    "\n",
    "    \n",
    "def load_test(test_imgs = None , test_labs=None):\n",
    "    \n",
    "    \"\"\"    \n",
    "    사용되는 글로벌 함수:\n",
    "    1.flie_locate\n",
    "    2.place_infro (divide_images)\n",
    "    \"\"\"\n",
    "    if test_imgs == None and test_labs ==None: \n",
    "\n",
    "        start_time=time.time()\n",
    "        test_img=np.load(file_locate+'test_img.npy')\n",
    "        test_lab=np.load(file_locate+'test_lab.npy')\n",
    "        val_imgs, val_labs = divide_images(val_img ,val_lab)\n",
    "        end_time=time.time()\n",
    "        print \"test images , labels was loaded and divided with batch_size\"\n",
    "        print \"batch_size : \",batch_size\n",
    "        print \"loading time\" , end_time-start_time\n",
    "        return test_imgs, test_labs\n",
    "    elif test_imgs != None and test_labs !=None:\n",
    "        return test_imgs  , test_labs\n",
    "\n",
    "def load_train(b_ind=None):\n",
    "    if b_ind==None:\n",
    "        b_ind=random.randrange(0,n_train)\n",
    "    train_img=np.load(file_locate+'train_'+str(b_ind)+'_img.npy')\n",
    "    train_lab=np.load(file_locate+'train_'+str(b_ind)+'_lab.npy')\n",
    "    return train_img , train_lab ,b_ind\n",
    "\n",
    "def load_train_all(start=None , end=None , arg_list=None):\n",
    "    pool=Pool()\n",
    "    train_imgs=[]\n",
    "    train_labs=[]\n",
    "    if arg_list!=None:\n",
    "        list_ = arg_list\n",
    "    elif start==None and end ==None:\n",
    "        list_=range(n_train)    \n",
    "    elif start!=None and end !=None:\n",
    "        list_=range(start , end)\n",
    "    \n",
    "    for train_img , train_lab ,b_ind in pool.imap(load_train ,list_):\n",
    "        train_imgs.append(train_img)\n",
    "        train_labs.append(train_lab)\n",
    "        msg='progress - {0}/{1}'.format(str(b_ind),str(n_train))\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    return train_imgs , train_labs\n",
    "\n",
    "def make_acc_step_log(folder_path):\n",
    "    f=open(folder_path+'step_max_acc.txt' , 'w')\n",
    "    msg='step\\tacc\\n'\n",
    "    f.write(msg,)\n",
    "    msg='{0}\\t{1}\\n'.format(str(0),str(0))\n",
    "    f.write(msg)\n",
    "    f.close()\n",
    "def make_folder(folder_path='./'):\n",
    "    # make folder that take accuracy , loss \n",
    "    # if folder is already existed , load folder. \n",
    "    up_to_date_folder=folder_path+'up_to_date/'\n",
    "    interrupt_folder=folder_path+'Interrupt/'\n",
    "    best_acc_folder=folder_path+'best_acc/'\n",
    "    if os.path.isdir(up_to_date_folder) != True:\n",
    "        os.mkdir(up_to_date_folder)\n",
    "        make_acc_step_log(up_to_date_folder)\n",
    "    if os.path.isdir(interrupt_folder)!=True:\n",
    "        os.mkdir(interrupt_folder)\n",
    "        make_acc_step_log(interrupt_folder)\n",
    "    if os.path.isdir(best_acc_folder)!=True:\n",
    "        os.mkdir(best_acc_folder)\n",
    "        make_acc_step_log(best_acc_folder)\n",
    "\n",
    "def load_step_acc(folder_path):\n",
    "    try:\n",
    "        f=open(folder_path+'step_max_acc.txt' , 'r')\n",
    "        step ,max_acc=f.readlines()[-1].split('\\t')\n",
    "        \n",
    "        print \"global_step and max_acc was restore!\"\n",
    "        print \"global step:\",step\n",
    "        print \"Max acc:\" ,max_acc\n",
    "        return step , max_acc\n",
    "\n",
    "    except IOError as ioe:\n",
    "        print 'global_step or maxacc cant found in'+folder_path\n",
    "        print 'Initialize global_step and max_acc to zero'\n",
    "        step=0 ;acc=0\n",
    "        return step , acc  \n",
    "    except Exception as ex:\n",
    "        print 'global_step or maxacc cant found in'+folder_path\n",
    "        print 'Initialize global_step and max_acc to zero'\n",
    "        step=0 ;acc=0\n",
    "        return step , acc  \n",
    "        \n",
    "#def write_acc_loss()\n",
    "\n",
    "def divide_images(images , labels):\n",
    "    \"\"\"\n",
    "    return list_images,list_labels\n",
    "    \"\"\"\n",
    "    n_divide=len(images)/batch_size\n",
    "\n",
    "    list_images=[]\n",
    "    list_labels=[]\n",
    "    for ind in range(n_divide):\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        image =images[ ind*batch_size :(ind+1)*batch_size] \n",
    "        label =labels[ ind*batch_size :(ind+1)*batch_size]\n",
    "        list_images.append(image)\n",
    "        list_labels.append(label)\n",
    "\n",
    "    #right above code have to modify\n",
    "    image = images[ -batch_size :  ] \n",
    "    label = labels[ -batch_size :  ]\n",
    "    list_images.append(image)\n",
    "    list_labels.append(label)\n",
    "    return list_images,list_labels\n",
    "\n",
    "def validate_from_images(images , labels ,tensor_info, place_info ,correct_pred=False,tensorboard_info = None ):    \n",
    "    \"\"\"\n",
    "    input : x-\n",
    "\n",
    "    x type  : numpy \n",
    "    x shape : [n , row , col , ch]\n",
    "    return  acc,  loss\n",
    "\n",
    "\n",
    "    2017/2/16\n",
    "    왜 tensorboard 에 기록이 안되나 했더니 여기서 문제가 있었다.3\n",
    "    validate_from_images에서는 기록이 안된다.\n",
    "    기록할수 있는 방법을 찾아야 겠다\n",
    "    내 생각에는 기존의 방식과 다른 tensorboard  객체를 만들고 거기다가 기록해야 할 것 같다.\n",
    "    \n",
    "    사용되는 글로벌 함수\n",
    "    place_info \n",
    "    \"\"\"    \n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    images_labels=zip(images,labels)\n",
    "    temp_correct_list = []\n",
    "    for img_ind ,(img,lab)  in enumerate(images_labels):\n",
    "        acc ,loss , correct_prediction= sess.run( [tensor_info['accuracy'],tensor_info['cost'] , tensor_info['correct_prediction']],\\\n",
    "                             feed_dict={place_info['x_']:img , place_info['y_']: lab , place_info['keep_prob']: 1.0  , place_info['phase_train']:False})\n",
    "        temp_correct_list.extend(correct_prediction)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "    correct_prediction=temp_correct_list\n",
    "    acc_list=np.asarray(acc_list)\n",
    "    loss_list=np.asarray(loss_list)\n",
    "    acc=np.mean(acc_list)\n",
    "    loss=np.mean(loss_list)\n",
    "    #print 'validate tensorboard' , tensorboard_info\n",
    "\n",
    "    if correct_pred == True:\n",
    "        #print 'correct_pred is True'\n",
    "        return acc , loss , correct_prediction\n",
    "    elif correct_pred == False :\n",
    "        return  acc,  loss\n",
    "\n",
    "def TRAINING(step,batch_xs , batch_ys , tensor_info ,place_info):\n",
    "    msg = '\\r-Progress : {0}/{1}'.format( str(step%check_point), str(check_point))\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    #print '---------------------------- --------training start{0}------------------------------------'.format(step)    \n",
    "    sess.run(tensor_info['train_step'] ,feed_dict={place_info['x_']: batch_xs, \\\n",
    "                                                   place_info['y_']:batch_ys , place_info['keep_prob'] : 0.5 , place_info['phase_train'] :True})\n",
    "def VALIDATE(val_imgs,val_labs,tensor_info,place_info):\n",
    "    start_time=time.time()\n",
    "    val_imgs,val_labs=divide_images(val_imgs , val_labs)\n",
    "    print np.shape(val_imgs)\n",
    "    val_acc, val_loss =validate_from_images(val_imgs ,val_labs ,tensor_info ,place_info) # 이걸 여러개의 쓰레드로 나눠서 실행해야한다\n",
    "    print time.time()-start_time\n",
    "    return val_acc , val_loss\n",
    "\n",
    "def TESTING(test_imgs, test_labs , tensor_info , place_info , training=True):\n",
    "    test_imgs,test_labs=divide_images(test_imgs, test_labs)\n",
    "    test_acc, test_loss =validate_from_images(test_imgs ,test_labs ,tensor_info ,place_info)\n",
    "    print \"test accuracy {0} , test loss {1}\".format(test_acc, test_loss)\n",
    "def save_weights_biases(step , max_acc , val_acc, save_folder ):\n",
    "    if  val_acc  > max_acc:\n",
    "        f=open(save_folder+'step_max_acc.txt','a')\n",
    "        msg='{0}\\t{1}\\n'.format(step , max_acc)\n",
    "        f.write(msg)\n",
    "        max_acc = val_acc  \n",
    "        trainable_list=tf.trainable_variables()\n",
    "        save_paths=[]\n",
    "        for i,ele in enumerate(trainable_list): \n",
    "            #print ele\n",
    "            #print ele.name.replace('/' , '_')\n",
    "            np_=sess.run(ele)\n",
    "            #print 'name:',ele.name\n",
    "            np.save(save_folder+ele.name.replace('/' , '_').replace(':0' , '') , np_ )\n",
    "\n",
    "        print \"model was saved\"\n",
    "        return max_acc\n",
    "    else:\n",
    "        return max_acc\n",
    "\"\"\"\n",
    "    def show_histo(save_folder,global_step):\n",
    "    if show_histo_flag:\n",
    "    if os.path.isdir(save_folder+'histogram/') == False:\n",
    "    os.mkdir(save_folder+'histogram/')\n",
    "    show_histo(save_folder+'histogram/' , step)\n",
    "    print \"making histogram\"\n",
    "    n_trainable=len(tf.trainable_variables())\n",
    "    plot_row=int(math.ceil((math.sqrt(n_trainable))))\n",
    "\n",
    "    plot_col=plot_row \n",
    "    print plot_col , plot_row\n",
    "    fig , axes  = plt.subplots(plot_row ,plot_col ,figsize=(60, 60))\n",
    "\n",
    "    for i , tensor in enumerate(tf.trainable_variables()):\n",
    "        if 'W' in tensor.name or 'B' in tensor.name:\n",
    "            values=sess.run(tensor.name)\n",
    "            values_np = np.asarray(values).flatten()\n",
    "            axes.flat[i].hist(values_np)\n",
    "            axes.flat[i].set_xlabel(tensor.name)\n",
    "    plt.savefig(save_folder+'/weights_and_biases_'+str(global_step)+'.png')\n",
    "    print \"saved histogram! \"\n",
    "    plt.close()\n",
    "\"\"\"\n",
    "def interrupt_mgs():\n",
    "    print \"keyboard Interupted!\"\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    print \"now start validate Test set by model Don't stop! waiting for a minute...\"\n",
    "\n",
    "    step_np[0]=step\n",
    "    maxacc_np[0] = max_acc\n",
    "    print \"now we start saving accuracy and loss\"\n",
    "    print \"training acc,loss Validation acc and loss was saved!\"        \n",
    "\n",
    "def show_acc_loss( step , val_acc , val_loss):\n",
    "    print(\"step %d , validation  accuracy %g\" %(step,val_acc))\n",
    "    print(\"step %d , validation loss : %g\" %(step,val_loss))\n",
    "\n",
    "def next_batch(batch_size,*args):\n",
    "    \"\"\"\n",
    "    list_number : \n",
    "    Type : list \n",
    "    N.B. the argument list_restricNum is extracted in turn  \n",
    "    from each kwargs element\n",
    "    list_clsNum: \n",
    "    Type : list \n",
    "    N.B. the argument list_clsNum point at number which \n",
    "    each args list is taken   \n",
    "    \"\"\"\n",
    "    #print batch_size\n",
    "    batch_count=0\n",
    "    imgs_list=[]\n",
    "    for i,thing in enumerate(args):\n",
    "        imgs_list.append(thing)\n",
    "    #print 'the number of classes : ',n_classes\n",
    "    ret_imgs=[]\n",
    "    ret_cls=[]\n",
    "    for i in range(batch_size):    \n",
    "        cls_idx=random.randint(0,n_classes-1)\n",
    "        imgs=imgs_list[cls_idx]\n",
    "        imgs=np.asarray(imgs)\n",
    "        n_imgs =np.shape(imgs)[0]\n",
    "        ind=random.randint(0,n_imgs-1)\n",
    "        img=imgs[ind]\n",
    "        ret_imgs.append(img)\n",
    "        ret_cls.append(cls_idx)\n",
    "    ret_imgs=np.asarray(ret_imgs)\n",
    "    ret_cls=np.asarray(ret_cls)\n",
    "    ret_labs=cls2onehot(n_classes,ret_cls)\n",
    "    return ret_imgs , ret_labs\n",
    "\n",
    "def next_random_batch(image , label ):\n",
    "    indices=random.sample(range(np.shape(image)[0])  , batch_size)\n",
    "    batch_x = image[indices]\n",
    "    batch_y= label[indices]\n",
    "    return batch_x, batch_y\n",
    "\n",
    "def next_batch_list(image_list , label_list , selected_list= None ):\n",
    "    \"\"\"\n",
    "    image_list shape taken 5 shape : [n_ , batch , row , col , in_ch]\n",
    "    3rd param 'list_' taken list that include which number run\n",
    "    \"\"\"\n",
    "    if selected_list != None:\n",
    "        random.shuffle(selected_list)\n",
    "        ind=selected_list[0]\n",
    "        #print 'selected_list'\n",
    "        #print 'ind',ind\n",
    "    elif selected_list == None:\n",
    "        ind=np.random.randint(len(image_list))\n",
    "    batch_x , batch_y=next_batch(image_list[ind] , label_list[ind] )\n",
    "    return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VALIDATE_FROM_TRAIN(indices):\n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    correct_list=[]\n",
    "    n_batch , row , col , input_ch =np.shape(train_imgs_list[0])\n",
    "    for i in indices:\n",
    "        imgs, labs =divide_images(train_imgs_list[i] ,train_labs_list[i] )\n",
    "        acc ,loss , correct_=validate_from_images(imgs , labs, tensor_info , place_info , correct_pred=True)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "        correct_list.extend(correct_)\n",
    "        \n",
    "    share =  len(train_imgs_list[i])/ batch_size \n",
    "    remainder = len(train_imgs_list[i])%batch_size\n",
    "    temp_correct_=[]\n",
    "    for k in range(len(indices)):\n",
    "        list_=correct_list[ (k*n_batch) + k*(n_batch - remainder)  : (k+1)*n_batch + k*(n_batch - remainder) ]\n",
    "        temp_correct_.extend(list_)\n",
    "    correct_list=np.asarray(temp_correct_)\n",
    "    acc=np.mean(correct_list)\n",
    "    print len(correct_list)\n",
    "    return acc , loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_point=100\n",
    "step=0\n",
    "def BATCH_TRAINING_RANDOM(maxiter, tensor_info, place_info,save_folder,restore_path,tensorboard_info=None , val_img_lab =None , test_img_lab=None):\n",
    "    try:\n",
    "        max_acc=0\n",
    "        make_folder(save_folder)\n",
    "        start_step,max_acc=load_step_acc(restore_path)\n",
    "        #val_imgs,val_labs=load_val()\n",
    "        for i in range(int(start_step), maxiter):\n",
    "            step=i\n",
    "            if step%check_point==0: #여기 if loop에서 validate을 합니다     \n",
    "                type1_val_acc,type1_val_loss=VALIDATE(test_type_1,test_type_1_lab,tensor_info , place_info)\n",
    "                type2_val_acc,type2_val_loss=VALIDATE(test_type_2,test_type_2_lab,tensor_info , place_info)\n",
    "                type3_val_acc,type3_val_loss=VALIDATE(test_type_3,test_type_3_lab,tensor_info , place_info)\n",
    "\n",
    "                acc_mean= ( type1_val_acc + type2_val_acc + type3_val_acc )/3\n",
    "                loss_mean=( type1_val_loss+ type2_val_loss + type3_val_loss )/3\n",
    "                show_acc_loss(step,type1_val_acc,type1_val_loss) \n",
    "                show_acc_loss(step,type2_val_acc,type2_val_loss) \n",
    "                show_acc_loss(step,type3_val_acc,type3_val_loss) \n",
    "                show_acc_loss(step,acc_mean,loss_mean) \n",
    "                if acc_mean > max_acc:\n",
    "                    save_weights_biases( step ,max_acc ,acc_mean , save_folder )\n",
    "                    max_acc=acc_mean \n",
    "            batch_xs ,batch_ys=next_batch(batch_size , train_type_1,train_type_2,train_type_3)\n",
    "            TRAINING(step,batch_xs , batch_ys,tensor_info,place_info)\n",
    "    except KeyboardInterrupt as kbie:\n",
    "        interrupt_mgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_folder='./model/'\n",
    "restore_path='./model/'\n",
    "restore_flag=False\n",
    "device_='/gpu:1'\n",
    "bn_flag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 214, 214, 3)\n",
      "PRE make weigths and biases\n",
      "(30, 56, 56, 64)\n",
      "STEM_A_1 make weigths and biases\n",
      "STEM_A_2 make weigths and biases\n",
      "STEM_A_3 make weigths and biases\n",
      "STEM_A_4 make weigths and biases\n",
      "STEM_B_1 make weigths and biases\n",
      "STEM_B_2 make weigths and biases\n",
      "STEM_B_3 make weigths and biases\n",
      "STEM_B_4 make weigths and biases\n",
      "b_STEM_B_1 make weigths and biases\n",
      "b_STEM_B_2 make weigths and biases\n",
      "STEM_C_1 make weigths and biases\n",
      "MODUEL_A_a_1 make weigths and biases\n",
      "MODUEL_A_a_2 make weigths and biases\n",
      "b1_MODUEL_A_a make weigths and biases\n",
      "b2_MODUEL_A_a make weigths and biases\n",
      "b3_MODUEL_A_a_1 make weigths and biases\n",
      "b3_MODUEL_A_a_2 make weigths and biases\n",
      "b3_MODUEL_A_a_3 make weigths and biases\n",
      "Tensor(\"MODUEL_A_a_end/concat:0\", shape=(30, 10, 10, 384), dtype=float32)\n",
      "FC_C make weigths and biases\n",
      "Tensor(\"h_fc1_dropout/mul:0\", shape=(30, 1024), dtype=float32, device=/device:GPU:1)\n",
      "FC_C_end make weigths and biases\n",
      "(38400, 1024)\n",
      "Tensor(\"add_1:0\", shape=(30, 3), dtype=float32, device=/device:GPU:1)\n"
     ]
    }
   ],
   "source": [
    "images=tf.map_fn (lambda image: pre_processing(image) ,x_)\n",
    "print images.get_shape()\n",
    "PRE=PRE_LAYER(x_ , device_,'PRE',64 , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "A=STEM_A(PRE , device_,'STEM_A',(32,32,64,96) , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "B=STEM_B(A , device_,'STEM_B', place_info  , bn_flag  , restore_flag , restore_path)\n",
    "C=STEM_C(B , device_,'STEM_C' , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "D=INCEPTION_MODULE_A(C, device_,'MODUEL_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#E=INCEPTION_MODULE_A(D, device_,'MODUEL_A_b',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#F=INCEPTION_MODULE_A(E, device_,'MODUEL_A_c',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#G=INCEPTION_MODULE_A(F, device_,'MODUEL_A_d',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_REDUCTION_A(G,device_,'REDUCT_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_MODULE_A(G, device_,'MODUEL_A_e',place_info ,bn_flag, restore_flag , restore_path)\n",
    "flat_ = FLAT(D , device_ , layer_name='FLAT_')\n",
    "y_conv=FC_C(flat_ , 0.5 , n_classes , device_ , 'FC_C' , restore_flag , restore_path)\n",
    "print y_conv\n",
    "tensor_info=TRAIN_STRUCTURE_A(y_conv , y_ , device_ , learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "images=tf.map_fn (lambda image: pre_processing(image) ,x_)\n",
    "print images.get_shape()\n",
    "PRE=PRE_LAYER(x_ , device_,'PRE',64 , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "A=CONV_1(PRE , device_  ,'CONV_1_a' , 128 , (5,5),[1,1,1,1] , 'SAME' ,place_info, bn_flag  , restore_flag , restore_path)\n",
    "MAX_A=MAX_POOL(A,[1,2,2,1],[1,2,2,1],'SAME','MAX_POOL_1_a',device_)\n",
    "B=CONV_1(MAX_A , device_  ,'CONV_2_a' , 184, (3,3),[1,1,1,1] , 'SAME' ,place_info, bn_flag  , restore_flag , restore_path)\n",
    "MAX_B=MAX_POOL(B,[1,2,2,1],[1,2,2,1],'SAME','MAX_POOL_2_a',device_)\n",
    "#A=STEM_A(PRE , device_,'STEM_A',(32,32,64,96) , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#B=STEM_B(A , device_,'STEM_B', place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#C=STEM_C(B , device_,'STEM_C' , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#D=INCEPTION_MODULE_A(C, device_,'MODUEL_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#E=INCEPTION_MODULE_A(D, device_,'MODUEL_A_b',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#F=INCEPTION_MODULE_A(E, device_,'MODUEL_A_c',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#G=INCEPTION_MODULE_A(F, device_,'MODUEL_A_d',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_REDUCTION_A(G,device_,'REDUCT_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_MODULE_A(G, device_,'MODUEL_A_e',place_info ,bn_flag, restore_flag , restore_path)\n",
    "flat_ = FLAT(MAX_B , device_ , layer_name='FLAT_')\n",
    "y_conv=FC_C(flat_ , 0.5 , n_classes , device_ , 'FC_C' , restore_flag , restore_path)\n",
    "print y_conv\n",
    "tensor_info=TRAIN_STRUCTURE_A(y_conv , y_ , device_ , learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "device__='/gpu:2'\n",
    "#_PRE=PRE_LAYER(images , device__,'PRE_2th',32 , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "_A=STEM_A(x_ , device__,'STEM_A_2th',(32,32,64,96) , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "_B=STEM_B(_A , device__,'STEM_B_2th', place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#_C=STEM_C(_B , device__,'STEM_C_2th' , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#_D=INCEPTION_MODULE_A(_C, device__,'MODUEL_A_a_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_E=INCEPTION_MODULE_A(_D, device__,'MODUEL_A_b_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_F=INCEPTION_MODULE_A(_E, device__,'MODUEL_A_c_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_G=INCEPTION_MODULE_A(_F, device__,'MODUEL_A_d_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_H=INCEPTION_REDUCTION_A(_G,device__,'REDUCT_A_a_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_MODULE_A(G, device_,'MODUEL_A_e',place_info ,bn_flag, restore_flag , restore_path)\n",
    "\n",
    "_flat=FLAT(_B,device__,layer_name='FLAT_2tsth')\n",
    "_y_conv=FC_C(_flat ,0.5, n_classes ,device__, 'FC_C_2th',restore_flag , restore_path)\n",
    "_tensor_info=TRAIN_STRUCTURE_A(_y_conv , y_2 , device__ , learning_rate = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-54-10a424e6d7f3>:5 in START_SESS.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess=START_SESS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step and max_acc was restore!\n",
      "global step: 500\n",
      "Max acc: 0\n",
      "\n",
      "(45, 30, 224, 224, 3)\n",
      "1.80152106285\n",
      "(142, 30, 224, 224, 3)\n",
      "5.58513402939\n",
      "(78, 30, 224, 224, 3)\n",
      "3.08822798729\n",
      "step 500 , validation  accuracy 0.591111\n",
      "step 500 , validation loss : 3.202\n",
      "step 500 , validation  accuracy 0.236385\n",
      "step 500 , validation loss : 3.99389\n",
      "step 500 , validation  accuracy 0.183333\n",
      "step 500 , validation loss : 3.09975\n",
      "step 500 , validation  accuracy 0.336943\n",
      "step 500 , validation loss : 3.43188\n",
      "-Progress : 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: DeprecationWarning: unorderable dtypes; returning scalar but in the future this will be an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Progress : 99/100(45, 30, 224, 224, 3)\n",
      "1.79490184784\n",
      "(142, 30, 224, 224, 3)\n",
      "5.53788495064\n",
      "(78, 30, 224, 224, 3)\n",
      "3.01749491692\n",
      "step 600 , validation  accuracy 0.697778\n",
      "step 600 , validation loss : 1.29149\n",
      "step 600 , validation  accuracy 0.104695\n",
      "step 600 , validation loss : 3.57172\n",
      "step 600 , validation  accuracy 0.25\n",
      "step 600 , validation loss : 2.54314\n",
      "step 600 , validation  accuracy 0.350824\n",
      "step 600 , validation loss : 2.46879\n",
      "-Progress : 99/100(45, 30, 224, 224, 3)\n",
      "1.74135899544\n",
      "(142, 30, 224, 224, 3)\n",
      "5.5360019207\n",
      "(78, 30, 224, 224, 3)\n",
      "3.05720496178\n",
      "step 700 , validation  accuracy 0.404444\n",
      "step 700 , validation loss : 2.26367\n",
      "step 700 , validation  accuracy 0.0697183\n",
      "step 700 , validation loss : 2.57101\n",
      "step 700 , validation  accuracy 0.609829\n",
      "step 700 , validation loss : 1.50617\n",
      "step 700 , validation  accuracy 0.361331\n",
      "step 700 , validation loss : 2.11362\n",
      "-Progress : 99/100(45, 30, 224, 224, 3)\n",
      "1.78488898277\n",
      "(142, 30, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "#tensorboard_info=OPEN_TENSORBOARD(sess ,tensor_info ,logdir) for tensorboard slow down ?\n",
    "#fp,dirname=make_logdir(dirname)\n",
    "BATCH_TRAINING_RANDOM(100000 ,tensor_info , place_info ,save_folder , restore_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
