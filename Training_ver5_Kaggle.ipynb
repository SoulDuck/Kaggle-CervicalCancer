{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#conv Neural Network\n",
    "# tensorboard --logdir=/home/ncc/notebook/learn/tensorboard/log\n",
    "\"\"\"\n",
    "created by kim Seong jung\n",
    "\n",
    "RESNET MODULE 2016/2/7\n",
    "CONVOLUTION MODULE 2016/2/6\n",
    "batch_normalization 적용\n",
    "3/14일 model save and restore 적용\n",
    "n_train=300 이 코드 수정하기 \n",
    "def Batch_random 에 valideation and test validate 하는 함수에 오류를 일부로 구현-->나중에 고치기 \n",
    "\n",
    "수정사항\n",
    "\n",
    "def divide_images(images , labels,batch_size):\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    image = images[ -batch_size :  ] \n",
    "    label = labels[ -batch_size :  ]\n",
    "    list_images.append(image)\n",
    "    list_labels.append(label)\n",
    "\n",
    "    return list_images,list_labels\n",
    "    2017_4/7 ver 3로 바꿈\n",
    "\n",
    "\n",
    "\n",
    "수정사항 \n",
    "tf.cond을 만들어서 처리한다.\n",
    "\"\"\"\n",
    "import sys\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images_cls(path_img_list , label_num ):\n",
    "    n_paths = len(path_img_list)\n",
    "    cls=np.zeros([n_paths])\n",
    "    cls=np.full_like(cls, label_num)\n",
    "    list_imgs=[]\n",
    "    for i , path in  enumerate(path_img_list):\n",
    "        msg = \"\\r progress {0} /{1}\".format(str(i),n_paths)\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        img=np.load(path)\n",
    "        list_imgs.append(img)\n",
    "    images=np.asarray(list_imgs)\n",
    "\n",
    "    return images , cls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Using multiProc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img=np.load(path)\n",
    "    return img\n",
    "def load_images_cls_multiproc(path_img_list , label_num ):\n",
    "    n_paths = len(path_img_list)\n",
    "    cls=np.zeros([n_paths])\n",
    "    cls=np.full_like(cls, label_num)\n",
    "    list_imgs=[]\n",
    "    pool=Pool()\n",
    "    count=0\n",
    "    for img in  pool.imap( load_img,path_img_list):\n",
    "        msg = \"\\r progress {0} /{1}\".format(str(count),n_paths)\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "        list_imgs.append(img)\n",
    "        count+=1\n",
    "    images=np.asarray(list_imgs)\n",
    "\n",
    "    return images , cls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Training , Validation , Test "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#cifar_data_format\n",
    "file_locate='/home/user01/notebook/KimLABs/cifar_dataset/npy/'\n",
    "ori_img_row = 32\n",
    "ori_img_col = 32\n",
    "in_ch =3\n",
    "n_classes=10\n",
    "img_size_cropped=28\n",
    "batch_size=60\n",
    "#for cifar_dataset\n",
    "start=time.time()\n",
    "train_imgs_list,train_labs_list=load_train_all()\n",
    "print time.time()-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_=[1,2,3]\n",
    "list_2=[3,4,5]\n",
    "type(list_) is list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_locate ='/ssd/n_vs_ab/type1/1/' #Folder data saved#WB_eye_15_PRE_A_B_C_incepAx3/\n",
    "ori_img_row = 300\n",
    "ori_img_col = 300\n",
    "in_ch =3\n",
    "n_classes=3\n",
    "img_size_cropped=288\n",
    "batch_size=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def crawl_folder(folder_path): #search_str 찾고자 하는 string \n",
    "    search_path_list=[]\n",
    "    fileList = os.walk(folder_path).next()[2]\n",
    "    subFolder_list = os.walk(folder_path).next()[1]\n",
    "    if(len(fileList)!=0):\n",
    "        for j in range(len(fileList)):\n",
    "            search_path_list.append(folder_path+'/'+fileList[j])\n",
    "    if len(subFolder_list)==0:\n",
    "        return search_path_list\n",
    "    else: \n",
    "        for i in range(len(subFolder_list)):\n",
    "            search_path_list.extend(crawl_folder(folder_path+'/'+subFolder_list[i] ))\n",
    "        return search_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnormal_path_2=crawl_folder('/ssd/normal_2/')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_path=crawl_folder('/ssd/ret/')\n",
    "normal_path_1=crawl_folder('/ssd/normal_1/')\n",
    "\"\"\"\n",
    "normal_path_2=crawl_folder('/ssd/normal_2/')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 classification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cat_imgs , cat_cls = load_images_cls(cat_path , 0)\n",
    "cat_gka_imgs , cat_gka_cls = load_images_cls(cat_gka_path , 1)\n",
    "ret_imgs , ret_cls = load_images_cls(ret_path , 2)\n",
    "ret_cat_imgs , ret_cat_cls = load_images_cls( ret_cat_path , 3)\n",
    "ret_glu_imgs , ret_glu_cls = load_images_cls(ret_glu_path , 4)\n",
    "gla_imgs , gla_cls = load_images_cls(gla_path , 5)\n",
    "normal_1_imgs , normal_1_cls = load_images_cls_multiproc(normal_path_1[:10000] , 6)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print np.shape(cat_imgs)\n",
    "print np.shape(cat_gka_imgs)\n",
    "print np.shape(ret_imgs)\n",
    "print np.shape(ret_cat_imgs)\n",
    "print np.shape(ret_glu_imgs)\n",
    "print np.shape(gla_imgs)\n",
    "print np.shape(normal_1_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " progress 6999 /7000"
     ]
    }
   ],
   "source": [
    "ret_imgs , ret_cls = load_images_cls(ret_path , 0)\n",
    "#cat_gka_imgs , cat_gka_cls = load_images_cls(cat_gka_path , 1)\n",
    "#ret_imgs , ret_cls = load_images_cls(ret_path , 1)\n",
    "#ret_cat_imgs , ret_cat_cls = load_images_cls( ret_cat_path , 3)\n",
    "#ret_glu_imgs , ret_glu_cls = load_images_cls(ret_glu_path , 4)\n",
    "#gla_imgs , gla_cls = load_images_cls(gla_path , 2)\n",
    "normal_1_imgs , normal_1_cls = load_images_cls_multiproc(normal_path_1[:7000] , 1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "normal_2_imgs , normal_2_cls = load_images_cls_multiproc(normal_path_1[10000:20000] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3359, 300, 300, 3)\n",
      "(7000, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(ret_imgs)\n",
    "#print np.shape(ret_imgs)\n",
    "#print np.shape(gla_imgs)\n",
    "print np.shape(normal_1_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cls2onehot(n_classes,list_cls):\n",
    "    tmp_list=[]\n",
    "    size=len(list_cls)\n",
    "    ret_onehot=np.zeros([size,n_classes])\n",
    "    for i , cls in enumerate(list_cls):\n",
    "        cls=int(cls)\n",
    "        ret_onehot[i,cls]=1\n",
    "    return ret_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ret_labs=cls2onehot(n_classes, ret_cls)\n",
    "#ret_labs=cls2onehot(n_classes , ret_cls)\n",
    "#gla_labs = cls2onehot(n_classes , gla_cls)\n",
    "normal_1_labs = cls2onehot(n_classes , normal_1_cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Variable , and placeholder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_= tf.placeholder(\"float\",shape=[batch_size,ori_img_row , ori_img_col , in_ch],  name = 'x-input')\n",
    "y_= tf.placeholder(\"float\",shape=[batch_size , n_classes] , name = 'y-input')\n",
    "y_cls = tf.argmax(y_ , axis = 1)\n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "#x_image= tf.reshape(x_,[-1,ori_img_row,ori_img_col,in_ch])\n",
    "phase_train= tf.placeholder(tf.bool , name='phase_train')\n",
    "bn_flag = tf.placeholder(tf.bool , name='bn_flag')\n",
    "bn_decay = tf.placeholder(\"float\")\n",
    "\n",
    "place_info={}\n",
    "place_info['x_']=x_\n",
    "place_info['y_']=y_\n",
    "place_info['keep_prob']=keep_prob\n",
    "place_info['phase_train']=phase_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image ProPrecessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function takes a single image as input,\n",
    "# and a boolean whether to build the training or testing graph.\n",
    "def pre_processing(image ):\n",
    "    def training(image):\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, in_ch])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow 0.10.0rc0 whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        #image = tf.minimum(image, 1.0)\n",
    "        #image = tf.maximum(image, 0.0)\n",
    "        return image\n",
    "    def testing(image):\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,target_height=img_size_cropped,target_width=img_size_cropped)\n",
    "        return image\n",
    "    image=tf.cond( phase_train , lambda : training(image) \\\n",
    "                  , lambda : testing(image) ,name='pre_processing')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(images, training):\n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PRE_PROCESSING(images, phase_train ,img_size_cropped  , device):\n",
    "    print \n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn( lambda image: pre_process_image(image, phase_train ,img_size_cropped  , device), images)\n",
    "    print 'distorted image\\'s shape is' , images.get_shape()\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"def weight_variable(name,shape):\n",
    "    #initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    initial = tf.get_variable(name,shape=shape , initializer = tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)\"\"\"\n",
    "def bias_variable(shape , name):\n",
    "    initial = tf.constant(0.1 , shape=shape , )\n",
    "    return tf.Variable(initial , name=name)\n",
    "\n",
    "def conv2d(x,w,strides_ , name):\n",
    "    return tf.nn.conv2d(x,w, strides = strides_, padding='SAME' , name = name)\n",
    "\n",
    "def max_pool(x , ksize , strides , padding , name ):\n",
    "    return tf.nn.max_pool(x ,ksize , strides , padding ,name=name)\n",
    "def make_weights_biases(layer_name\n",
    "                        , w_name , b_name, ksize ,device_name , initializer='xavier',\\\n",
    "                        restore_flag =False , restore_path = './WB_save'):    \n",
    "    \"\"\"\n",
    "    Doc\n",
    "    the folder include weights and bises that will be restored is located in './WB_save'\n",
    "    if you want to change save path ,  change restore_path  \n",
    "    \"\"\"\n",
    "    if len(ksize)==4: # convolution filter shape [batch , row , col , color_ch]\n",
    "        out_ch=ksize[3]\n",
    "    elif len(ksize)==2: #fully connected layer shape [in_ch , output_ch]\n",
    "        out_ch=ksize[1]\n",
    "    with tf.device(device_name):\n",
    "        with tf.variable_scope(layer_name) as scope:\n",
    "            if restore_flag==False:\n",
    "                print layer_name+' make weigths and biases'\n",
    "\n",
    "                try:\n",
    "                    w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())\n",
    "                except:\n",
    "                    scope.reuse_variables()\n",
    "                    w_conv = tf.get_variable(w_name, ksize , initializer = tf.contrib.layers.xavier_initializer())        \n",
    "                try:\n",
    "                    b_conv = bias_variable([out_ch] , name=b_name)\n",
    "                except:\n",
    "                    scope.reuse_variables()\n",
    "                    b_conv = bias_variable([out_ch],name=b_name)\n",
    "                return w_conv , b_conv\n",
    "            elif restore_flag == True:\n",
    "                print layer_name+' load weigths and biases'\n",
    "                try:\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1:0\n",
    "                        if layer_name+'_'+w_name == name:\n",
    "                            print layer_name+'_'+w_name+'was restored!!'\n",
    "                            w_conv = tf.Variable(np.load(path) , name = w_name)\n",
    "                except:\n",
    "                    scope.reuse_variables()\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1\n",
    "                        if layer_name+'_'+w_name == name:\n",
    "                            print layer_name+'_'+w_name+'was restored'\n",
    "                            w_conv = tf.Variable(np.load(path) , name = w_name)         \n",
    "                try:\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1\n",
    "                        if layer_name+'_'+b_name == name:\n",
    "                            print layer_name+'_'+b_name+'was restored!!'\n",
    "                            b_conv = tf.Variable(np.load(path),name = b_name)        \n",
    "                except:\n",
    "                    file_list=crawl_folder(restore_path)\n",
    "                    for path in file_list:\n",
    "                        name=path.split('/')[-1].split('.')[0] #Bottlenect_b_W1\n",
    "                        if layer_name+'_'+b_name == name:\n",
    "                            print layer_name+'_'+b_name+'was restored'                            \n",
    "                            b_conv = tf.Variable(np.load(path),name = b_name)        \n",
    "                return w_conv , b_conv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_conv_info( x,w_conv,b_conv,c_strides,c_pooling ):\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['name']=name\n",
    "    conv_info['b_conv']=b_conv\n",
    "    \n",
    "    \"\"\"\n",
    "    conv_info={}\n",
    "    \n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['b_conv']=b_conv\n",
    "    \n",
    "    return conv_info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def batch_norm(x, bn_decay , train_flag):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        n_out:       integer, depth of input maps\n",
    "        train_flag: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    \n",
    "    n_out = x.get_shape()[3] \n",
    "    beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                 name='beta', trainable=True)\n",
    "    gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                  name='gamma', trainable=True)\n",
    "    batch_mean, batch+\n",
    "    -3_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage(bn_decay , name=\"EMA\")\n",
    "\n",
    "    def mean_var_with_update():\n",
    "        ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "        with tf.control_dependencies([ema_apply_op]):\n",
    "            return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "    mean, var = tf.cond(train_flag,\n",
    "                        mean_var_with_update,\n",
    "                        lambda: (ema.average(batch_mean), ema.average(batch_var)) , name = 'bn_cond')\n",
    "    normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3 , name = 'batch_norm')\n",
    "    return normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bn(layer  , layer_name  ,  decay , restore_flag=False , restore_path ='./WB_save/' ):\n",
    "    #hyper parameter : decay \n",
    "    #\n",
    "    n_out = layer.get_shape()[3] \n",
    "    if restore_flag == False:\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "    elif restore_flag == True:\n",
    "        beta = tf.Variable(np.load(restore_path+layer_name+'_beta.npy') , name='beta')\n",
    "        gamma = tf.Variable(np.load(restore_path+layer_name+'_gamma.npy') , name ='gamma')\n",
    "        print layer_name+'beta was restored'\n",
    "        print layer_name+'gamma was restored'\n",
    "        \n",
    "    batch_mean, batch_var = tf.nn.moments(layer, [0,1,2], name='moments')\n",
    "    ema = tf.train.ExponentialMovingAverage( decay , name=\"EMA\")\n",
    "    ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "    ema_mean=ema.average(batch_mean) ;ema_var=ema.average(batch_var) \n",
    "    layer_BN = tf.nn.batch_normalization(layer, batch_mean, batch_var, beta, gamma, 1e-3 , name = 'BN')    \n",
    "    layer_relu=tf.nn.relu(layer_BN ,name='bn_relu')\n",
    "    return layer_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convolution(conv_info , place_info , bn_flag , layer_name , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    place_info['x_']=x_\n",
    "    place_info['y_']=y_\n",
    "    place_info['keep_prob']=keep_prob\n",
    "    place_info['train_flag'] =train_flag\n",
    "    place_info['bn_flag'] =bn_flag\n",
    "    place_info['bn_decay'] = bn_decay\n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['name']=name\n",
    "    conv_info['b_conv']=b_conv    \n",
    "    \"\"\"\n",
    "    with tf.variable_scope(layer_name) as scope:\n",
    "        layer = tf.nn.conv2d(conv_info['x'] , conv_info['w_conv'] , conv_info['c_strides'] ,\\\n",
    "                             conv_info['c_pooling'] ,name='conv')+conv_info['b_conv']\n",
    "        if bn_flag==True:\n",
    "            layer_relu=bn(layer , layer_name , 0.999 , restore_flag , restore_path)\n",
    "        if bn_flag==False:\n",
    "            layer_relu=tf.nn.relu(layer ,name='no_bn_relu')\n",
    "        layer_drop = tf.nn.dropout(layer_relu,place_info['keep_prob'] , name='dropout')\n",
    "        return layer_drop        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PRE_LAYER(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    place_info['x_']=x_\n",
    "    place_info['y_']=y_\n",
    "    place_info['keep_prob']=keep_prob\n",
    "    place_info['train_flag'] =train_flag\n",
    "    place_info['bn_flag'] = train_flag\n",
    "    place_info['bn_decay'] = bn_decay\n",
    "    conv\n",
    "    \"\"\"\n",
    "    in_ch = x.get_shape()[3]\n",
    "    out_ch=n_nodes\n",
    "    c_ksize=[7,7 , in_ch, out_ch]\n",
    "    c_pooling ='SAME'\n",
    "    c_strides=[1,2,2,1] # when downsampling featrue map , set strides parameter,[1,2,2,1]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W' ,'B' , c_ksize ,device_ ,'xavier',restore_flag ,  restore_path )\n",
    "    conv_info=make_conv_info(x, w_conv, b_conv, c_strides, c_pooling)\n",
    "    layer1=convolution(conv_info , place_info , bn_flag , layer_name+'_L' , restore_flag , restore_path)   \n",
    "    p_ksize=[1,3,3,1]\n",
    "    p_strides=[1,2,2,1]\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer2 = tf.nn.max_pool(layer1 ,p_ksize, c_strides , c_pooling , name='maxpool')\n",
    "    print layer2.get_shape()\n",
    "    return layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RES_2(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    out_ch1 , out_ch2 = n_nodes\n",
    "    out_ch1 , out_ch2=n_nodes\n",
    "    conv_info['x']=x\n",
    "    conv_info['w_conv']=w_conv\n",
    "    conv_info['c_strides']=c_strides\n",
    "    conv_info['c_pooling']=c_pooling\n",
    "    conv_info['name']=name\n",
    "    conv_info['b_conv']=b_conv\n",
    "    문제는 형이 변할때인데 이미지가 축소할때 기본의  x는 이미지를 살려서 패치를 해야 한다,\n",
    "    그것을 텐서 플로어를 이용해서 해야 한다는 것이다.    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \"\"\"만약 입력한 영상의 row와 또는 col이 layer2의 row 또는 col과 다르다면 padding 을 시켜야 한다.\n",
    "    넘어갈때는 폴링을 시키는것이 아니라 1x1 conv 에 1,2,2,1 스트라이드를 시키는지는 정확히 모르겠다\n",
    "    또 논문에 보면 차원이 늘어날때 extra padding 이라고 하는데 단순히 zeropadding을 뒤에 붙이는건지는\n",
    "    잘 모르겠다. 어짜피 뒤에 있는 레이어와 더해져 문제 될것 같지는 않은데 잘 모르겠다.\n",
    "    \"\"\"\n",
    "\n",
    "    #pad_row=int((x.get_shape()[1]-layer2.get_shape()[1])/2)\n",
    "    #pad_col=int((x.get_shape()[2]-layer2.get_shape()[2])/2)\n",
    "\n",
    "    \"\"\"add padding \n",
    "    아직 구현 미완료\n",
    "    x_padded=tf.pad(x,paddings=[[pad_col,pad_col],[pad_row,pad_row]],mode=\"CONSTANT\",name=layer_name+'x_padded')\n",
    "    x_padded=tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1],padding='SAME' , name=layer_name+'x_padded')\n",
    "    x_ch=int(x_padded.get_shape()[3])\n",
    "    print x_padded.get_shape()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #여기에 batch  가 들어가야 한다.\n",
    "\n",
    "    \"\"\"\n",
    "    여기에만 Batch Normalization 을 추가하는 게 좋을까 \n",
    "    아니면 다른곳에도 batch normalization 을 추가하는게 좋을까?\n",
    "    그리고 이것을 어떻게 수식으로 표현할수 있을까?\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    in_ch = x.get_shape()[3]\n",
    "\n",
    "    out_ch1,out_ch2=n_nodes\n",
    "    out_ch_shortcut = out_ch2\n",
    "    \n",
    "    c_ksize1=[3,3 , in_ch   , out_ch1]\n",
    "    c_ksize2=[3,3 , out_ch1 , out_ch2]\n",
    "    c_ksize_shortcut = [1,1,in_ch,out_ch2]\n",
    "    \n",
    "    c_strides1=strides # when downsampling featrue map , set strides parameter,[1,2,2,1]\n",
    "    c_strides2=[1,1,1,1]\n",
    "    c_strides_shortcut=strides\n",
    "    \n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='SAME'\n",
    "    c_pooling_shortcut=\"SAME\"\n",
    "    \n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+'_1', 'W' ,'B' ,c_ksize1 ,device_ ,'xavier',restore_flag , restore_path )\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+'_2', 'W' ,'B' , c_ksize2 ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    w_conv_shortcut , b_conv_shortcut =make_weights_biases(layer_name+'shortcut', 'W' ,'B' , c_ksize_shortcut ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)    \n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag ,layer_name+'_L1' , restore_flag , restore_path)   \n",
    "\n",
    "    conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info_2 , place_info , bn_flag, layer_name+'_L2' , restore_flag , restore_path)\n",
    "\n",
    "    conv_info_shortcut = make_conv_info(x, w_conv_shortcut, b_conv_shortcut, c_strides_shortcut, c_pooling_shortcut)\n",
    "    layer_shortcut=convolution(conv_info_shortcut , place_info , bn_flag , layer_name+'Lshortcut' , restore_flag , restore_path)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_sum=tf.add(layer2 ,layer_shortcut , name=\"add\")    \n",
    "        layer_sum_relu=tf.nn.relu(layer_sum , name=layer_name+\"relu\")    \n",
    "    print layer_sum_relu.get_shape()\n",
    "\n",
    "    return layer_sum_relu\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BOTTLENECT(x , device_,layer_name,n_nodes , strides , bn_flag , restore_flag  , restore_path ):\n",
    "    \"\"\"\n",
    "    usage:\n",
    "    n_nodes=(n_nodes[0],n_nodes[1],n_nodes[2])\n",
    "    out_ch1 , out_ch2 , out_ch3 = n_nodes\n",
    "    \"\"\"\n",
    "    \"\"\"만약 입력한 영상의 row와 또는 col이 layer2의 row 또는 col과 다르다면 padding 을 시켜야 한다.\n",
    "    넘어갈때는 폴링을 시키는것이 아니라 1x1 conv 에 1,2,2,1 스트라이드를 시키는지는 정확히 모르겠다\n",
    "    또 논문에 보면 차원이 늘어날때 extra padding 이라고 하는데 단순히 zeropadding을 뒤에 붙이는건지는\n",
    "    잘 모르겠다. 어짜피 뒤에 있는 레이어와 더해져 문제 될것 같지는 않은데 잘 모르겠다.\n",
    "    \"\"\"\n",
    "\n",
    "    #pad_row=int((x.get_shape()[1]-layer2.get_shape()[1])/2)\n",
    "    #pad_col=int((x.get_shape()[2]-layer2.get_shape()[2])/2)\n",
    "\n",
    "    \"\"\"add padding \n",
    "    아직 구현 미완료\n",
    "    x_padded=tf.pad(x,paddings=[[pad_col,pad_col],[pad_row,pad_row]],mode=\"CONSTANT\",name=layer_name+'x_padded')\n",
    "    x_padded=tf.nn.max_pool(x,[1,2,2,1],[1,2,2,1],padding='SAME' , name=layer_name+'x_padded')\n",
    "    x_ch=int(x_padded.get_shape()[3])\n",
    "    print x_padded.get_shape()\n",
    "\n",
    "    \"\"\"\n",
    "    ############################# layer4 #############################\n",
    "\n",
    "    #여기에 batch  가 들어가야 한다.\n",
    "\n",
    "    \"\"\"\n",
    "    여기에만 Batch Normalization 을 추가하는 게 좋을까 \n",
    "    아니면 다른곳에도 batch normalization 을 추가하는게 좋을까?\n",
    "    그리고 이것을 어떻게 수식으로 표현할수 있을까?\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #############################layer1#############################\n",
    "    in_ch = x.get_shape()[3]\n",
    "    \n",
    "    out_ch1,out_ch2,out_ch3=n_nodes\n",
    "    c_ksize1=[1,1 , in_ch   , out_ch1]\n",
    "    c_ksize2=[3,3 , out_ch1 , out_ch2]\n",
    "    c_ksize3=[1,1 , out_ch2 , out_ch3]\n",
    "    c_ksize_shortcut=[1,1,in_ch,out_ch3]\n",
    "    \n",
    "    c_pooling1=\"SAME\";c_strides1=strides;\n",
    "    c_pooling2=\"SAME\";c_strides2=[1,1,1,1];\n",
    "    c_pooling3=\"SAME\";c_strides3=[1,1,1,1];\n",
    "    c_pooling_shortcut=\"SAME\";c_strides_shortcut=strides;\n",
    "    \n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+'_1', 'W' ,'B' ,c_ksize1 ,device_ ,'xavier',restore_flag , restore_path  )\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+'_2', 'W' ,'B' ,c_ksize2 ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+'_3', 'W' ,'B' ,c_ksize3 ,device_ ,'xavier',restore_flag , restore_path)\n",
    "    w_conv_shortcut , b_conv_shortcut =make_weights_biases(layer_name+'_shortcut', 'W' ,'B' ,c_ksize_shortcut,device_,'xavier',restore_flag,restore_path)\n",
    "    \n",
    "    \n",
    "    conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1) \n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info_2, place_info , bn_flag , layer_name+'_L2',restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_3=make_conv_info(layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "    layer3=convolution(conv_info_3, place_info , bn_flag , layer_name+'_L3',restore_flag , restore_path)\n",
    "    \n",
    "    conv_info_shortcut = make_conv_info(x, w_conv_shortcut, b_conv_shortcut, c_strides_shortcut, c_pooling_shortcut)\n",
    "    layer_shortcut=convolution(conv_info_shortcut , place_info , bn_flag , layer_name+'_Lshortcut',restore_flag , restore_path)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope: \n",
    "        layer_sum=tf.add(layer3 ,layer_shortcut , name=\"sum\")\n",
    "    print layer_sum.get_shape()\n",
    "    return layer_sum\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTION_NET_V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_A(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\" \n",
    "        standard = 32;32;64;96\n",
    "        out_ch1 , out_ch2 , out_ch3 , out_ch4 =n_nodes   \n",
    "        out_ch1=n_nodes[0]\n",
    "        c_ksize1=[1,1 , in_ch   , out_ch1]\n",
    "        c_strides1=strides;c_pooling1=\"SAME\"\n",
    "        w_conv1 , b_conv1 =make_weights_biases\\\n",
    "        (layer_name+'_1', 'W' ,'B' ,c_ksize1 ,device_ ,'xavier',restore_flag , restore_path  )\n",
    "        conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "        layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_1_bn' ,restore_flag , restore_path)\n",
    "\n",
    "    \"\"\"    \n",
    "    with tf.device(device_):\n",
    "        out_ch1=32;out_ch2=32;out_ch3=64;out_ch4 =96\n",
    "        in_ch=x.get_shape()[3]\n",
    "        \n",
    "        ################################## layer 1 ##################################  \n",
    "        c_ksize1=[3,3,in_ch , out_ch1]\n",
    "        c_strides1=[1,2,2,1]\n",
    "        c_pooling1='VALID'\n",
    "        w_conv1 , b_conv1 =make_weights_biases(layer_name+'_1' , 'W' ,'B', c_ksize1 , device_,'xavier',restore_flag,  restore_path)\n",
    "        conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "        layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)        \n",
    "        ################################## layer 2 ##################################  \n",
    "        c_ksize2=[3,3,out_ch1,out_ch2]\n",
    "        w_conv2 , b_conv2= make_weights_biases(layer_name+'_2' , 'W' ,'B', c_ksize2 , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides2=[1,1,1,1];c_pooling2='VALID'\n",
    "        conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "        layer2=convolution(conv_info_2 , place_info , bn_flag , layer_name+'_L2' ,restore_flag , restore_path)\n",
    "        ################################## layer 3 ##################################  \n",
    "        c_ksize3=[3,3,out_ch2 , out_ch3]\n",
    "        w_conv3 , b_conv3= make_weights_biases(layer_name+'_3' , 'W' ,'B' ,c_ksize3 , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_pooling3='SAME'\n",
    "        conv_info_3=make_conv_info(layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "        layer3=convolution(conv_info_3 , place_info , bn_flag , layer_name+'_L3' ,restore_flag , restore_path)\n",
    "        ################################## layer 4 ##################################  \n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv4 , b_conv4= make_weights_biases(layer_name+'_4' , 'W' ,'B', c_ksize4 , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides4=[1,2,2,1]\n",
    "        c_pooling4='VALID'\n",
    "        conv_info_4=make_conv_info(layer3, w_conv4, b_conv4, c_strides4, c_pooling4)\n",
    "        layer4=convolution(conv_info_4 , place_info , bn_flag , layer_name+'_L4' ,restore_flag , restore_path)\n",
    "        ################################## layer 4 brach ##################################          \n",
    "        b_p_ksize4=[1,3,3,1]\n",
    "        b_p_strides4=[1,2,2,1]\n",
    "        b_p_padding4 ='VALID'\n",
    "        with tf.variable_scope('b_'+layer_name+'_4') as scope:\n",
    "            b_layer4=tf.nn.max_pool(layer3 , b_p_ksize4, b_p_strides4, b_p_padding4 ,name='max_pool') #b is branch\n",
    "            b_layer4_relu=tf.nn.relu(b_layer4 , name = 'relu')\n",
    "        with tf.variable_scope(layer_name+'_end') as scope:\n",
    "            concat_layer=tf.concat(3 , [layer4 , b_layer4_relu] , name='CONCAT')\n",
    "        return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_B(x,device_,layer_name , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    stardard =>64,64,64,96 \n",
    "    b_out_ch1,b_out_ch2=64, 96\n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #################################################################################\n",
    "        out_ch1=64;out_ch2=64;out_ch3=64;out_ch4=96; \n",
    "        ##############################right side layer 1##################################\n",
    "        c_ksize1=[1,1,in_ch,out_ch1]\n",
    "        w_conv1 , b_conv1=make_weights_biases(layer_name+'_1' , 'W' ,'B', c_ksize1 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides1=[1,1,1,1]\n",
    "        c_pooling1='SAME'\n",
    "        conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "        layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)\n",
    "        ##############################right side layer 2##################################\n",
    "        c_ksize2=[7,1,out_ch1 , out_ch2]\n",
    "        w_conv2 , b_conv2= make_weights_biases(layer_name+'_2' , 'W' ,'B',c_ksize2 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides2=[1,1,1,1]\n",
    "        c_pooling2='SAME'\n",
    "        conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "        layer2=convolution(conv_info_2 , place_info , bn_flag , layer_name+'_L2' ,restore_flag , restore_path)\n",
    "        ##############################right side layer 3##################+################\n",
    "        c_ksize3=[1,7,out_ch2 , out_ch3]\n",
    "        w_conv3 , b_conv3= make_weights_biases(layer_name+'_3' , 'W' ,'B',c_ksize3 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides3=[1,1,1,1]\n",
    "        c_pooling3='SAME'\n",
    "        conv_info_3=make_conv_info(layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "        layer3=convolution(conv_info_3 , place_info , bn_flag , layer_name+'_L3' ,restore_flag , restore_path)\n",
    "        ##############################right side layer 4##################################\n",
    "        c_ksize4=[3,3,out_ch3 , out_ch4]\n",
    "        w_conv4 , b_conv4= make_weights_biases(layer_name+'_4' , 'W' ,'B', c_ksize4 , device_ ,'xavier',restore_flag,restore_path)\n",
    "        c_strides4=[1,1,1,1]\n",
    "        c_pooling4='VALID'\n",
    "        conv_info_4=make_conv_info(layer3, w_conv4, b_conv4, c_strides4, c_pooling4)\n",
    "        layer4=convolution(conv_info_4 , place_info , bn_flag , layer_name+'_L4' ,restore_flag , restore_path)\n",
    "        ##############################left side##################################\n",
    "        b_out_ch1=64;b_out_ch2=96\n",
    "        ##############################layer_1_branch####################################\n",
    "        \n",
    "        b_c_ksize1=[1,1,in_ch , b_out_ch1]\n",
    "        b_w_conv1 , b_b_conv1 =make_weights_biases('b_'+layer_name+'_1', 'W' , 'B', b_c_ksize1 ,device_,'xavier',restore_flag,restore_path)\n",
    "        b_c_strides1=[1,1,1,1]\n",
    "        b_c_pooling1='SAME'\n",
    "        b_conv_info1=make_conv_info(x, b_w_conv1, b_b_conv1, b_c_strides1, b_c_pooling1)\n",
    "        b_layer_1=convolution(b_conv_info1 , place_info , bn_flag , 'b_'+layer_name+'_L1' ,restore_flag , restore_path)\n",
    "        ##############################layer_2_branch####################################'b_'+\n",
    "        \n",
    "        b_c_ksize2=[3,3,b_out_ch1 , b_out_ch2]\n",
    "        b_w_conv2 , b_b_conv2= make_weights_biases('b_'+layer_name+'_2' , 'W' , 'B',b_c_ksize2 ,device_,'xavier',restore_flag,  restore_path)\n",
    "        b_c_strides2=[1,1,1,1]\n",
    "        b_c_pooling2='VALID'\n",
    "        b_conv_info_2=make_conv_info(b_layer_1, b_w_conv2, b_b_conv2, b_c_strides2, b_c_pooling2)\n",
    "        b_layer_2=convolution(b_conv_info_2 , place_info , bn_flag , 'b_'+layer_name+'_L2' ,restore_flag , restore_path)        \n",
    "        ##############################concatenate layers###########################\n",
    "        with tf.variable_scope(layer_name+'end') as scope:\n",
    "            concat_layer=tf.concat(3 , [layer4 , b_layer_2] , name=\"CONCAT\")\n",
    "    return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def STEM_C( x , device_,layer_name , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    out_ch = n_nodes\n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "        in_ch=x.get_shape()[3]\n",
    "        #########################################################################\n",
    "        out_ch = 192\n",
    "        c_ksize=[3,3,in_ch,out_ch]\n",
    "        w_conv_1 , b_conv_1 =make_weights_biases(layer_name+'_1' , 'W' , 'B',c_ksize , device_,'xavier',restore_flag,  restore_path)\n",
    "        c_strides=[1,1,1,1]\n",
    "        c_pooling='SAME'\n",
    "        conv_info=make_conv_info(x,w_conv_1 , b_conv_1, c_strides, c_pooling)\n",
    "        layer=convolution(conv_info , place_info , bn_flag , layer_name+'_L1' ,restore_flag , restore_path)\n",
    "\n",
    "        #########################################################################\n",
    "        \n",
    "        b_p_ksize=[1,2,2,1]\n",
    "        b_p_strides=[1,1,1,1]\n",
    "        b_p_pooling='SAME'\n",
    "        with tf.variable_scope(layer_name+'_L2') as scope:\n",
    "            b_layer = tf.nn.max_pool(layer , b_p_ksize , b_p_strides , b_p_pooling,name='max_pool' )\n",
    "            b_layer_relu = tf.nn.relu(b_layer,name='relu')\n",
    "        #########################################################################\n",
    "        with tf.variable_scope(layer_name+'end') as scope:        \n",
    "            concat_layer=tf.concat(3,[layer , b_layer_relu] , name = 'concat')\n",
    "    return concat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_A(x , device_,layer_name, place_info  , bn_flag  , restore_flag , restore_path):\n",
    "\n",
    "    \"\"\"\n",
    "    out_ch1,out_ch2=n_nodes\n",
    "    input X shape is [n_batch , row , col, out_ch]\n",
    "    35 x 35 grid\n",
    "    \"\"\"\n",
    "    #######################################layer1##########################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1=64 ;c_strides1=[1,1,1,1];c_ksize1=[1,1,in_ch,out_ch1];c_pooling1='SAME'\n",
    "    out_ch2=96 ;c_strides2=[1,1,1,1];c_ksize2=[3,3,out_ch1,out_ch2];c_pooling2='SAME'\n",
    "             \n",
    "    w_conv1 , b_conv1 = make_weights_biases(layer_name+'_1', 'W', 'B',c_ksize1,device_,'xavier',restore_flag,restore_path)\n",
    "    w_conv2 , b_conv2 = make_weights_biases(layer_name+'_2' ,'W' ,'B',c_ksize2,device_,'xavier',restore_flag,restore_path)\n",
    "    \n",
    "    conv_info_1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag , layer_name+'_L1',restore_flag , restore_path)\n",
    "    conv_info_2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info_2 , place_info , bn_flag , layer_name+'_L2',restore_flag , restore_path)\n",
    "    ####################################layer_1_branch#############################################                     \n",
    "\n",
    "    b1_p_ksize=[1,2,2,1];b1_p_strides=[1,1,1,1];b1_p_pooling='SAME'\n",
    "    with tf.variable_scope('b1_'+layer_name+'_1') as scope:\n",
    "        b1_layer1      =tf.nn.avg_pool(x, b1_p_ksize , b1_p_strides,b1_p_pooling ,name='avg_pool')\n",
    "        b1_layer1_relu =tf.nn.relu(b1_layer1,name='relu')\n",
    "    b1_out_ch=96\n",
    "    b1_c_ksize=[1,1, in_ch , b1_out_ch]\n",
    "    b1_c_strides=[1,1,1,1]\n",
    "    b1_c_pooling ='SAME'\n",
    "    b1_w_conv,b1_b_conv=make_weights_biases('b1_'+layer_name,'W','B',b1_c_ksize , device_ ,'xavier',restore_flag,  restore_path)                \n",
    "    b1_conv_info=make_conv_info(b1_layer1_relu,b1_w_conv,b1_b_conv,b1_c_strides, b1_c_pooling)\n",
    "    b1_layer=convolution(b1_conv_info , place_info , bn_flag , 'b1_'+layer_name+'_L' ,restore_flag,  restore_path)\n",
    "\n",
    "    ####################################layer_2_branch#############################################                     \n",
    "\n",
    "    b2_out_ch=96;b2_c_ksize=[1,1,in_ch,b2_out_ch];b2_c_strides=[1,1,1,1];b2_c_pooling='SAME'\n",
    "    b2_w_conv , b2_b_conv=make_weights_biases('b2_'+layer_name,'W','B',b2_c_ksize , device_ ,'xavier',restore_flag, restore_path)\n",
    "    b2_conv_info=make_conv_info(x, b2_w_conv, b2_b_conv, b2_c_strides, b2_c_pooling)\n",
    "    b2_layer=convolution(b2_conv_info , place_info , bn_flag , 'b2_'+layer_name+'_L',restore_flag,  restore_path)\n",
    "    ####################################layer_3_branch#############################################                     \n",
    "\n",
    "    b3_out_ch1=64;b3_c_ksize1 =[1,1,     in_ch , b3_out_ch1];b3_c_strides1=[1,1,1,1];b3_c_pooling1='SAME'\n",
    "    b3_out_ch2=96;b3_c_ksize2 =[3,3,b3_out_ch1 , b3_out_ch2];b3_c_strides2=[1,1,1,1];b3_c_pooling2='SAME'\n",
    "    b3_out_ch3=96;b3_c_ksize3 =[3,3,b3_out_ch2 , b3_out_ch3];b3_c_strides3=[1,1,1,1];b3_c_pooling3='SAME'\n",
    "    \n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('b3_'+layer_name+'_1','W','B',b3_c_ksize1 , device_ ,'xavier',restore_flag,  restore_path)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('b3_'+layer_name+'_2','W','B',b3_c_ksize2 , device_ ,'xavier',restore_flag,  restore_path)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('b3_'+layer_name+'_3','W','B',b3_c_ksize3 , device_ ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info1=make_conv_info(x, b3_w_conv1, b3_b_conv1, b3_c_strides1, b3_c_pooling1)\n",
    "    b3_layer_1=convolution(b3_conv_info1 , place_info , bn_flag ,'b3_'+layer_name+'_L1' ,restore_flag,  restore_path)\n",
    "    b3_conv_info2=make_conv_info(b3_layer_1, b3_w_conv2, b3_b_conv2, b3_c_strides2, b3_c_pooling2)    \n",
    "    b3_layer_2=convolution(b3_conv_info2 , place_info , bn_flag ,'b3_'+layer_name+'_L2' ,restore_flag, restore_path)\n",
    "    b3_conv_info3=make_conv_info(b3_layer_2, b3_w_conv3, b3_b_conv3, b3_c_strides3, b3_c_pooling3)\n",
    "    b3_layer_3=convolution(b3_conv_info3 , place_info , bn_flag , 'b3_'+layer_name+'_L3' ,restore_flag,  restore_path)\n",
    "\n",
    "    #################################################################################                     \n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_concat=tf.concat(3,[layer2,b1_layer ,b2_layer,b3_layer_3 ],name = 'concat')\n",
    "        print layer_concat\n",
    "    return layer_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_B(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "\n",
    "    \"\"\"\n",
    "    for 17 X 17 grid \n",
    "    \"\"\"\n",
    "    in_ch =x.get_shape()[3]\n",
    "    out_ch1 =192 ; out_ch2=224; out_ch3 =256\n",
    "    c_ksize1 = [1,1, in_ch  ,out_ch1]\n",
    "    c_ksize2 = [1,7, out_ch1,out_ch2]\n",
    "    c_ksize3 = [7,1, out_ch2,out_ch3]\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases( layer_name+'_1','W' ,'B', c_ksize1 , device)\n",
    "    w_conv2 , b_conv2 =make_weights_biases( layer_name+'_2','W' ,'B', c_ksize2 , device)\n",
    "    w_conv3 , b_conv3 =make_weights_biases( layer_name+'_3','W' ,'B', c_ksize3 , device)\n",
    "    \n",
    "    c_strides1 =[1,1,1,1]\n",
    "    c_strides2 =[1,1,1,1]\n",
    "    c_strides3 =[1,1,1,1]\n",
    "    \n",
    "    c_pooling1 ='SAME'\n",
    "    c_pooling2 ='SAME'\n",
    "    c_pooling3 ='SAME'\n",
    "\n",
    "    conv_info1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer_1=convolution(conv_info_1 , place_info , bn_flag ,layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2=make_conv_info(layer_1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer_2=convolution(conv_info2 , place_info , bn_flag ,layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info3=make_conv_info(x, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "    layer_3=convolution(conv_info3 , place_info , bn_flag ,layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "\n",
    "    #####################################layer_1_branch############################################ \n",
    "    b1_p_ksize=[1,2,2,1]\n",
    "    b1_p_strides=[1,1,1,1]\n",
    "    b1_p_pooling ='SAME'\n",
    "    with tf.variable_scope(layer_name+'b1_layer1') as scope:\n",
    "        b1_layer1      =tf.nn.avg_pool(x , b1_p_ksize , b1_p_strides , b1_p_pooling ,name='conv')\n",
    "        b1_layer1_relu =tf.nn.relu(b1_layer1,name='relu')\n",
    "\n",
    "    b1_out_ch2 = 128\n",
    "    b1_c_ksize2=[1,1,in_ch,b1_out_ch]\n",
    "    b1_w_conv2 , b1_b_conv2 = make_weights_biases('b1_'+layer_name,'W','B',b1_c_ksize, device )\n",
    "    b1_c_strides2=[1,1,1,1]\n",
    "    b1_c_pooling2='SAME'\n",
    "    b1_conv_info2=make_conv_info(b1_layer1_relu , b1_w_conv2, b1_b_conv2, b1_c_strides2, b1_c_pooling2)\n",
    "    b1_layer2=convolution(b1_conv_info2 , place_info , bn_flag ,layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    #####################################layer_2_branch############################################ \n",
    "    b2_out_ch=384\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv =make_weights_biases('b2_'+layer_name,'W','B',b2_c_ksize , device)\n",
    "    b2_c_strides=[1,1,1,1]\n",
    "    b2_c_pooling='SAME'\n",
    "    b2_conv_info=make_conv_info(x , b2_w_conv, b1_b_conv, b2_c_strides, b2_c_pooling)\n",
    "    b2_layer=convolution(b2_conv_info , place_info , bn_flag ,layer_name+'_L' ,'xavier',restore_flag,  restore_path)\n",
    "    #####################################layer_3_branch############################################ \n",
    "\n",
    "\n",
    "    b3_out_ch1=192; b3_out_ch2 =192; b3_out_ch3=224 ; b3_out_ch4=224 ; b3_out_ch5 =256\n",
    "    b3_c_ksize1=[1,1,in_ch,b3_out_ch1]\n",
    "    b3_c_ksize2=[1,7,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3=[7,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4=[1,7,b3_out_ch3 , b3_out_ch4]\n",
    "    b3_c_ksize5=[7,1,b3_out_ch4 , b3_out_ch5]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1=make_weights_biases('b3_'+layer_name+'_1','W','B',b3_c_ksize1, device)\n",
    "    b3_w_conv2 , b3_b_conv2=make_weights_biases('b3_'+layer_name+'_2','W','B',b3_c_ksize2, device)\n",
    "    b3_w_conv3 , b3_b_conv3=make_weights_biases('b3_'+layer_name+'_3','W','B',b3_c_ksize3, device)\n",
    "    b3_w_conv4 , b3_b_conv4=make_weights_biases('b3_'+layer_name+'_4','W','B',b3_c_ksize4, device)\n",
    "    b3_w_conv5 , b3_b_conv5=make_weights_biases('b3_'+layer_name+'_5','W','B',b3_c_ksize5, device)\n",
    "    \n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4=[1,1,1,1]\n",
    "    b3_c_strides5=[1,1,1,1]\n",
    "    \n",
    "    b3_c_pooling1=\"SAME\"\n",
    "    b3_c_pooling2=\"SAME\"\n",
    "    b3_c_pooling3=\"SAME\"\n",
    "    b3_c_pooling4=\"SAME\"\n",
    "    b3_c_pooling5=\"SAME\"\n",
    "    \n",
    "    b3_conv_info1=make_conv_info(x , b3_w_conv1, b3_b_conv1, b3_c_strides1, b3_c_pooling1)\n",
    "    b3_layer1=convolution(b3_conv_info1 , place_info , bn_flag ,'b3_'+layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info2=make_conv_info(b3_layer1 , b3_w_conv2, b3_b_conv2, b3_c_strides2, b2_c_pooling)\n",
    "    b3_layer2=convolution(b3_conv_info2 , place_info , bn_flag ,'b3_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info3=make_conv_info(b3_layer2 , b3_w_conv3, b3_b_conv3, b3_c_strides3, b2_c_pooling)\n",
    "    b3_layer3=convolution(b3_conv_info3 , place_info , bn_flag ,'b3_'+layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info4=make_conv_info(b3_layer3 , b3_w_conv4, b3_b_conv4, b3_c_strides4, b2_c_pooling)\n",
    "    b3_layer4=convolution(b3_conv_info4 , place_info , bn_flag ,'b3_'+layer_name+'_L4' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info5=make_conv_info(b3_layer4 , b3_w_conv5, b3_b_conv5, b3_c_strides5, b2_c_pooling)\n",
    "    b3_layer5=convolution(b3_conv_info5 , place_info , bn_flag ,'b3_'+layer_name+'_L5' ,'xavier',restore_flag,  restore_path)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_concat=tf.concat(3, [layer_3 , b1_layer2 ,b2_layer ,b3_layer5] ,name='concat')\n",
    "    return layer_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_MODULE_C(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "\n",
    "    \"\"\"\n",
    "    for 8 X 8 grid modules\n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    \n",
    "    out_ch1 = 384 ; out_ch2_a =256 ;out_ch2_b = 256\n",
    "    c_ksize1 = [1,1,in_ch , out_ch1]\n",
    "    c_ksize2_a = [1,3,out_ch1 , out_ch2_a]\n",
    "    c_ksize2_b = [3,1,out_ch1 , out_ch2_b]\n",
    "    w_conv1 ,b_conv1=make_weights_biases(layer_name+'_1','W','B', c_ksize1 ,device)\n",
    "    w_conv2_a ,b_conv2_a=make_weights_biases(layer_name+'_2_a','W','B', c_ksize2_a ,device)\n",
    "    w_conv2_b ,b_conv2_b=make_weights_biases(layer_name+'_2_b','_W_b','_B_b', c_ksize2_b ,device)\n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2_a=[1,1,1,1]\n",
    "    c_strides2_b=[1,1,1,1]\n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2_a='SAME'\n",
    "    c_pooling2_b='SAME'\n",
    "    conv_info1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer1=convolution(conv_info_1 , place_info , bn_flag ,layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2_a=make_conv_info(layer_1, w_conv2_a, b_conv2_a, c_strides2_a, c_pooling2_a)\n",
    "    layer2_a=convolution(conv_info2_a , place_info , bn_flag ,layer_name+'_L2_a' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2_b=make_conv_info(layer_1, w_conv2_b, b_conv2_b, c_strides2_b, c_pooling2_b)\n",
    "    layer2_b=convolution(conv_info2_b , place_info , bn_flag ,layer_name+'_L2_b' ,'xavier',restore_flag,  restore_path)\n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b1_p_ksize1=[1,2,2,1]\n",
    "    b1_p_strides1=[1,1,1,1]\n",
    "    b1_p_pooling1='SAME'\n",
    "    with tf.variable_scope('b1_'+layer_name+'_1') as scope:    \n",
    "        b1_layer1     = tf.nn.avg_pool(x , b1_p_ksize1 , b1_p_strides1 , b1_p_pooling1 , name='avg_pool')\n",
    "        b1_layer1_relu= tf.nn.relu(b1_layer1 , name='relu')\n",
    "\n",
    "    b1_out_ch2 =256\n",
    "    b1_c_ksize2=[1,1,in_ch , b1_out_ch]\n",
    "    b1_w_conv2 , b1_b_conv2= make_weights_biases('b1_'+layer_name+'_2', 'W' ,'B', b1_c_ksize , device)\n",
    "    b1_c_pooling2 = 'SAME';b1_c_strides = [1,1,1,1];\n",
    "    b1_conv_info2=make_conv_info(x, b1_w_conv2, b1_b_conv2, b1_c_strides, b1_c_pooling2)\n",
    "    b1_layer2=convolution(b1_conv_info2 , place_info , bn_flag ,'b1_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    ################################################################################# \n",
    "    b2_out_ch=256\n",
    "    b2_c_ksize=[1,1,in_ch,b2_out_ch]\n",
    "    b2_w_conv , b2_b_conv= make_weights_biases('b2_'+layer_name , 'W' , 'B',b2_c_ksize , device)\n",
    "    b2_c_pooling = 'SAME';b2_c_strides=[1,1,1,1];\n",
    "    b2_conv_info=make_conv_info(x, b1_w_conv2, b1_b_conv2, b1_c_strides, b1_c_pooling2)\n",
    "    b2_layer2=convolution(b2_conv_info , place_info , bn_flag ,'b2_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "   \n",
    "    ################################################################################# \n",
    "\n",
    "\n",
    "    b3_out_ch1=384;b3_out_ch2=448;b3_out_ch3=512;b3_out_ch4_a=256;b3_out_ch4_b=256\n",
    "    b3_c_ksize1 =[1,1,in_ch , b3_out_ch1]\n",
    "    b3_c_ksize2 =[1,3,b3_out_ch1 , b3_out_ch2]\n",
    "    b3_c_ksize3 =[3,1,b3_out_ch2 , b3_out_ch3]\n",
    "    b3_c_ksize4_a =[3,1,b3_out_ch3 , b3_out_ch4_a]\n",
    "    b3_c_ksize4_b =[1,3,b3_out_ch3, b3_out_ch4_b]\n",
    "\n",
    "    b3_w_conv1 , b3_b_conv1 = make_weights_biases('b3_'+layer_name+'_1','W','B',b3_c_ksize1 , device)\n",
    "    b3_w_conv2 , b3_b_conv2 = make_weights_biases('b3_'+layer_name+'_2','W','B',b3_c_ksize2 , device)\n",
    "    b3_w_conv3 , b3_b_conv3 = make_weights_biases('b3_'+layer_name+'_3','W','B',b3_c_ksize3 , device)\n",
    "    b3_w_conv4_a , b3_b_conv4_a = make_weights_biases('b3_'+layer_name+'_4_a','W','B',b3_c_ksize4_a , device)\n",
    "    b3_w_conv4_b , b3_b_conv4_b = make_weights_biases('b3_'+layer_name+'_4_b','W','B',b3_c_ksize4_b , device)\n",
    "\n",
    "    b3_c_strides1=[1,1,1,1]\n",
    "    b3_c_strides2=[1,1,1,1]\n",
    "    b3_c_strides3=[1,1,1,1]\n",
    "    b3_c_strides4_a=[1,1,1,1]\n",
    "    b3_c_strides4_b=[1,1,1,1]\n",
    "\n",
    "    b3_c_pooling1='SAME'\n",
    "    b3_c_pooling2='SAME'\n",
    "    b3_c_pooling3='SAME'\n",
    "    b3_c_pooling4_a='SAME'\n",
    "    b3_c_pooling4_b='SAME'\n",
    "    b3_conv_info1=make_conv_info(x, b3_w_conv1, b3_b_conv1, b3_c_strides1, b3_c_pooling1)\n",
    "    b3_layer1=convolution(b3_conv_info1 , place_info , bn_flag ,'b3_'+layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info2=make_conv_info(b3_layer1, b3_w_conv2, b3_b_conv2, b3_c_strides2, b3_c_pooling2)\n",
    "    b3_layer2=convolution(b3_conv_info2 , place_info , bn_flag ,'b3_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info3=make_conv_info(b3_layer2, w_conv3, b_conv3, c_strides3, c_pooling3)\n",
    "    b3_layer3=convolution(b3_conv_info3 , place_info , bn_flag ,'b3_'+layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info4=make_conv_info(b3_layer3, w_conv4, b_conv4, c_strides4, c_pooling4)\n",
    "    b3_layer4=convolution(b3_conv_info4 , place_info , bn_flag ,'b3_'+layer_name+'_L4' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b3_conv_info5=make_conv_info(b3_layer4, w_conv5, b_conv5, c_strides5, c_pooling5)\n",
    "    b3_layer5=convolution(b3_conv_info5 , place_info , bn_flag ,'b3_'+layer_name+'_L5' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "\n",
    "    #################################################################################  with tf.variable_scope(layer_name+'b3_layer5') as scope:    \n",
    "    with tf.variable_scope(layer_name+'_end') as scope:    \n",
    "        layer_concat = tf.concat(3 , [layer2_a,layer2_b,b1_layer2, b2_layer2,b3_layer5],name='concat')\n",
    "\n",
    "    return layer_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_A(x , device,layer_name , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    ####################################################################################\n",
    "    \"\"\"\n",
    "    usage:\n",
    "    x shape =[ n_batch , row , col , ch] \n",
    "    \"\"\"\n",
    "    print x.get_shape()\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch = 384\n",
    "    c_ksize= [3,3,in_ch , out_ch]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W','B',c_ksize,device)\n",
    "    c_strides=[1,2,2,1]\n",
    "    c_pooling='VALID'\n",
    "    conv_info=make_conv_info(x, w_conv, b_conv, c_strides, c_pooling)\n",
    "    layer=convolution(conv_info , place_info , bn_flag ,layer_name+'_L',restore_flag,  restore_path)\n",
    "\n",
    "    ####################################################################################   \n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    with tf.variable_scope('b1_'+layer_name+'_L') as scope:\n",
    "        b1_layer = tf.nn.max_pool(x,b1_p_ksize , b1_p_strides , b1_p_pooling, name='max_pool')\n",
    "        b1_layer_relu = tf.nn.relu(b1_layer , name='relu')\n",
    "    ####################################################################################\n",
    "    b2_out_ch1 = 192; b2_out_ch2=288 ;b2_out_ch3 = 256;\n",
    "    b2_c_ksize1=[1,1,in_ch,b2_out_ch1]\n",
    "    b2_c_ksize2=[3,3,b2_out_ch1,b2_out_ch2]\n",
    "    b2_c_ksize3=[3,3,b2_out_ch2,b2_out_ch3]\n",
    "    \n",
    "    b2_w_conv1 , b2_b_conv1 = make_weights_biases('b2_'+layer_name+'_1' ,'W' ,'B', b2_c_ksize1 , device)\n",
    "    b2_w_conv2 , b2_b_conv2 = make_weights_biases('b2_'+layer_name+'_2' ,'W' ,'B',b2_c_ksize2 , device)\n",
    "    b2_w_conv3 , b2_b_conv3 = make_weights_biases('b2_'+layer_name+'_3' ,'W' ,'B',b2_c_ksize3 , device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,2,2,1]\n",
    "    b2_c_pooling1='SAME'\n",
    "    b2_c_pooling2='SAME'\n",
    "    b2_c_pooling3='VALID'\n",
    "    \n",
    "    b2_conv_info1=make_conv_info(x, b2_w_conv1, b2_b_conv1, b2_c_strides1, b2_c_pooling1)\n",
    "    b2_layer1=convolution(b2_conv_info1 , place_info , bn_flag ,'b2_'+layer_name+'_L1' ,restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info2=make_conv_info(b2_layer1, b2_w_conv2, b2_b_conv2, b2_c_strides2, b2_c_pooling2)\n",
    "    b2_layer2=convolution(b2_conv_info2 , place_info , bn_flag ,'b2_'+layer_name+'_L2' ,restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv3, b2_b_conv3, b2_c_strides3, b2_c_pooling3)\n",
    "    b2_layer3=convolution(b2_conv_info3 , place_info , bn_flag ,'b2_'+layer_name+'_L3' ,restore_flag,  restore_path)\n",
    "    \n",
    "    ####################################################################################\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:    \n",
    "        layer_concat=tf.concat(3 ,[layer ,b1_layer_relu ,b2_layer3] ,name='concat')\n",
    "\n",
    "    \n",
    "    \n",
    "    return layer_concat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def INCEPTION_REDUCTION_B(x , device_,layer_name,n_nodes , place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ####################################################################################\n",
    "    in_ch=x.get_shape()[3]\n",
    "    out_ch1=192 ; out_ch2=192;\n",
    "\n",
    "    c_ksize1 =[1,1,in_ch , out_ch1]\n",
    "    c_ksize2 =[3,3,out_ch1,out_ch2]\n",
    "    w_conv1, b_conv1 = make_weights_biases(layer_name+'_1','W','B',c_ksize1,device)\n",
    "    w_conv2, b_conv2 = make_weights_biases(layer_name+'_2','W','B',c_ksize2,device)\n",
    "    \n",
    "    c_strides1=[1,1,1,1]\n",
    "    c_strides2=[1,2,2,1]\n",
    "    \n",
    "    c_pooling1='SAME'\n",
    "    c_pooling2='VALID'\n",
    "    conv_info1=make_conv_info(x, w_conv1, b_conv1, c_strides1, c_pooling1)\n",
    "    layer1=convolution(conv_info1 , place_info , bn_flag ,layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    conv_info2=make_conv_info(layer1, w_conv2, b_conv2, c_strides2, c_pooling2)\n",
    "    layer2=convolution(conv_info2 , place_info , bn_flag ,layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    ####################################################################################\n",
    "    b1_p_ksize=[1,3,3,1]\n",
    "    b1_p_strides=[1,2,2,1]\n",
    "    b1_p_pooling='VALID'\n",
    "    with tf.variable_scope('b1_'+layer_name+'L') as scope:\n",
    "        b1_layer=tf.nn.max_pool(x ,b1_p_ksize , b1_p_strides , b1_p_pooling,name='max_pool')\n",
    "        b1_layer_relu = tf.nn.relu(b1_layer , name='relu')\n",
    "    ####################################################################################\n",
    "    b2_out_ch1=256 ; b2_out_ch2 = 256 ; b2_out_ch3=320 ; b2_out_ch4=320;\n",
    "    b2_c_ksize1 =[1,1,in_ch , b2_out_ch1]\n",
    "    b2_c_ksize2 =[1,7,b2_out_ch1 , b2_out_ch2]\n",
    "    b2_c_ksize3 =[7,1,b2_out_ch2 , b2_out_ch3]\n",
    "    b2_c_ksize4 =[3,3,b2_out_ch3 , b2_out_ch4]\n",
    "    \n",
    "    b2_w_conv1, b2_b_conv1 = make_weights_biases('b2_'+layer_name+'_1','W' ,'B',b2_c_ksize1,device)\n",
    "    b2_w_conv2, b2_b_conv2 = make_weights_biases('b2_'+layer_name+'_2','W' ,'B',b2_c_ksize2,device)\n",
    "    b2_w_conv3, b2_b_conv3 = make_weights_biases('b2_'+layer_name+'_3','W' ,'B',b2_c_ksize3,device)\n",
    "    b2_w_conv4, b2_b_conv4 = make_weights_biases('b2_'+layer_name+'_4','W' ,'B',b2_c_ksize4,device)\n",
    "    \n",
    "    b2_c_strides1=[1,1,1,1]\n",
    "    b2_c_strides2=[1,1,1,1]\n",
    "    b2_c_strides3=[1,1,1,1]\n",
    "    b2_c_strides4=[1,2,2,1]\n",
    "    \n",
    "    b2_c_pooling1= 'SAME'\n",
    "    b2_c_pooling2= 'SAME'\n",
    "    b2_c_pooling3 = 'SAME'\n",
    "    b2_c_pooling4 = 'VALID'\n",
    "    \n",
    "    b2_conv_info1=make_conv_info(x, b2_w_conv1, b2_b_conv1, b2_c_strides1, b2_c_pooling1)\n",
    "    b2_layer1=convolution(b2_conv_info1 , place_info , bn_flag ,'b2_'+layer_name+'_L1' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info2=make_conv_info(b2_layer1, b2_w_conv2, b2_b_conv2, b1_c_strides2, b1_c_pooling2)\n",
    "    b2_layer2=convolution(b2_conv_info2 , place_info , bn_flag ,'b2_'+layer_name+'_L2' ,'xavier',restore_flag,  restore_path)\n",
    "    \n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv3, b2_b_conv3, b2_c_strides3, b2_c_pooling3)\n",
    "    b2_layer3=convolution(b2_conv_info3 , place_info , bn_flag ,'b2_'+layer_name+'_L3' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv4, b2_b_conv4, b2_c_strides4, b2_c_pooling4)\n",
    "    b2_layer3=convolution(b2_conv_info4 , place_info , bn_flag ,'b2_'+layer_name+'_L4' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    b2_conv_info3=make_conv_info(b2_layer2, b2_w_conv5, b2_b_conv5, b2_c_strides5, b2_c_pooling5)\n",
    "    b2_layer3=convolution(b2_conv_info5 , place_info , bn_flag ,'b2_'+layer_name+'_L5' ,'xavier',restore_flag,  restore_path)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'_end') as scope:\n",
    "        layer_concat_A=tf.concat(3,[layer2,b1_layer_relu,b2_layer3] ,name='concat')\n",
    "    return layer_concat_A\n",
    "    ####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULLYCONNCECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FLAT(x , device_ , layer_name = \"FLAT\"):\n",
    "    with tf.variable_scope(layer_name) as scope:\n",
    "        with tf.device(device_):\n",
    "            row=int(x.get_shape()[1])\n",
    "            col=int(x.get_shape()[2])\n",
    "            ch=int(x.get_shape()[3])\n",
    "\n",
    "            res_x = tf.reshape(x , shape=[-1,row*col*ch] ,name='flat_layer');\n",
    "            return res_x\n",
    "            #connect fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_A(x , dropout_rate ,n_classes , device_ , layer_name , restore_flag , restore_path):\n",
    "    with tf.device(device_):    \n",
    "        fully_ch1=1024; fully_ch2=1024;\n",
    "        \n",
    "        fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "        fc_ksize2=[fully_ch1,fully_ch2]\n",
    "\n",
    "        w_fc1 ,b_fc1 = make_weights_biases(layer_name+'_1' , 'W' ,'B' ,fc_ksize1 ,  device_,'xavier',restore_flag , restore_path)\n",
    "        w_fc2 ,b_fc2 = make_weights_biases(layer_name+'_2' , 'W' ,'B' ,fc_ksize2 ,  device_,'xavier',restore_flag , restore_path)\n",
    "    \n",
    "        h_fc1=tf.matmul(x, w_fc1 ,name='h_fc1')+b_fc1\n",
    "        h_fc1=tf.nn.dropout(h_fc1 , dropout_rate , name='h_fc1_dropout')\n",
    "        h_fc2=tf.matmul(h_fc1 , w_fc2 ,name='h_fc2')+b_fc2\n",
    "        h_fc2=tf.nn.dropout(h_fc2 , dropout_rate,name='h_fc2_dropout')\n",
    "        end_fc=h_fc2\n",
    "\n",
    "        end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases('fc_end' , 'W' , 'B' ,end_ksize ,  device_)\n",
    "        y_conv = tf.matmul(end_fc , w_end ,name=layer_name+'y_conv')+b_end\n",
    "\n",
    "        print w_fc1.get_shape()\n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FC_B(x , n_classes , device_ , layer_name , restore_flag , restore_path):\n",
    "    with tf.device(device_):\n",
    "        end_ksize=[x.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases\\\n",
    "        (layer_name , 'W','B' , end_ksize ,  device_ ,'xavier',restore_flag , restore_path)\n",
    "        y_conv = tf.matmul(x , w_end , name=layer_name+'y_conv')+b_end\n",
    "        return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FC_C(x , dropout_rate,n_classes , device_ , layer_name , restore_flag , restore_path):\n",
    "    with tf.device(device_):    \n",
    "        fully_ch1=1024;\n",
    "        \n",
    "        fc_ksize1=[x.get_shape()[1],fully_ch1]\n",
    "\n",
    "        w_fc1 ,b_fc1 = make_weights_biases(layer_name , 'W' ,'B' ,fc_ksize1 ,  device_,'xavier',restore_flag , restore_path)    \n",
    "        h_fc1=tf.matmul(x, w_fc1 ,name='h_fc1')+b_fc1\n",
    "        h_fc1=tf.nn.dropout(h_fc1 , dropout_rate , name='h_fc1_dropout')\n",
    "        end_fc=h_fc1\n",
    "        print end_fc\n",
    "        end_ksize=[end_fc.get_shape()[1] , n_classes]   \n",
    "        w_end ,b_end = make_weights_biases(layer_name+'_end' , 'W' , 'B' ,end_ksize ,  device_,'xavier',restore_flag , restore_path)\n",
    "        y_conv = tf.matmul(end_fc , w_end , name=layer_name+'y_conv')+b_end\n",
    "\n",
    "        print w_fc1.get_shape()\n",
    "    return y_conv\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AVG_POOL(x , ksize , strides ,pooling,layer_name,device_):\n",
    "    with tf.device(device_):\n",
    "        layer=tf.nn.avg_pool(x,ksize ,strides,pooling,name = layer_name+\"AVG_POOL\")\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MAX_POOL(x , ksize , strides,pooling,layer_name,device_):\n",
    "    with tf.device(device_):\n",
    "        layer=tf.nn.max_pool(x,ksize ,strides,pooling,name = layer_name+\"MAX_POOL\")\n",
    "    print layer\n",
    "    return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DROPOUT(x ,keep_prob , layer_name , device_):\n",
    "    with tf.device(device_):\n",
    "        drop_x=tf.nn.dropout(x , keep_prob , name=layer_name+'dropout')\n",
    "        return drop_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTION LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CONV_6(x , device_ , layer_name , n_nodes , kernel_size ,strides ,pooling):\n",
    "    \"\"\" \n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[0] \n",
    "    \n",
    "    \"\"\"\n",
    "    in_ch = x.get_shape()[3]\n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[1] \n",
    "    \n",
    "    \n",
    "    out_ch1=n_nodes\n",
    "    out_ch2=n_nodes\n",
    "    out_ch3=n_nodes\n",
    "    out_ch4=n_nodes\n",
    "    out_ch5=n_nodes\n",
    "    out_ch6=n_nodes\n",
    "    \n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    c_ksize4=[k_row,k_col , out_ch3 , out_ch4]\n",
    "    c_ksize5=[k_row,k_col , out_ch4 , out_ch5]\n",
    "    c_ksize6=[k_row,k_col , out_ch5 , out_ch6]\n",
    "    \n",
    "    c_strides1=strides\n",
    "    c_strides2=strides\n",
    "    c_strides3=strides\n",
    "    c_strides4=strides\n",
    "    c_strides5=strides\n",
    "    c_strides6=strides\n",
    "    \n",
    "    c_pooling1=pooling\n",
    "    c_pooling2=pooling\n",
    "    c_pooling3=pooling\n",
    "    c_pooling4=pooling\n",
    "    c_pooling5=pooling\n",
    "    c_pooling6=pooling\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1) , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2) , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3) , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "    w_conv4 , b_conv4= make_weights_biases(layer_name+str(4) , 'W4' ,'B4', c_ksize4 ,device_name = device_)\n",
    "    w_conv5 , b_conv5= make_weights_biases(layer_name+str(5) , 'W5' ,'B5', c_ksize5 ,device_name = device_)\n",
    "    w_conv6 , b_conv6= make_weights_biases(layer_name+str(6) , 'W6' ,'B6', c_ksize5 ,device_name = device_)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1,name='layer1_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='layer2_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='layer3_relu')\n",
    "    with tf.variable_scope(layer_name+'conv4') as scope:\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4,name='layer4')+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4,name='layer4_relu')\n",
    "    with tf.variable_scope(layer_name+'conv5') as scope:\n",
    "        layer5 = tf.nn.conv2d(layer4 , w_conv5 , c_strides5 , c_pooling5,name='layer5')+b_conv5\n",
    "        layer5 = tf.nn.relu(layer5,name='layer5_relu')\n",
    "    with tf.variable_scope(layer_name+'conv6') as scope:\n",
    "        layer6 = tf.nn.conv2d(layer5 , w_conv6 , c_strides6 , c_pooling6,name='layer6')+b_conv6\n",
    "        layer6 = tf.nn.relu(layer5,name='layer6_relu')\n",
    "\n",
    "    return layer6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CONV_5(x , device_ , layer_name , n_nodes , kernel_size ,strides ,pooling):\n",
    "    \"\"\" \n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[0] \n",
    "    \n",
    "    \"\"\"\n",
    "    in_ch = x.get_shape()[3]\n",
    "\n",
    "    c_kernel1,c_kernel2,c_kernel3,c_kernel4,c_kernel5 = kernel_size  \n",
    "    out_ch1,out_ch2,out_ch3,out_ch4,out_ch5=n_nodes\n",
    "\n",
    "    c_ksize1=[c_kernel1[0],c_kernel1[1] , in_ch   , out_ch1]\n",
    "    c_ksize2=[c_kernel2[0],c_kernel2[1] , out_ch1 , out_ch2]\n",
    "    c_ksize3=[c_kernel3[0],c_kernel3[1] , out_ch2 , out_ch3]\n",
    "    c_ksize4=[c_kernel4[0],c_kernel4[1] , out_ch3 , out_ch4]\n",
    "    c_ksize5=[c_kernel5[0],c_kernel5[1] , out_ch4 , out_ch5]\n",
    "    \n",
    "    c_strides1,c_strides2,c_strides3,c_strides4,c_strides5=strides\n",
    "    c_pooling1,c_pooling2,c_pooling3,c_pooling4,c_pooling5=pooling\n",
    "\n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1), 'W1' ,'B1' , c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2), 'W2' ,'B2' , c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3), 'W3' ,'B3' , c_ksize3 ,device_name = device_)\n",
    "    w_conv4 , b_conv4= make_weights_biases(layer_name+str(4), 'W4' ,'B4' , c_ksize4 ,device_name = device_)\n",
    "    w_conv5 , b_conv5= make_weights_biases(layer_name+str(5), 'W5' ,'B5' , c_ksize5 ,device_name = device_)\n",
    "\n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1,name='layer1_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='layer2_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='layer3_relu')\n",
    "    with tf.variable_scope(layer_name+'conv4') as scope:\n",
    "        layer4 = tf.nn.conv2d(layer3 , w_conv4 , c_strides4 , c_pooling4,name='layer4')+b_conv4\n",
    "        layer4 = tf.nn.relu(layer4,name='layer4_relu')\n",
    "    with tf.variable_scope(layer_name+'conv5') as scope:\n",
    "        layer5 = tf.nn.conv2d(layer4 , w_conv5 , c_strides5 , c_pooling5,name='layer5')+b_conv5\n",
    "        layer5 = tf.nn.relu(layer5,name='layer4_relu')\n",
    "\n",
    "    return layer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CONV_3(x , device_ , layer_name , n_nodes , kernel_size ,strides,pooling):\n",
    "    \"\"\"\n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    \"\"\"\n",
    "    \n",
    "    in_ch = x.get_shape()[3]\n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[1]     \n",
    "    \n",
    "    c_ksize1=[k_row,k_col , in_ch   , n_nodes]\n",
    "    c_ksize2=[k_row,k_col , n_nodes , n_nodes]\n",
    "    c_ksize3=[k_row,k_col , n_nodes , n_nodes]\n",
    "    \n",
    "    c_strides1=strides\n",
    "    c_strides2=strides\n",
    "    c_strides3=strides\n",
    "        \n",
    "    c_pooling1=pooling\n",
    "    c_pooling2=pooling\n",
    "    c_pooling3=pooling\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1) , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2) , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3) , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "    \n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1 = tf.nn.relu(layer1,name='layer1_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1 , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2 = tf.nn.relu(layer2,name='layer2_relu')\n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2 , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3 = tf.nn.relu(layer3,name='layer3_relu')\n",
    "    return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CONV_3_BN(x , device_ , layer_name , n_nodes , kernel_size ,strides,pooling,train_flag=True):\n",
    "    \"\"\"\n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    \"\"\"\n",
    "    \n",
    "    in_ch = x.get_shape()[3]\n",
    "    k_row=kernel_size[0]  \n",
    "    k_col=kernel_size[1]     \n",
    "    \n",
    "    c_ksize1=[k_row,k_col , in_ch   , n_nodes]\n",
    "    c_ksize2=[k_row,k_col , n_nodes , n_nodes]\n",
    "    c_ksize3=[k_row,k_col , n_nodes , n_nodes]\n",
    "    \n",
    "    c_strides1=strides\n",
    "    c_strides2=strides\n",
    "    c_strides3=strides\n",
    "        \n",
    "    c_pooling1=pooling\n",
    "    c_pooling2=pooling\n",
    "    c_pooling3=pooling\n",
    "    \n",
    "    w_conv1 , b_conv1 =make_weights_biases(layer_name+str(1) , 'W1' ,'B1', c_ksize1 ,device_name = device_)\n",
    "    w_conv2 , b_conv2= make_weights_biases(layer_name+str(2) , 'W2' ,'B2',c_ksize2 ,device_name = device_)\n",
    "    w_conv3 , b_conv3= make_weights_biases(layer_name+str(3) , 'W3' ,'B3' ,c_ksize3 ,device_name = device_)\n",
    "    \n",
    "    \n",
    "    beta1, gamma1 = tf.Variable()\n",
    "    with tf.variable_scope(layer_name+'conv1') as scope:\n",
    "        layer1 = tf.nn.conv2d(x ,      w_conv1 , c_strides1 , c_pooling1 ,name='layer1')+b_conv1\n",
    "        layer1_BN = batch_norm(layer1,n_nodes ,train_flag,layer_name+'bn')\n",
    "        layer1_relu = tf.nn.relu(layer1_BN,name='layer1_relu')\n",
    "        \n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer2 = tf.nn.conv2d(layer1_relu , w_conv2 , c_strides2 , c_pooling2 , name='layer2')+b_conv2\n",
    "        layer2_BN = batch_norm(layer2,n_nodes ,train_flag,layer_name+'bn2')\n",
    "        layer2_relu = tf.nn.relu(layer2_BN,name='layer2_relu')\n",
    "        \n",
    "    with tf.variable_scope(layer_name+'conv2') as scope:\n",
    "        layer3 = tf.nn.conv2d(layer2_relu , w_conv3 , c_strides3 , c_pooling3,name='layer3')+b_conv3\n",
    "        layer3_BN=batch_norm(layer3,n_nodes ,train_flag,layer_name+'bn3')\n",
    "        layer3_relu = tf.nn.relu(layer3_BN,name='layer3_relu')\n",
    "    return layer3_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CONV_1(x , device_ , layer_name , n_nodes , kernel_size ,strides, pooling,  place_info  , bn_flag  , restore_flag , restore_path):\n",
    "    \"\"\"\n",
    "    c_ksize1=[k_row,k_col , in_ch   , out_ch1]\n",
    "    c_ksize2=[k_row,k_col , out_ch1 , out_ch2]\n",
    "    c_ksize3=[k_row,k_col , out_ch2 , out_ch3]\n",
    "    \"\"\"\n",
    "    \n",
    "    in_ch = x.get_shape()[3]\n",
    "    out_ch=n_nodes\n",
    "    c_ksize=[kernel_size[0], kernel_size[1] , in_ch, out_ch]\n",
    "    c_pooling =pooling\n",
    "    c_strides=strides # when downsampling featrue map , set strides parameter,[1,2,2,1]\n",
    "    w_conv , b_conv =make_weights_biases(layer_name,'W' ,'B' , c_ksize ,device_ ,'xavier',restore_flag ,  restore_path )\n",
    "    conv_info=make_conv_info(x, w_conv, b_conv, c_strides, c_pooling)\n",
    "    layer1=convolution(conv_info , place_info , bn_flag , layer_name+'_L' , restore_flag , restore_path)   \n",
    "    print layer_name , layer1.get_shape()\n",
    "    return layer1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def batch_norm(x , decay, train_flag ):\n",
    "    \"\"\"\n",
    "    Batch normalization on convolutional maps.\n",
    "    Ref.: http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow\n",
    "    Args:\n",
    "        x:           Tensor, 4D BHWD input maps\n",
    "        x shape: [n , row , col , ch]\n",
    "        n_out:       integer, depth of input maps\n",
    "        train_flag: boolean tf.Varialbe, true indicates training phase\n",
    "        scope:       string, variable scope\n",
    "    Return:\n",
    "        normed:      batch-normalized maps\n",
    "    \"\"\"\n",
    "    \n",
    "    n_out=x.get_shape()[3]\n",
    "    with tf.variable_scope('bn'):\n",
    "        beta = tf.Variable(tf.constant(0.0, shape=[n_out]),\n",
    "                                     name='beta', trainable=True)\n",
    "        gamma = tf.Variable(tf.constant(1.0, shape=[n_out]),\n",
    "                                      name='gamma', trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0,1,2], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(train_flag,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n",
    "    return normed\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_list(folder_path):\n",
    "    \"\"\"\n",
    "    return ret_train_img_list ,ret_train_lab_list \n",
    "    \n",
    "    \"\"\"\n",
    "    list_files=os.walk(folder_path).next()[2]\n",
    "    ret_train_img_list=[]\n",
    "    ret_train_lab_list=[]\n",
    "    np_train_imgs=[]\n",
    "    np_train_labs=[]\n",
    "    for i , ele in enumerate(list_files):\n",
    "\n",
    "        if 'train'  in ele and 'img'in ele:\n",
    "            ret_train_img_list.append(ele)\n",
    "        elif 'train' in ele  and  'lab' in ele:\n",
    "            ret_train_lab_list.append(ele)\n",
    "    \n",
    "    ret_train_img_list.sort(key=natural_keys)\n",
    "    ret_train_lab_list.sort(key = natural_keys)\n",
    "    print 'check match image and label '\n",
    "    for i in range(len(ret_train_img_list)):\n",
    "        print ret_train_img_list[i] , ret_train_lab_list[i]\n",
    "    \n",
    "    for i  in range(len(ret_train_img_list)):\n",
    "        print str(i)+'th Image loading... waiting for minute....'\n",
    "        np_train_imgs.append(np.load(folder_path+ret_train_img_list[i]))\n",
    "        np_train_labs.append(np.load(folder_path+ret_train_lab_list[i]))\n",
    "    \n",
    "    return np_train_imgs ,np_train_labs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    \n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "    \n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "                \n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "                \n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "    \n",
    "    return ret_images ,ret_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test_img(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col ):\n",
    "    left_top =(0,0)\n",
    "    right_top =(  img_row  - crop_img_row  , 0 )\n",
    "    center =  ((img_row  - crop_img_row)/2  , (img_col - crop_img_row)/2)\n",
    "    left_buttom = (0,(img_col - crop_img_row)/2 )\n",
    "    right_buttom =  (img_row  - crop_img_row , img_col - crop_img_row)\n",
    "    \n",
    "    left_top_images  = np_img[: , left_top[0]:crop_img_row+left_top[0] , left_top[1] : crop_img_col+left_top[1] , :  ]\n",
    "    right_top_images = np_img[: , right_top[0]:crop_img_row +right_top[0], right_top[1] : crop_img_col +right_top[1], :  ]\n",
    "    center_images    = np_img[: , center[0]:crop_img_row +center[0], center[1] : crop_img_col +center[1], :  ]\n",
    "    left_buttom_images=np_img[: , left_buttom[0]:crop_img_row +left_buttom[0], left_buttom[1] : crop_img_col +left_buttom[1], :  ]\n",
    "    right_buttom_images= np_img[: , right_buttom[0]:crop_img_row+right_buttom[0] , right_buttom[1] : crop_img_col +right_buttom[1] , :  ]\n",
    "\n",
    "    \n",
    "        \n",
    "    return left_top_images , right_top_images , center_images , left_buttom_images , right_buttom_images \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TRAIN_STRUCTURE_A(y_conv , y_ , device_,learning_rate ):\n",
    "    \"\"\"\n",
    "    Return Value : cost , train_step ,correct_prediction , accuracy \n",
    "    \n",
    "    \"\"\"\n",
    "    with tf.device(device_):\n",
    "    #sm_conv= tf.nn.softmax(y_conv)\n",
    "        #cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "\n",
    "        softmax=tf.nn.softmax(y_conv)\n",
    "        pred_cls = tf.argmax(softmax , axis = 1)\n",
    "        #regular=0.01*(tf.reduce_sum(tf.square(y_conv)))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits( y_conv, y_))\n",
    "    with tf.device(device_):\n",
    "        #cost = cost+regular\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost) #1e-4\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                correct_prediction = tf.equal(tf.argmax(y_conv,1) ,tf.argmax(y_,1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\")) \n",
    "    tensor_info ={}\n",
    "    tensor_info['cost']=cost\n",
    "    tensor_info['train_step']=train_step\n",
    "    tensor_info['correct_prediction']=correct_prediction\n",
    "    tensor_info['accuracy']=accuracy\n",
    "    tensor_info['softmax']=softmax\n",
    "    tensor_info['pred_cls'] = pred_cls\n",
    "    return tensor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def START_SESS():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    return sess \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Terminal Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dirname = '/home/ncc/notebook/mammo/result/'\n",
    "def make_logdir(dirname):\n",
    "  \n",
    "\n",
    "    count=0\n",
    "    while(True):\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        elif not os.path.isdir(dirname + str(count)):\n",
    "            dirname=dirname+str(count)\n",
    "            os.mkdir(dirname)\n",
    "            break\n",
    "        else:\n",
    "            count+=1\n",
    "    print 'it is recorded at :'+str(count)\n",
    "\n",
    "    f=open(dirname+\"/log.txt\",'w')\n",
    "    return f,dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_acc_loss(step , val_acc , val_loss ,file_path):\n",
    "    \"\"\"\n",
    "    fp = File Pointer\n",
    "    \"\"\"\n",
    "    str_ = 'step:\\t'+str(step)+'\\tacc:\\t'+str(acc) +'\\tloss:\\t'+str(loss)+'\\n'\n",
    "    fp.write(str_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_TVT(divide_flag,file_locate):\n",
    "    if divide_flag == False:\n",
    "        train_img=np.load(file_locate+'train_img.npy');\n",
    "        train_lab=np.load(file_locate+'train_lab.npy');\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "\n",
    "        print \"Training Data Image\",np.shape(train_img)\n",
    "        print \"Training Data Label\",np.shape(train_lab)\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        \n",
    "        n_train= np.shape(train_img)[0]\n",
    "        n_train_lab = np.shape(train_lab)[0]\n",
    "        return train_img ,train_lab,val_img,val_lab,test_img,test_lab\n",
    "    if divide_flag == True:\n",
    "        print '트레이닝 파일이 여러개로 분할되어 있습니다. 분할된 트레이닝 파일에 대한 조치가 필요합니다'\n",
    "        train_images, train_labels =get_batch_list(file_locate)\n",
    "        #print train_images ,train_labels\n",
    "        val_img= np.load(file_locate+'val_img.npy');\n",
    "        val_lab = np.load(file_locate+'val_lab.npy');\n",
    "        test_img=np.load(file_locate+'test_img.npy');\n",
    "        test_lab=np.load(file_locate+'test_lab.npy');\n",
    "        print \"the number of training image batch\",len(train_images)\n",
    "        print \"the number of training label batch\",len(train_labels)\n",
    "        print \"training Data Label\",np.shape(train_labels[0])\n",
    "        print \"training Data Image\",np.shape(train_images[0])\n",
    "        print \"Test Data Label\",np.shape(test_lab)\n",
    "        print \"Test Data Image\",np.shape(test_img)\n",
    "        print \"val Data Label\" , np.shape(val_lab)\n",
    "        print \"val Data Image\" , np.shape(val_img)\n",
    "        return train_images, train_labels,val_img,val_lab,test_img,test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_weights_biases(sess, save_folder):\n",
    "    \n",
    "    trainable_list=tf.trainable_variables()\n",
    "    save_paths=[]\n",
    "    for i,ele in enumerate(trainable_list): \n",
    "        #print ele\n",
    "        #print ele.name.replace('/' , '_')\n",
    "        np_=sess.run(ele)\n",
    "        #print 'name:',ele.name\n",
    "        np.save(save_folder+ele.name.replace('/' , '_').replace(':0' , '') , np_ )\n",
    " \n",
    "    print \"model was saved\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate(sess,img , lab ,tensor_info , place_info,tensorboard_info=None , step=None): #default\n",
    "    \"\"\"\n",
    "    return val_acc,  val_loss, train_acc, train_loss\n",
    "    tensorboard_info['writer']\n",
    "    tensorboard_info['merge']    \n",
    "    \"\"\"    \n",
    "    #print 'validate tensorboard' , tensorboard_info\n",
    "    if tensorboard_info ==None: #텐서 보드를 비활성 합니다.\n",
    "        print 'No tensorboard info'\n",
    "        acc ,loss = sess.run( [tensor_info['accuracy'],tensor_info['cost']] ,\\\n",
    "                             feed_dict={place_info['x_']:img , place_info['y_']: lab , place_info['keep_prob']: 1.0})    \n",
    "    else: # 텐서보드를 활성화 합니다\n",
    "        print 'tensorboard info'\n",
    "        summary,acc,loss = sess.run([tensorboard_info['merge'],tensor_info['accuracy'],tensor_info['cost']] ,\\\n",
    "                                    feed_dict={place_info['x_']:img , place_info['y_']:lab , place_info['keep_prob']: 1.0})        \n",
    "        tensorboard_info['writer'].add_summary(summary , step)\n",
    "        \n",
    "        \n",
    "    return acc,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "  \n",
    "def validate_extract_imgs(val_img , val_lab , train_img , train_lab ):\n",
    "    \"\"\"\n",
    "    extract patch from ori-image\n",
    "    \"\"\"\n",
    "    color_ch = in_ch\n",
    "    val_images  =extract_test_img(val_img , 128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    train_images=extract_test_img(train_img ,128 , 128 , color_ch   ,crop_img_row =118 , crop_img_col =118 )\n",
    "    val_acc, val_loss =validate_from_images(sess, val_images , val_lab , accuracy ,cost )\n",
    "    train_acc , train_loss =validate_from_images(sess, train_images , train_lab ,accuracy , cost)\n",
    "    return val_acc , val_loss, train_acc ,train_loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_8_times(x):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    x shape is [n_batch , row ,col , color_ch ]\n",
    "    x type is numpy \n",
    "    this code need too many time to run \n",
    "    we should find solution using parallel method to less run time maybe \n",
    "    \n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    n_batch,row,col,ch=np.shape(x)\n",
    "    lr_x = np.flipud(x)\n",
    "\n",
    "    np_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "\n",
    "    np_lr_rot90 =np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot180=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    np_lr_rot270=np.zeros(shape =[n_batch , row ,col ,ch] )\n",
    "    \n",
    "    \n",
    "\n",
    "    for batch_ind in range(n_batch):\n",
    "\n",
    "        rot90=np.rot90(x[batch_ind,:,:,:])\n",
    "        rot180=np.rot90(rot90)\n",
    "        rot270=np.rot90(rot180)\n",
    "\n",
    "        np_rot90[batch_ind,:,:,:] = rot90\n",
    "        np_rot180[batch_ind,:,:,:]=rot180\n",
    "        np_rot270[batch_ind,:,:,:]=rot270\n",
    "\n",
    "        lr_rot90=np.rot90(lr_x[batch_ind,:,:,:])\n",
    "        lr_rot180=np.rot90(lr_rot90)\n",
    "        lr_rot270=np.rot90(lr_rot180)\n",
    "\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot90\n",
    "        np_lr_rot180[batch_ind,:,:,:]=lr_rot180\n",
    "        np_lr_rot90[batch_ind,:,:,:]=lr_rot270\n",
    "    return x,np_rot90,np_rot180,np_rot270,lr_x,np_lr_rot90 ,np_lr_rot180 , np_lr_rot270 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OPEN_TENSORBOARD(sess,tensor_info , logdir ):\n",
    "    \n",
    "    tensorboard_info={}\n",
    "    tb_acc=tf.summary.scalar(\"accuarcy\" ,tensor_info['accuracy'] )\n",
    "    tb_loss=tf.summary.scalar(\"loss\" ,tensor_info['cost'] )\n",
    "    tb_merge = tf.summary.merge_all()\n",
    "    writer=tf.train.SummaryWriter(logdir , sess.graph )\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    \n",
    "    tensorboard_info['writer']=writer\n",
    "    tensorboard_info['merge'] =tb_merge\n",
    "  \n",
    "    return tensorboard_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_crop(np_img ,img_row ,img_col , color_ch, crop_img_row , crop_img_col , label):\n",
    "    n_img = np.shape(np_img)[0] \n",
    "    n_ret_img = n_img*(img_row - crop_img_row) * (img_col - crop_img_col)*2\n",
    "    ret_images = np.zeros([n_ret_img ,crop_img_row , crop_img_col,color_ch])\n",
    "    len_label= np.shape(label)[1]\n",
    "    ret_labels =  np.zeros([n_ret_img  ,len_label])\n",
    "    #print \"n_augmented image size : \" , n_ret_img \n",
    "    #print \"n classes :\", len_label\n",
    "    #copy label in factor by 2014\n",
    "\n",
    "    if len(np.shape(np_img))==2:\n",
    "        np_img=np.reshape(np_img , newshape = [np.shape(np_img)[0] , img_row , img_col ,color_ch])\n",
    "        print np.shape(np_img)\n",
    "    for n  in range(len(np_img)):\n",
    "        ret_labels[n*2 , : ] = label[n,:]\n",
    "        ret_labels[n*2+1 , : ] = label[n,:]\n",
    "        for r in range(img_row - crop_img_row):\n",
    "            for c in range(img_col - crop_img_col):\n",
    "\n",
    "                cropped_img = np_img[n, r:crop_img_row +r , c:crop_img_col+c ,: ]\n",
    "\n",
    "                ret_images[n*2,:,:,:]=cropped_img  \n",
    "                ret_images[(n*2+1) , :,:,:] =np.fliplr(cropped_img )\n",
    "\n",
    "\n",
    "    return ret_images ,ret_labels\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_result(dirname , result):\n",
    "    \"\"\"\n",
    "     list_val_acc , list_val_loss , list_train_acc , list_train_loss\n",
    "    \"\"\"\n",
    "    np_val_acc=np.asarray(result[0])\n",
    "    np.save(dirname+'/val_acc' , np_val_acc)\n",
    "    np_val_loss=np.asarray(result[1])\n",
    "    np.save(dirname+'/val_loss' , np_val_loss)\n",
    "    \n",
    "    np_train_acc=np.asarray(result[2])\n",
    "    np.save(dirname+'/train_acc' , np_train_acc)\n",
    "    np_train_loss=np.asarray(result[3])\n",
    "    np.save(dirname+'/train_loss' , np_train_loss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_val(val_imgs = None,  val_labs=None):\n",
    "    \"\"\"\n",
    "    사용되는 글로벌 함수:\n",
    "    1.flie_locate\n",
    "    2.place_infro (divide_images)\n",
    "    \"\"\"\n",
    "    if val_imgs == None and val_labs ==None: \n",
    "        start_time=time.time()\n",
    "        val_img=np.load(file_locate + 'val_img.npy')\n",
    "        val_lab=np.load(file_locate + 'val_lab.npy')\n",
    "        val_imgs, val_labs = divide_images(val_img ,val_lab)\n",
    "        end_time=time.time()\n",
    "        print \"validate images , labels was loaded and divided with batch_size\"\n",
    "        print \"batch_size : \",batch_size\n",
    "        return val_imgs, val_labs\n",
    "    elif val_imgs != None and val_labs !=None:\n",
    "        return val_imgs  , val_labs\n",
    "\n",
    "    \n",
    "def load_test(test_imgs = None , test_labs=None):\n",
    "    \n",
    "    \"\"\"    \n",
    "    사용되는 글로벌 함수:\n",
    "    1.flie_locate\n",
    "    2.place_infro (divide_images)\n",
    "    \"\"\"\n",
    "    if test_imgs == None and test_labs ==None: \n",
    "\n",
    "        start_time=time.time()\n",
    "        test_img=np.load(file_locate+'test_img.npy')\n",
    "        test_lab=np.load(file_locate+'test_lab.npy')\n",
    "        val_imgs, val_labs = divide_images(val_img ,val_lab)\n",
    "        end_time=time.time()\n",
    "        print \"test images , labels was loaded and divided with batch_size\"\n",
    "        print \"batch_size : \",batch_size\n",
    "        print \"loading time\" , end_time-start_time\n",
    "        return test_imgs, test_labs\n",
    "    elif test_imgs != None and test_labs !=None:\n",
    "        return test_imgs  , test_labs\n",
    "\n",
    "def load_train(b_ind=None):\n",
    "    if b_ind==None:\n",
    "        b_ind=random.randrange(0,n_train)\n",
    "    train_img=np.load(file_locate+'train_'+str(b_ind)+'_img.npy')\n",
    "    train_lab=np.load(file_locate+'train_'+str(b_ind)+'_lab.npy')\n",
    "    return train_img , train_lab ,b_ind\n",
    "\n",
    "def load_train_all(start=None , end=None , arg_list=None):\n",
    "    pool=Pool()\n",
    "    train_imgs=[]\n",
    "    train_labs=[]\n",
    "    if arg_list!=None:\n",
    "        list_ = arg_list\n",
    "    elif start==None and end ==None:\n",
    "        list_=range(n_train)    \n",
    "    elif start!=None and end !=None:\n",
    "        list_=range(start , end)\n",
    "    \n",
    "    for train_img , train_lab ,b_ind in pool.imap(load_train ,list_):\n",
    "        train_imgs.append(train_img)\n",
    "        train_labs.append(train_lab)\n",
    "        msg='progress - {0}/{1}'.format(str(b_ind),str(n_train))\n",
    "        sys.stdout.write(msg)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    return train_imgs , train_labs\n",
    "\n",
    "def make_acc_step_log(folder_path):\n",
    "    f=open(folder_path+'step_max_acc.txt' , 'w')\n",
    "    msg='step\\tacc\\n'\n",
    "    f.write(msg,)\n",
    "    msg='{0}\\t{1}\\n'.format(str(0),str(0))\n",
    "    f.write(msg)\n",
    "    f.close()\n",
    "def make_folder(folder_path='./'):\n",
    "    # make folder that take accuracy , loss \n",
    "    # if folder is already existed , load folder. \n",
    "    up_to_date_folder=folder_path+'up_to_date/'\n",
    "    interrupt_folder=folder_path+'Interrupt/'\n",
    "    best_acc_folder=folder_path+'best_acc/'\n",
    "    if os.path.isdir(up_to_date_folder) != True:\n",
    "        os.mkdir(up_to_date_folder)\n",
    "        make_acc_step_log(up_to_date_folder)\n",
    "    if os.path.isdir(interrupt_folder)!=True:\n",
    "        os.mkdir(interrupt_folder)\n",
    "        make_acc_step_log(interrupt_folder)\n",
    "    if os.path.isdir(best_acc_folder)!=True:\n",
    "        os.mkdir(best_acc_folder)\n",
    "        make_acc_step_log(best_acc_folder)\n",
    "\n",
    "def load_step_acc(folder_path):\n",
    "    try:\n",
    "        f=open(folder_path+'step_max_acc.txt' , 'r')\n",
    "        step ,max_acc=f.readlines()[-1].split('\\t')\n",
    "        \n",
    "        print \"global_step and max_acc was restore!\"\n",
    "        print \"global step:\",step\n",
    "        print \"Max acc:\" ,max_acc\n",
    "        return step , max_acc\n",
    "\n",
    "    except IOError as ioe:\n",
    "        print 'global_step or maxacc cant found in'+folder_path\n",
    "        print 'Initialize global_step and max_acc to zero'\n",
    "        step=0 ;acc=0\n",
    "        return step , acc  \n",
    "    except Exception as ex:\n",
    "        print 'global_step or maxacc cant found in'+folder_path\n",
    "        print 'Initialize global_step and max_acc to zero'\n",
    "        step=0 ;acc=0\n",
    "        return step , acc  \n",
    "        \n",
    "#def write_acc_loss()\n",
    "\n",
    "def divide_images(images , labels):\n",
    "    \"\"\"\n",
    "    return list_images,list_labels\n",
    "    \"\"\"\n",
    "    n_divide=len(images)/batch_size\n",
    "\n",
    "    list_images=[]\n",
    "    list_labels=[]\n",
    "    for ind in range(n_divide):\n",
    "        # j*batch_size :(j+1)*batch_size\n",
    "        image =images[ ind*batch_size :(ind+1)*batch_size] \n",
    "        label =labels[ ind*batch_size :(ind+1)*batch_size]\n",
    "        list_images.append(image)\n",
    "        list_labels.append(label)\n",
    "\n",
    "    #right above code have to modify\n",
    "    image = images[ -batch_size :  ] \n",
    "    label = labels[ -batch_size :  ]\n",
    "    list_images.append(image)\n",
    "    list_labels.append(label)\n",
    "    return list_images,list_labels\n",
    "\n",
    "def validate_from_images(images , labels ,tensor_info, place_info ,correct_pred=False,tensorboard_info = None ):    \n",
    "    \"\"\"\n",
    "    input : x-\n",
    "\n",
    "    x type  : numpy \n",
    "    x shape : [n , row , col , ch]\n",
    "    return  acc,  loss\n",
    "\n",
    "\n",
    "    2017/2/16\n",
    "    왜 tensorboard 에 기록이 안되나 했더니 여기서 문제가 있었다.3\n",
    "    validate_from_images에서는 기록이 안된다.\n",
    "    기록할수 있는 방법을 찾아야 겠다\n",
    "    내 생각에는 기존의 방식과 다른 tensorboard  객체를 만들고 거기다가 기록해야 할 것 같다.\n",
    "    \n",
    "    사용되는 글로벌 함수\n",
    "    place_info \n",
    "    \"\"\"    \n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    images_labels=zip(images,labels)\n",
    "    temp_correct_list = []\n",
    "    for img_ind ,(img,lab)  in enumerate(images_labels):\n",
    "        acc ,loss , correct_prediction= sess.run( [tensor_info['accuracy'],tensor_info['cost'] , tensor_info['correct_prediction']],\\\n",
    "                             feed_dict={place_info['x_']:img , place_info['y_']: lab , place_info['keep_prob']: 1.0  , place_info['phase_train']:False})\n",
    "        temp_correct_list.extend(correct_prediction)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "    correct_prediction=temp_correct_list\n",
    "    acc_list=np.asarray(acc_list)\n",
    "    loss_list=np.asarray(loss_list)\n",
    "    acc=np.mean(acc_list)\n",
    "    loss=np.mean(loss_list)\n",
    "    #print 'validate tensorboard' , tensorboard_info\n",
    "\n",
    "    if correct_pred == True:\n",
    "        #print 'correct_pred is True'\n",
    "        return acc , loss , correct_prediction\n",
    "    elif correct_pred == False :\n",
    "        return  acc,  loss\n",
    "\n",
    "def TRAINING(step,batch_xs , batch_ys , tensor_info ,place_info):\n",
    "    msg = '\\r-Progress : {0}/{1}'.format( str(step%check_point), str(check_point))\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    #print '---------------------------- --------training start{0}------------------------------------'.format(step)    \n",
    "    sess.run(tensor_info['train_step'] ,feed_dict={place_info['x_']: batch_xs, \\\n",
    "                                                   place_info['y_']:batch_ys , place_info['keep_prob'] : 0.5 , place_info['phase_train'] :True})\n",
    "def VALIDATE(val_imgs,val_labs,tensor_info,place_info):\n",
    "    start_time=time.time()\n",
    "    val_imgs,val_labs=divide_images(val_imgs , val_labs)\n",
    "    print np.shape(val_imgs)\n",
    "    val_acc, val_loss =validate_from_images(val_imgs ,val_labs ,tensor_info ,place_info) # 이걸 여러개의 쓰레드로 나눠서 실행해야한다\n",
    "    print time.time()-start_time\n",
    "    return val_acc , val_loss\n",
    "\n",
    "def TESTING(test_imgs, test_labs , tensor_info , place_info , training=True):\n",
    "    test_imgs,test_labs=divide_images(test_imgs, test_labs)\n",
    "    test_acc, test_loss =validate_from_images(test_imgs ,test_labs ,tensor_info ,place_info)\n",
    "    print \"test accuracy {0} , test loss {1}\".format(test_acc, test_loss)\n",
    "def save_weights_biases(step , max_acc , val_acc, save_folder ):\n",
    "    if  val_acc  > max_acc:\n",
    "        f=open(save_folder+'step_max_acc.txt','a')\n",
    "        msg='{0}\\t{1}\\n'.format(step , max_acc)\n",
    "        f.write(msg)\n",
    "        max_acc = val_acc  \n",
    "        trainable_list=tf.trainable_variables()\n",
    "        save_paths=[]\n",
    "        for i,ele in enumerate(trainable_list): \n",
    "            #print ele\n",
    "            #print ele.name.replace('/' , '_')\n",
    "            np_=sess.run(ele)\n",
    "            #print 'name:',ele.name\n",
    "            np.save(save_folder+ele.name.replace('/' , '_').replace(':0' , '') , np_ )\n",
    "\n",
    "        print \"model was saved\"\n",
    "        return max_acc\n",
    "    else:\n",
    "        return max_acc\n",
    "\"\"\"\n",
    "    def show_histo(save_folder,global_step):\n",
    "    if show_histo_flag:\n",
    "    if os.path.isdir(save_folder+'histogram/') == False:\n",
    "    os.mkdir(save_folder+'histogram/')\n",
    "    show_histo(save_folder+'histogram/' , step)\n",
    "    print \"making histogram\"\n",
    "    n_trainable=len(tf.trainable_variables())\n",
    "    plot_row=int(math.ceil((math.sqrt(n_trainable))))\n",
    "\n",
    "    plot_col=plot_row \n",
    "    print plot_col , plot_row\n",
    "    fig , axes  = plt.subplots(plot_row ,plot_col ,figsize=(60, 60))\n",
    "\n",
    "    for i , tensor in enumerate(tf.trainable_variables()):\n",
    "        if 'W' in tensor.name or 'B' in tensor.name:\n",
    "            values=sess.run(tensor.name)\n",
    "            values_np = np.asarray(values).flatten()\n",
    "            axes.flat[i].hist(values_np)\n",
    "            axes.flat[i].set_xlabel(tensor.name)\n",
    "    plt.savefig(save_folder+'/weights_and_biases_'+str(global_step)+'.png')\n",
    "    print \"saved histogram! \"\n",
    "    plt.close()\n",
    "\"\"\"\n",
    "def interrupt_mgs():\n",
    "    print \"keyboard Interupted!\"\n",
    "    print(\"--- Training Time : %s ---\" % (time.time() - start_time))\n",
    "    train_time=\"--- Training Time : ---:\\t\" +str(time.time() - start_time)\n",
    "    print \"now start validate Test set by model Don't stop! waiting for a minute...\"\n",
    "\n",
    "    step_np[0]=step\n",
    "    maxacc_np[0] = max_acc\n",
    "    print \"now we start saving accuracy and loss\"\n",
    "    print \"training acc,loss Validation acc and loss was saved!\"        \n",
    "\n",
    "def show_acc_loss( step , val_acc , val_loss):\n",
    "    print(\"step %d , validation  accuracy %g\" %(step,val_acc))\n",
    "    print(\"step %d , validation loss : %g\" %(step,val_loss))\n",
    "\n",
    "def next_batch(batch_size,*args):\n",
    "    \"\"\"\n",
    "    list_number : \n",
    "    Type : list \n",
    "    N.B. the argument list_restricNum is extracted in turn  \n",
    "    from each kwargs element\n",
    "    list_clsNum: \n",
    "    Type : list \n",
    "    N.B. the argument list_clsNum point at number which \n",
    "    each args list is taken   \n",
    "    \"\"\"\n",
    "    #print batch_size\n",
    "    batch_count=0\n",
    "    imgs_list=[]\n",
    "    for i,thing in enumerate(args):\n",
    "        imgs_list.append(thing)\n",
    "    #print 'the number of classes : ',n_classes\n",
    "    ret_imgs=[]\n",
    "    ret_cls=[]\n",
    "    for i in range(batch_size):    \n",
    "        cls_idx=random.randint(0,n_classes-1)\n",
    "        imgs=imgs_list[cls_idx]\n",
    "        imgs=np.asarray(imgs)\n",
    "        n_imgs =np.shape(imgs)[0]\n",
    "        ind=random.randint(0,n_imgs-1)\n",
    "        img=imgs[ind]\n",
    "        #print np.shape(img)\n",
    "        ret_imgs.append(img)\n",
    "        ret_cls.append(cls_idx)\n",
    "    ret_imgs=np.asarray(ret_imgs)\n",
    "    ret_cls=np.asarray(ret_cls)\n",
    "    ret_labs=cls2onehot(n_classes,ret_cls)\n",
    "    return ret_imgs , ret_labs\n",
    "\n",
    "def next_random_batch(image , label ):\n",
    "    indices=random.sample(range(np.shape(image)[0])  , batch_size)\n",
    "    batch_x = image[indices]\n",
    "    batch_y= label[indices]\n",
    "    return batch_x, batch_y\n",
    "\n",
    "def next_batch_list(image_list , label_list , selected_list= None ):\n",
    "    \"\"\"\n",
    "    image_list shape taken 5 shape : [n_ , batch , row , col , in_ch]\n",
    "    3rd param 'list_' taken list that include which number run\n",
    "    \"\"\"\n",
    "    if selected_list != None:\n",
    "        random.shuffle(selected_list)\n",
    "        ind=selected_list[0]\n",
    "        #print 'selected_list'\n",
    "        #print 'ind',ind\n",
    "    elif selected_list == None:\n",
    "        ind=np.random.randint(len(image_list))\n",
    "    batch_x , batch_y=next_batch(image_list[ind] , label_list[ind] )\n",
    "    return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VALIDATE_FROM_TRAIN(indices):\n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    correct_list=[]\n",
    "    n_batch , row , col , input_ch =np.shape(train_imgs_list[0])\n",
    "    for i in indices:\n",
    "        imgs, labs =divide_images(train_imgs_list[i] ,train_labs_list[i] )\n",
    "        acc ,loss , correct_=validate_from_images(imgs , labs, tensor_info , place_info , correct_pred=True)\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "        correct_list.extend(correct_)\n",
    "        \n",
    "    share =  len(train_imgs_list[i])/ batch_size \n",
    "    remainder = len(train_imgs_list[i])%batch_size\n",
    "    temp_correct_=[]\n",
    "    for k in range(len(indices)):\n",
    "        list_=correct_list[ (k*n_batch) + k*(n_batch - remainder)  : (k+1)*n_batch + k*(n_batch - remainder) ]\n",
    "        temp_correct_.extend(list_)\n",
    "    correct_list=np.asarray(temp_correct_)\n",
    "    acc=np.mean(correct_list)\n",
    "    print len(correct_list)\n",
    "    return acc , loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(log_path,save_path):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_point=100\n",
    "step=0\n",
    "def BATCH_TRAINING_RANDOM(maxiter, tensor_info, place_info,save_folder,restore_path,tensorboard_info=None , val_img_lab =None , test_img_lab=None):\n",
    "    try:\n",
    "        max_acc=0\n",
    "        make_folder(save_folder)\n",
    "        start_step,max_acc=load_step_acc(restore_path)\n",
    "        #val_imgs,val_labs=load_val()\n",
    "        for i in range(int(start_step), maxiter):\n",
    "            step=i\n",
    "            if step%check_point==0: #여기 if loop에서 validate을 합니다     \n",
    "                cat_val_acc,cat_val_loss=VALIDATE(ret_imgs[-300:], ret_labs[-300:],tensor_info , place_info)\n",
    "                #ret_acc,ret_loss=VALIDATE(ret_imgs[-100:], ret_labs[-100:],tensor_info , place_info)\n",
    "                #gla_acc,gla_loss=VALIDATE(gla_imgs[-100:], gla_labs[-100:],tensor_info , place_info)\n",
    "                normal_1_acc,normal_1_loss=VALIDATE(normal_1_imgs[-300:], normal_1_labs[-300:],tensor_info , place_info)\n",
    "                total_acc=(cat_val_acc +normal_1_acc)/2\n",
    "                total_loss=(cat_val_loss +normal_1_loss)/2\n",
    "                \n",
    "                show_acc_loss(step,cat_val_acc , cat_val_loss) \n",
    "                #show_acc_loss(step,ret_acc,ret_loss) \n",
    "                #show_acc_loss(step,gla_acc,gla_loss) \n",
    "                show_acc_loss(step,normal_1_acc,normal_1_loss) \n",
    "\n",
    "                #val_acc=float(val_acc)\n",
    "                #max_acc=float(max_acc)\n",
    "                #if val_acc > max_acc:\n",
    "                #    print 'val_acc > max_acc'\n",
    "                #    max_acc = val_acc\n",
    "                #print 'max_acc', max_acc\n",
    "            batch_xs ,batch_ys=next_batch(batch_size , ret_imgs[:-300],normal_1_imgs[:-300])\n",
    "            TRAINING(step,batch_xs , batch_ys,tensor_info,place_info)\n",
    "        test_imgs, test_labs=load_test()\n",
    "        test_acc, test_loss=TESTING(test_imgs, test_labs,tensor_info)\n",
    "    except KeyboardInterrupt as kbie:\n",
    "        interrupt_mgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_folder='./LAB_1/'\n",
    "restore_path='./LAB_1/best_acc/'\n",
    "restore_flag=False\n",
    "device_='/gpu:1'\n",
    "bn_flag=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 288, 288, 3)\n",
      "PRE make weigths and biases\n",
      "(30, 75, 75, 64)\n",
      "STEM_A_1 make weigths and biases\n",
      "STEM_A_2 make weigths and biases\n",
      "STEM_A_3 make weigths and biases\n",
      "STEM_A_4 make weigths and biases\n",
      "STEM_B_1 make weigths and biases\n",
      "STEM_B_2 make weigths and biases\n",
      "STEM_B_3 make weigths and biases\n",
      "STEM_B_4 make weigths and biases\n",
      "b_STEM_B_1 make weigths and biases\n",
      "b_STEM_B_2 make weigths and biases\n",
      "STEM_C_1 make weigths and biases\n",
      "MODUEL_A_a_1 make weigths and biases\n",
      "MODUEL_A_a_2 make weigths and biases\n",
      "b1_MODUEL_A_a make weigths and biases\n",
      "b2_MODUEL_A_a make weigths and biases\n",
      "b3_MODUEL_A_a_1 make weigths and biases\n",
      "b3_MODUEL_A_a_2 make weigths and biases\n",
      "b3_MODUEL_A_a_3 make weigths and biases\n",
      "Tensor(\"MODUEL_A_a_end/concat:0\", shape=(30, 15, 15, 384), dtype=float32)\n",
      "FC_C make weigths and biases\n",
      "Tensor(\"h_fc1_dropout/mul:0\", shape=(30, 1024), dtype=float32, device=/device:GPU:1)\n",
      "FC_C_end make weigths and biases\n",
      "(86400, 1024)\n",
      "Tensor(\"add_1:0\", shape=(30, 2), dtype=float32, device=/device:GPU:1)\n"
     ]
    }
   ],
   "source": [
    "images=tf.map_fn (lambda image: pre_processing(image) ,x_)\n",
    "print images.get_shape()\n",
    "PRE=PRE_LAYER(x_ , device_,'PRE',64 , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "A=STEM_A(PRE , device_,'STEM_A',(32,32,64,96) , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "B=STEM_B(A , device_,'STEM_B', place_info  , bn_flag  , restore_flag , restore_path)\n",
    "C=STEM_C(B , device_,'STEM_C' , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "D=INCEPTION_MODULE_A(C, device_,'MODUEL_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#E=INCEPTION_MODULE_A(D, device_,'MODUEL_A_b',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#F=INCEPTION_MODULE_A(E, device_,'MODUEL_A_c',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#G=INCEPTION_MODULE_A(F, device_,'MODUEL_A_d',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_REDUCTION_A(G,device_,'REDUCT_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_MODULE_A(G, device_,'MODUEL_A_e',place_info ,bn_flag, restore_flag , restore_path)\n",
    "flat_ = FLAT(D , device_ , layer_name='FLAT_')\n",
    "y_conv=FC_C(flat_ , 0.5 , n_classes , device_ , 'FC_C' , restore_flag , restore_path)\n",
    "print y_conv\n",
    "tensor_info=TRAIN_STRUCTURE_A(y_conv , y_ , device_ , learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "images=tf.map_fn (lambda image: pre_processing(image) ,x_)\n",
    "print images.get_shape()\n",
    "PRE=PRE_LAYER(x_ , device_,'PRE',64 , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "A=CONV_1(PRE , device_  ,'CONV_1_a' , 128 , (5,5),[1,1,1,1] , 'SAME' ,place_info, bn_flag  , restore_flag , restore_path)\n",
    "MAX_A=MAX_POOL(A,[1,2,2,1],[1,2,2,1],'SAME','MAX_POOL_1_a',device_)\n",
    "B=CONV_1(MAX_A , device_  ,'CONV_2_a' , 184, (3,3),[1,1,1,1] , 'SAME' ,place_info, bn_flag  , restore_flag , restore_path)\n",
    "MAX_B=MAX_POOL(B,[1,2,2,1],[1,2,2,1],'SAME','MAX_POOL_2_a',device_)\n",
    "#A=STEM_A(PRE , device_,'STEM_A',(32,32,64,96) , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#B=STEM_B(A , device_,'STEM_B', place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#C=STEM_C(B , device_,'STEM_C' , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#D=INCEPTION_MODULE_A(C, device_,'MODUEL_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#E=INCEPTION_MODULE_A(D, device_,'MODUEL_A_b',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#F=INCEPTION_MODULE_A(E, device_,'MODUEL_A_c',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#G=INCEPTION_MODULE_A(F, device_,'MODUEL_A_d',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_REDUCTION_A(G,device_,'REDUCT_A_a',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_MODULE_A(G, device_,'MODUEL_A_e',place_info ,bn_flag, restore_flag , restore_path)\n",
    "flat_ = FLAT(MAX_B , device_ , layer_name='FLAT_')\n",
    "y_conv=FC_C(flat_ , 0.5 , n_classes , device_ , 'FC_C' , restore_flag , restore_path)\n",
    "print y_conv\n",
    "tensor_info=TRAIN_STRUCTURE_A(y_conv , y_ , device_ , learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "device__='/gpu:2'\n",
    "#_PRE=PRE_LAYER(images , device__,'PRE_2th',32 , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "_A=STEM_A(x_ , device__,'STEM_A_2th',(32,32,64,96) , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "_B=STEM_B(_A , device__,'STEM_B_2th', place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#_C=STEM_C(_B , device__,'STEM_C_2th' , place_info  , bn_flag  , restore_flag , restore_path)\n",
    "#_D=INCEPTION_MODULE_A(_C, device__,'MODUEL_A_a_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_E=INCEPTION_MODULE_A(_D, device__,'MODUEL_A_b_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_F=INCEPTION_MODULE_A(_E, device__,'MODUEL_A_c_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_G=INCEPTION_MODULE_A(_F, device__,'MODUEL_A_d_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#_H=INCEPTION_REDUCTION_A(_G,device__,'REDUCT_A_a_2th',place_info ,bn_flag, restore_flag , restore_path)\n",
    "#H=INCEPTION_MODULE_A(G, device_,'MODUEL_A_e',place_info ,bn_flag, restore_flag , restore_path)\n",
    "\n",
    "_flat=FLAT(_B,device__,layer_name='FLAT_2tsth')\n",
    "_y_conv=FC_C(_flat ,0.5, n_classes ,device__, 'FC_C_2th',restore_flag , restore_path)\n",
    "_tensor_info=TRAIN_STRUCTURE_A(_y_conv , y_2 , device__ , learning_rate = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-48-10a424e6d7f3>:5 in START_SESS.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "sess=START_SESS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step and max_acc was restore!\n",
      "global step: 0\n",
      "Max acc: 0\n",
      "\n",
      "(11, 30, 300, 300, 3)\n",
      "2.57384181023\n",
      "(11, 30, 300, 300, 3)\n",
      "0.718773126602\n",
      "step 0 , validation  accuracy 0.651515\n",
      "step 0 , validation loss : 0.771799\n",
      "step 0 , validation  accuracy 0.333333\n",
      "step 0 , validation loss : 1.67859\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.737827062607\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705290079117\n",
      "step 100 , validation  accuracy 0.948485\n",
      "step 100 , validation loss : 4.70848\n",
      "step 100 , validation  accuracy 0.0272727\n",
      "step 100 , validation loss : 135.468\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694058895111\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694045066833\n",
      "step 200 , validation  accuracy 0.687879\n",
      "step 200 , validation loss : 4.1239\n",
      "step 200 , validation  accuracy 0.284849\n",
      "step 200 , validation loss : 14.5703\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.741234064102\n",
      "(11, 30, 300, 300, 3)\n",
      "0.707885980606\n",
      "step 300 , validation  accuracy 0.0878788\n",
      "step 300 , validation loss : 11.3803\n",
      "step 300 , validation  accuracy 0.866667\n",
      "step 300 , validation loss : 3.73084\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.726367235184\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688194990158\n",
      "step 400 , validation  accuracy 0.245455\n",
      "step 400 , validation loss : 3.2564\n",
      "step 400 , validation  accuracy 0.8\n",
      "step 400 , validation loss : 0.599589\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705618143082\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690567970276\n",
      "step 500 , validation  accuracy 0.781818\n",
      "step 500 , validation loss : 0.465885\n",
      "step 500 , validation  accuracy 0.242424\n",
      "step 500 , validation loss : 1.91703\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693527936935\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683919906616\n",
      "step 600 , validation  accuracy 0.651515\n",
      "step 600 , validation loss : 0.759567\n",
      "step 600 , validation  accuracy 0.442424\n",
      "step 600 , validation loss : 0.974841\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.72435593605\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701244831085\n",
      "step 700 , validation  accuracy 0.512121\n",
      "step 700 , validation loss : 0.922267\n",
      "step 700 , validation  accuracy 0.548485\n",
      "step 700 , validation loss : 0.709518\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690526008606\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678481817245\n",
      "step 800 , validation  accuracy 0.260606\n",
      "step 800 , validation loss : 1.46477\n",
      "step 800 , validation  accuracy 0.727273\n",
      "step 800 , validation loss : 0.435086\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703325986862\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678949117661\n",
      "step 900 , validation  accuracy 0.851515\n",
      "step 900 , validation loss : 0.494972\n",
      "step 900 , validation  accuracy 0.160606\n",
      "step 900 , validation loss : 1.08225\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693308115005\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686821937561\n",
      "step 1000 , validation  accuracy 0.666667\n",
      "step 1000 , validation loss : 0.626996\n",
      "step 1000 , validation  accuracy 0.351515\n",
      "step 1000 , validation loss : 0.833518\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68181014061\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685885190964\n",
      "step 1100 , validation  accuracy 0.557576\n",
      "step 1100 , validation loss : 0.692121\n",
      "step 1100 , validation  accuracy 0.427273\n",
      "step 1100 , validation loss : 0.767363\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706012964249\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689053058624\n",
      "step 1200 , validation  accuracy 0.775758\n",
      "step 1200 , validation loss : 0.534451\n",
      "step 1200 , validation  accuracy 0.278788\n",
      "step 1200 , validation loss : 0.957083\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684705018997\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701502799988\n",
      "step 1300 , validation  accuracy 0.484848\n",
      "step 1300 , validation loss : 0.888991\n",
      "step 1300 , validation  accuracy 0.536364\n",
      "step 1300 , validation loss : 0.637042\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694493055344\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706453084946\n",
      "step 1400 , validation  accuracy 0.224242\n",
      "step 1400 , validation loss : 0.901778\n",
      "step 1400 , validation  accuracy 0.815152\n",
      "step 1400 , validation loss : 0.5471\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689755916595\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690076828003\n",
      "step 1500 , validation  accuracy 0.312121\n",
      "step 1500 , validation loss : 0.825332\n",
      "step 1500 , validation  accuracy 0.745455\n",
      "step 1500 , validation loss : 0.611497\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687909126282\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682228088379\n",
      "step 1600 , validation  accuracy 0.681818\n",
      "step 1600 , validation loss : 0.628535\n",
      "step 1600 , validation  accuracy 0.354546\n",
      "step 1600 , validation loss : 0.787833\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682989835739\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684340953827\n",
      "step 1700 , validation  accuracy 0.487879\n",
      "step 1700 , validation loss : 0.832636\n",
      "step 1700 , validation  accuracy 0.524242\n",
      "step 1700 , validation loss : 0.641278\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694301843643\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699795007706\n",
      "step 1800 , validation  accuracy 0.381818\n",
      "step 1800 , validation loss : 0.749715\n",
      "step 1800 , validation  accuracy 0.633333\n",
      "step 1800 , validation loss : 0.663343\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696356058121\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675988912582\n",
      "step 1900 , validation  accuracy 0.569697\n",
      "step 1900 , validation loss : 0.673071\n",
      "step 1900 , validation  accuracy 0.442424\n",
      "step 1900 , validation loss : 0.728466\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68750500679\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690746068954\n",
      "step 2000 , validation  accuracy 0.284848\n",
      "step 2000 , validation loss : 0.787691\n",
      "step 2000 , validation  accuracy 0.745455\n",
      "step 2000 , validation loss : 0.628163\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687131881714\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694086074829\n",
      "step 2100 , validation  accuracy 0.548485\n",
      "step 2100 , validation loss : 0.683386\n",
      "step 2100 , validation  accuracy 0.487879\n",
      "step 2100 , validation loss : 0.722299\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690485954285\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68008685112\n",
      "step 2200 , validation  accuracy 0.309091\n",
      "step 2200 , validation loss : 0.875778\n",
      "step 2200 , validation  accuracy 0.70303\n",
      "step 2200 , validation loss : 0.568755\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697244167328\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706484079361\n",
      "step 2300 , validation  accuracy 0.3\n",
      "step 2300 , validation loss : 0.795471\n",
      "step 2300 , validation  accuracy 0.69697\n",
      "step 2300 , validation loss : 0.620547\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682566165924\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680363893509\n",
      "step 2400 , validation  accuracy 0.551515\n",
      "step 2400 , validation loss : 0.673825\n",
      "step 2400 , validation  accuracy 0.469697\n",
      "step 2400 , validation loss : 0.736571\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.71261715889\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698820114136\n",
      "step 2500 , validation  accuracy 0.518182\n",
      "step 2500 , validation loss : 0.695118\n",
      "step 2500 , validation  accuracy 0.524242\n",
      "step 2500 , validation loss : 0.720283\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689383029938\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683741092682\n",
      "step 2600 , validation  accuracy 0.30303\n",
      "step 2600 , validation loss : 0.80667\n",
      "step 2600 , validation  accuracy 0.709091\n",
      "step 2600 , validation loss : 0.604859\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705096006393\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690155029297\n",
      "step 2700 , validation  accuracy 0.521212\n",
      "step 2700 , validation loss : 0.689742\n",
      "step 2700 , validation  accuracy 0.512121\n",
      "step 2700 , validation loss : 0.711671\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689553022385\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681807994843\n",
      "step 2800 , validation  accuracy 0.227273\n",
      "step 2800 , validation loss : 0.955706\n",
      "step 2800 , validation  accuracy 0.775758\n",
      "step 2800 , validation loss : 0.514037\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701061010361\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688665866852\n",
      "step 2900 , validation  accuracy 0.166667\n",
      "step 2900 , validation loss : 0.904766\n",
      "step 2900 , validation  accuracy 0.890909\n",
      "step 2900 , validation loss : 0.516126\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678406000137\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693822860718\n",
      "step 3000 , validation  accuracy 0.309091\n",
      "step 3000 , validation loss : 0.808464\n",
      "step 3000 , validation  accuracy 0.727273\n",
      "step 3000 , validation loss : 0.592411\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680597066879\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692342042923\n",
      "step 3100 , validation  accuracy 0.633333\n",
      "step 3100 , validation loss : 0.671058\n",
      "step 3100 , validation  accuracy 0.448485\n",
      "step 3100 , validation loss : 0.716245\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695991039276\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680116891861\n",
      "step 3200 , validation  accuracy 0.563636\n",
      "step 3200 , validation loss : 0.679936\n",
      "step 3200 , validation  accuracy 0.521212\n",
      "step 3200 , validation loss : 0.697836\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676523208618\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69973897934\n",
      "step 3300 , validation  accuracy 0.49697\n",
      "step 3300 , validation loss : 0.717684\n",
      "step 3300 , validation  accuracy 0.548485\n",
      "step 3300 , validation loss : 0.670105\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695732831955\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694107055664\n",
      "step 3400 , validation  accuracy 0.484849\n",
      "step 3400 , validation loss : 0.731597\n",
      "step 3400 , validation  accuracy 0.6\n",
      "step 3400 , validation loss : 0.642029\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674754858017\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688797950745\n",
      "step 3500 , validation  accuracy 0.339394\n",
      "step 3500 , validation loss : 0.813967\n",
      "step 3500 , validation  accuracy 0.739394\n",
      "step 3500 , validation loss : 0.582396\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705793857574\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698581933975\n",
      "step 3600 , validation  accuracy 0.354546\n",
      "step 3600 , validation loss : 0.826974\n",
      "step 3600 , validation  accuracy 0.669697\n",
      "step 3600 , validation loss : 0.576062\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689128160477\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698246002197\n",
      "step 3700 , validation  accuracy 0.409091\n",
      "step 3700 , validation loss : 0.748249\n",
      "step 3700 , validation  accuracy 0.657576\n",
      "step 3700 , validation loss : 0.632843\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686226844788\n",
      "(11, 30, 300, 300, 3)\n",
      "0.708247900009\n",
      "step 3800 , validation  accuracy 0.342424\n",
      "step 3800 , validation loss : 0.814331\n",
      "step 3800 , validation  accuracy 0.730303\n",
      "step 3800 , validation loss : 0.574668\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6774289608\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683510065079\n",
      "step 3900 , validation  accuracy 0.430303\n",
      "step 3900 , validation loss : 0.743646\n",
      "step 3900 , validation  accuracy 0.642424\n",
      "step 3900 , validation loss : 0.643929\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697885036469\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681099891663\n",
      "step 4000 , validation  accuracy 0.293939\n",
      "step 4000 , validation loss : 0.806169\n",
      "step 4000 , validation  accuracy 0.812121\n",
      "step 4000 , validation loss : 0.553285\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686177015305\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694849967957\n",
      "step 4100 , validation  accuracy 0.515152\n",
      "step 4100 , validation loss : 0.70884\n",
      "step 4100 , validation  accuracy 0.584849\n",
      "step 4100 , validation loss : 0.666156\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685334920883\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680296897888\n",
      "step 4200 , validation  accuracy 0.445455\n",
      "step 4200 , validation loss : 0.742269\n",
      "step 4200 , validation  accuracy 0.648485\n",
      "step 4200 , validation loss : 0.643606\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685302019119\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689923048019\n",
      "step 4300 , validation  accuracy 0.5\n",
      "step 4300 , validation loss : 0.721498\n",
      "step 4300 , validation  accuracy 0.590909\n",
      "step 4300 , validation loss : 0.644396\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69095993042\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695312976837\n",
      "step 4400 , validation  accuracy 0.515152\n",
      "step 4400 , validation loss : 0.74102\n",
      "step 4400 , validation  accuracy 0.572727\n",
      "step 4400 , validation loss : 0.651224\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693303823471\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69146490097\n",
      "step 4500 , validation  accuracy 0.518182\n",
      "step 4500 , validation loss : 0.696958\n",
      "step 4500 , validation  accuracy 0.6\n",
      "step 4500 , validation loss : 0.668426\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673084020615\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689800024033\n",
      "step 4600 , validation  accuracy 0.633333\n",
      "step 4600 , validation loss : 0.650738\n",
      "step 4600 , validation  accuracy 0.50303\n",
      "step 4600 , validation loss : 0.711066\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697687149048\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68879699707\n",
      "step 4700 , validation  accuracy 0.475758\n",
      "step 4700 , validation loss : 0.721493\n",
      "step 4700 , validation  accuracy 0.630303\n",
      "step 4700 , validation loss : 0.626532\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69414305687\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691095113754\n",
      "step 4800 , validation  accuracy 0.512121\n",
      "step 4800 , validation loss : 0.695726\n",
      "step 4800 , validation  accuracy 0.621212\n",
      "step 4800 , validation loss : 0.656905\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705674886703\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698641061783\n",
      "step 4900 , validation  accuracy 0.630303\n",
      "step 4900 , validation loss : 0.664455\n",
      "step 4900 , validation  accuracy 0.5\n",
      "step 4900 , validation loss : 0.702286\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695942878723\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682392120361\n",
      "step 5000 , validation  accuracy 0.533333\n",
      "step 5000 , validation loss : 0.686931\n",
      "step 5000 , validation  accuracy 0.618182\n",
      "step 5000 , validation loss : 0.646803\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677565097809\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695060014725\n",
      "step 5100 , validation  accuracy 0.575758\n",
      "step 5100 , validation loss : 0.69697\n",
      "step 5100 , validation  accuracy 0.545455\n",
      "step 5100 , validation loss : 0.669666\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706660032272\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69401216507\n",
      "step 5200 , validation  accuracy 0.306061\n",
      "step 5200 , validation loss : 0.871785\n",
      "step 5200 , validation  accuracy 0.751515\n",
      "step 5200 , validation loss : 0.527696\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691351175308\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69703578949\n",
      "step 5300 , validation  accuracy 0.721212\n",
      "step 5300 , validation loss : 0.607276\n",
      "step 5300 , validation  accuracy 0.451515\n",
      "step 5300 , validation loss : 0.744082\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694566965103\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692568063736\n",
      "step 5400 , validation  accuracy 0.363636\n",
      "step 5400 , validation loss : 0.753735\n",
      "step 5400 , validation  accuracy 0.772727\n",
      "step 5400 , validation loss : 0.59939\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686740159988\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687334060669\n",
      "step 5500 , validation  accuracy 0.524242\n",
      "step 5500 , validation loss : 0.691142\n",
      "step 5500 , validation  accuracy 0.621212\n",
      "step 5500 , validation loss : 0.657044\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699808835983\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699865102768\n",
      "step 5600 , validation  accuracy 0.730303\n",
      "step 5600 , validation loss : 0.630972\n",
      "step 5600 , validation  accuracy 0.49697\n",
      "step 5600 , validation loss : 0.729107\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689260959625\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677263021469\n",
      "step 5700 , validation  accuracy 0.460606\n",
      "step 5700 , validation loss : 0.726224\n",
      "step 5700 , validation  accuracy 0.675758\n",
      "step 5700 , validation loss : 0.634275\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702956199646\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685757875443\n",
      "step 5800 , validation  accuracy 0.618182\n",
      "step 5800 , validation loss : 0.662436\n",
      "step 5800 , validation  accuracy 0.578788\n",
      "step 5800 , validation loss : 0.691873\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678562879562\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681818962097\n",
      "step 5900 , validation  accuracy 0.293939\n",
      "step 5900 , validation loss : 0.757805\n",
      "step 5900 , validation  accuracy 0.851515\n",
      "step 5900 , validation loss : 0.600952\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682814121246\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690843105316\n",
      "step 6000 , validation  accuracy 0.478788\n",
      "step 6000 , validation loss : 0.76079\n",
      "step 6000 , validation  accuracy 0.645455\n",
      "step 6000 , validation loss : 0.620052\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692327022552\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69701218605\n",
      "step 6100 , validation  accuracy 0.506061\n",
      "step 6100 , validation loss : 0.694218\n",
      "step 6100 , validation  accuracy 0.663636\n",
      "step 6100 , validation loss : 0.668416\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685768127441\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690322875977\n",
      "step 6200 , validation  accuracy 0.469697\n",
      "step 6200 , validation loss : 0.735152\n",
      "step 6200 , validation  accuracy 0.721212\n",
      "step 6200 , validation loss : 0.593295\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.711822032928\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686283826828\n",
      "step 6300 , validation  accuracy 0.530303\n",
      "step 6300 , validation loss : 0.70119\n",
      "step 6300 , validation  accuracy 0.651515\n",
      "step 6300 , validation loss : 0.642302\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680233001709\n",
      "(11, 30, 300, 300, 3)\n",
      "0.711720943451\n",
      "step 6400 , validation  accuracy 0.642424\n",
      "step 6400 , validation loss : 0.60333\n",
      "step 6400 , validation  accuracy 0.524242\n",
      "step 6400 , validation loss : 0.747616\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696822881699\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690318107605\n",
      "step 6500 , validation  accuracy 0.578788\n",
      "step 6500 , validation loss : 0.66497\n",
      "step 6500 , validation  accuracy 0.624242\n",
      "step 6500 , validation loss : 0.68316\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695149898529\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684344053268\n",
      "step 6600 , validation  accuracy 0.454545\n",
      "step 6600 , validation loss : 0.739475\n",
      "step 6600 , validation  accuracy 0.690909\n",
      "step 6600 , validation loss : 0.62029\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700611829758\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691583156586\n",
      "step 6700 , validation  accuracy 0.681818\n",
      "step 6700 , validation loss : 0.622479\n",
      "step 6700 , validation  accuracy 0.524242\n",
      "step 6700 , validation loss : 0.724442\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684429168701\n",
      "(11, 30, 300, 300, 3)\n",
      "0.721725940704\n",
      "step 6800 , validation  accuracy 0.418182\n",
      "step 6800 , validation loss : 0.76664\n",
      "step 6800 , validation  accuracy 0.745455\n",
      "step 6800 , validation loss : 0.571798\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.671777963638\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690719127655\n",
      "step 6900 , validation  accuracy 0.733333\n",
      "step 6900 , validation loss : 0.624155\n",
      "step 6900 , validation  accuracy 0.424242\n",
      "step 6900 , validation loss : 0.725687\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70224905014\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706209897995\n",
      "step 7000 , validation  accuracy 0.49697\n",
      "step 7000 , validation loss : 0.698563\n",
      "step 7000 , validation  accuracy 0.648485\n",
      "step 7000 , validation loss : 0.640029\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686053991318\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68833899498\n",
      "step 7100 , validation  accuracy 0.530303\n",
      "step 7100 , validation loss : 0.716213\n",
      "step 7100 , validation  accuracy 0.624242\n",
      "step 7100 , validation loss : 0.624387\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684489011765\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681313991547\n",
      "step 7200 , validation  accuracy 0.339394\n",
      "step 7200 , validation loss : 0.798641\n",
      "step 7200 , validation  accuracy 0.8\n",
      "step 7200 , validation loss : 0.558646\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688014030457\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6927318573\n",
      "step 7300 , validation  accuracy 0.475758\n",
      "step 7300 , validation loss : 0.767617\n",
      "step 7300 , validation  accuracy 0.675758\n",
      "step 7300 , validation loss : 0.570753\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696728944778\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687231063843\n",
      "step 7400 , validation  accuracy 0.578788\n",
      "step 7400 , validation loss : 0.689475\n",
      "step 7400 , validation  accuracy 0.575758\n",
      "step 7400 , validation loss : 0.663279\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673271894455\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683857917786\n",
      "step 7500 , validation  accuracy 0.621212\n",
      "step 7500 , validation loss : 0.669421\n",
      "step 7500 , validation  accuracy 0.590909\n",
      "step 7500 , validation loss : 0.659735\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700520038605\n",
      "(11, 30, 300, 300, 3)\n",
      "0.717602014542\n",
      "step 7600 , validation  accuracy 0.527273\n",
      "step 7600 , validation loss : 0.675006\n",
      "step 7600 , validation  accuracy 0.627273\n",
      "step 7600 , validation loss : 0.683924\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695018053055\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685899019241\n",
      "step 7700 , validation  accuracy 0.721212\n",
      "step 7700 , validation loss : 0.635504\n",
      "step 7700 , validation  accuracy 0.415152\n",
      "step 7700 , validation loss : 0.718356\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690781831741\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695060014725\n",
      "step 7800 , validation  accuracy 0.736364\n",
      "step 7800 , validation loss : 0.587437\n",
      "step 7800 , validation  accuracy 0.375758\n",
      "step 7800 , validation loss : 0.815904\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687152147293\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688704967499\n",
      "step 7900 , validation  accuracy 0.506061\n",
      "step 7900 , validation loss : 0.727712\n",
      "step 7900 , validation  accuracy 0.651515\n",
      "step 7900 , validation loss : 0.622013\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680160045624\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689789056778\n",
      "step 8000 , validation  accuracy 0.481818\n",
      "step 8000 , validation loss : 0.709278\n",
      "step 8000 , validation  accuracy 0.636364\n",
      "step 8000 , validation loss : 0.644133\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70628619194\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68895816803\n",
      "step 8100 , validation  accuracy 0.39697\n",
      "step 8100 , validation loss : 0.781144\n",
      "step 8100 , validation  accuracy 0.778788\n",
      "step 8100 , validation loss : 0.561227\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68655705452\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693351984024\n",
      "step 8200 , validation  accuracy 0.490909\n",
      "step 8200 , validation loss : 0.694642\n",
      "step 8200 , validation  accuracy 0.660606\n",
      "step 8200 , validation loss : 0.650638\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682010889053\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677155017853\n",
      "step 8300 , validation  accuracy 0.557576\n",
      "step 8300 , validation loss : 0.67045\n",
      "step 8300 , validation  accuracy 0.60303\n",
      "step 8300 , validation loss : 0.687731\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675222158432\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6850938797\n",
      "step 8400 , validation  accuracy 0.321212\n",
      "step 8400 , validation loss : 0.751394\n",
      "step 8400 , validation  accuracy 0.821212\n",
      "step 8400 , validation loss : 0.574989\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690294981003\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68944811821\n",
      "step 8500 , validation  accuracy 0.363636\n",
      "step 8500 , validation loss : 0.786781\n",
      "step 8500 , validation  accuracy 0.763636\n",
      "step 8500 , validation loss : 0.538463\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680881023407\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690393209457\n",
      "step 8600 , validation  accuracy 0.530303\n",
      "step 8600 , validation loss : 0.713954\n",
      "step 8600 , validation  accuracy 0.59394\n",
      "step 8600 , validation loss : 0.664819\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697969913483\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677052021027\n",
      "step 8700 , validation  accuracy 0.506061\n",
      "step 8700 , validation loss : 0.717003\n",
      "step 8700 , validation  accuracy 0.633333\n",
      "step 8700 , validation loss : 0.624608\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.672780036926\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697041034698\n",
      "step 8800 , validation  accuracy 0.70303\n",
      "step 8800 , validation loss : 0.588668\n",
      "step 8800 , validation  accuracy 0.448485\n",
      "step 8800 , validation loss : 0.76725\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677678108215\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68910908699\n",
      "step 8900 , validation  accuracy 0.384849\n",
      "step 8900 , validation loss : 0.806104\n",
      "step 8900 , validation  accuracy 0.778788\n",
      "step 8900 , validation loss : 0.53846\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694680929184\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698266983032\n",
      "step 9000 , validation  accuracy 0.366667\n",
      "step 9000 , validation loss : 0.781498\n",
      "step 9000 , validation  accuracy 0.793939\n",
      "step 9000 , validation loss : 0.534714\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692001104355\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684840917587\n",
      "step 9100 , validation  accuracy 0.448485\n",
      "step 9100 , validation loss : 0.718353\n",
      "step 9100 , validation  accuracy 0.69697\n",
      "step 9100 , validation loss : 0.617037\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701755046844\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683474063873\n",
      "step 9200 , validation  accuracy 0.412121\n",
      "step 9200 , validation loss : 0.740594\n",
      "step 9200 , validation  accuracy 0.693939\n",
      "step 9200 , validation loss : 0.611027\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686368942261\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683249950409\n",
      "step 9300 , validation  accuracy 0.324242\n",
      "step 9300 , validation loss : 0.806224\n",
      "step 9300 , validation  accuracy 0.760606\n",
      "step 9300 , validation loss : 0.54761\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696334123611\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68331694603\n",
      "step 9400 , validation  accuracy 0.221212\n",
      "step 9400 , validation loss : 1.00798\n",
      "step 9400 , validation  accuracy 0.854546\n",
      "step 9400 , validation loss : 0.422889\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687596082687\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679811954498\n",
      "step 9500 , validation  accuracy 0.375758\n",
      "step 9500 , validation loss : 0.765734\n",
      "step 9500 , validation  accuracy 0.772727\n",
      "step 9500 , validation loss : 0.576361\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696868896484\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699724912643\n",
      "step 9600 , validation  accuracy 0.321212\n",
      "step 9600 , validation loss : 0.913875\n",
      "step 9600 , validation  accuracy 0.809091\n",
      "step 9600 , validation loss : 0.480977\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685375928879\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68839097023\n",
      "step 9700 , validation  accuracy 0.484848\n",
      "step 9700 , validation loss : 0.718329\n",
      "step 9700 , validation  accuracy 0.660606\n",
      "step 9700 , validation loss : 0.621575\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700048923492\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695803880692\n",
      "step 9800 , validation  accuracy 0.463636\n",
      "step 9800 , validation loss : 0.806449\n",
      "step 9800 , validation  accuracy 0.660606\n",
      "step 9800 , validation loss : 0.596729\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684739112854\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683586120605\n",
      "step 9900 , validation  accuracy 0.451515\n",
      "step 9900 , validation loss : 0.718934\n",
      "step 9900 , validation  accuracy 0.687879\n",
      "step 9900 , validation loss : 0.608003\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680338859558\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685643911362\n",
      "step 10000 , validation  accuracy 0.669697\n",
      "step 10000 , validation loss : 0.60903\n",
      "step 10000 , validation  accuracy 0.545455\n",
      "step 10000 , validation loss : 0.715825\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695168972015\n",
      "(11, 30, 300, 300, 3)\n",
      "0.702534914017\n",
      "step 10100 , validation  accuracy 0.224242\n",
      "step 10100 , validation loss : 0.959474\n",
      "step 10100 , validation  accuracy 0.881818\n",
      "step 10100 , validation loss : 0.446249\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683220148087\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699955940247\n",
      "step 10200 , validation  accuracy 0.493939\n",
      "step 10200 , validation loss : 0.731113\n",
      "step 10200 , validation  accuracy 0.70303\n",
      "step 10200 , validation loss : 0.597139\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696318864822\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693132162094\n",
      "step 10300 , validation  accuracy 0.412121\n",
      "step 10300 , validation loss : 0.767874\n",
      "step 10300 , validation  accuracy 0.775758\n",
      "step 10300 , validation loss : 0.542991\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683566808701\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679999113083\n",
      "step 10400 , validation  accuracy 0.2\n",
      "step 10400 , validation loss : 1.03107\n",
      "step 10400 , validation  accuracy 0.9\n",
      "step 10400 , validation loss : 0.383154\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702242136002\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683874845505\n",
      "step 10500 , validation  accuracy 0.306061\n",
      "step 10500 , validation loss : 0.945637\n",
      "step 10500 , validation  accuracy 0.80303\n",
      "step 10500 , validation loss : 0.47092\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687269210815\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692669868469\n",
      "step 10600 , validation  accuracy 0.469697\n",
      "step 10600 , validation loss : 0.731336\n",
      "step 10600 , validation  accuracy 0.706061\n",
      "step 10600 , validation loss : 0.59023\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685491085052\n",
      "(11, 30, 300, 300, 3)\n",
      "0.710723161697\n",
      "step 10700 , validation  accuracy 0.181818\n",
      "step 10700 , validation loss : 1.23653\n",
      "step 10700 , validation  accuracy 0.90303\n",
      "step 10700 , validation loss : 0.336683\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681066036224\n",
      "(11, 30, 300, 300, 3)\n",
      "0.668933868408\n",
      "step 10800 , validation  accuracy 0.30303\n",
      "step 10800 , validation loss : 0.790043\n",
      "step 10800 , validation  accuracy 0.80303\n",
      "step 10800 , validation loss : 0.556479\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69550204277\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705279111862\n",
      "step 10900 , validation  accuracy 0.309091\n",
      "step 10900 , validation loss : 0.846218\n",
      "step 10900 , validation  accuracy 0.809091\n",
      "step 10900 , validation loss : 0.504657\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684453964233\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686867952347\n",
      "step 11000 , validation  accuracy 0.378788\n",
      "step 11000 , validation loss : 0.731697\n",
      "step 11000 , validation  accuracy 0.757576\n",
      "step 11000 , validation loss : 0.607275\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69092798233\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687052965164\n",
      "step 11100 , validation  accuracy 0.475758\n",
      "step 11100 , validation loss : 0.750728\n",
      "step 11100 , validation  accuracy 0.690909\n",
      "step 11100 , validation loss : 0.601433\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68666100502\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684390068054\n",
      "step 11200 , validation  accuracy 0.454545\n",
      "step 11200 , validation loss : 0.773494\n",
      "step 11200 , validation  accuracy 0.745455\n",
      "step 11200 , validation loss : 0.555528\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693140983582\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682708024979\n",
      "step 11300 , validation  accuracy 0.427273\n",
      "step 11300 , validation loss : 0.938303\n",
      "step 11300 , validation  accuracy 0.612121\n",
      "step 11300 , validation loss : 0.654961\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695546150208\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686279058456\n",
      "step 11400 , validation  accuracy 0.366667\n",
      "step 11400 , validation loss : 0.869819\n",
      "step 11400 , validation  accuracy 0.775758\n",
      "step 11400 , validation loss : 0.500279\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.670664072037\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678326845169\n",
      "step 11500 , validation  accuracy 0.60303\n",
      "step 11500 , validation loss : 0.651237\n",
      "step 11500 , validation  accuracy 0.645455\n",
      "step 11500 , validation loss : 0.631344\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695755004883\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686806201935\n",
      "step 11600 , validation  accuracy 0.345455\n",
      "step 11600 , validation loss : 0.897638\n",
      "step 11600 , validation  accuracy 0.787879\n",
      "step 11600 , validation loss : 0.483889\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680063009262\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683970212936\n",
      "step 11700 , validation  accuracy 0.484848\n",
      "step 11700 , validation loss : 0.78527\n",
      "step 11700 , validation  accuracy 0.736364\n",
      "step 11700 , validation loss : 0.540274\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697777032852\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698205947876\n",
      "step 11800 , validation  accuracy 0.360606\n",
      "step 11800 , validation loss : 0.951779\n",
      "step 11800 , validation  accuracy 0.766667\n",
      "step 11800 , validation loss : 0.470434\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674830913544\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696604967117\n",
      "step 11900 , validation  accuracy 0.436364\n",
      "step 11900 , validation loss : 0.848708\n",
      "step 11900 , validation  accuracy 0.712121\n",
      "step 11900 , validation loss : 0.553903\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682302951813\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696770906448\n",
      "step 12000 , validation  accuracy 0.406061\n",
      "step 12000 , validation loss : 0.835993\n",
      "step 12000 , validation  accuracy 0.775758\n",
      "step 12000 , validation loss : 0.482726\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692754030228\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686779022217\n",
      "step 12100 , validation  accuracy 0.490909\n",
      "step 12100 , validation loss : 0.741049\n",
      "step 12100 , validation  accuracy 0.675758\n",
      "step 12100 , validation loss : 0.602401\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692026138306\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691766023636\n",
      "step 12200 , validation  accuracy 0.545455\n",
      "step 12200 , validation loss : 0.707528\n",
      "step 12200 , validation  accuracy 0.730303\n",
      "step 12200 , validation loss : 0.557475\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702095985413\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692781925201\n",
      "step 12300 , validation  accuracy 0.245455\n",
      "step 12300 , validation loss : 0.899706\n",
      "step 12300 , validation  accuracy 0.875758\n",
      "step 12300 , validation loss : 0.435229\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.672564029694\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688158035278\n",
      "step 12400 , validation  accuracy 0.433333\n",
      "step 12400 , validation loss : 0.879973\n",
      "step 12400 , validation  accuracy 0.781818\n",
      "step 12400 , validation loss : 0.479937\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683526992798\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691061973572\n",
      "step 12500 , validation  accuracy 0.493939\n",
      "step 12500 , validation loss : 0.707382\n",
      "step 12500 , validation  accuracy 0.7\n",
      "step 12500 , validation loss : 0.575184\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697702169418\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691202163696\n",
      "step 12600 , validation  accuracy 0.445455\n",
      "step 12600 , validation loss : 0.737466\n",
      "step 12600 , validation  accuracy 0.766667\n",
      "step 12600 , validation loss : 0.527284\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.707211017609\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698400020599\n",
      "step 12700 , validation  accuracy 0.548485\n",
      "step 12700 , validation loss : 0.666866\n",
      "step 12700 , validation  accuracy 0.678788\n",
      "step 12700 , validation loss : 0.648673\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685482025146\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690612792969\n",
      "step 12800 , validation  accuracy 0.560606\n",
      "step 12800 , validation loss : 0.668688\n",
      "step 12800 , validation  accuracy 0.687879\n",
      "step 12800 , validation loss : 0.629267\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692222118378\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697856903076\n",
      "step 12900 , validation  accuracy 0.257576\n",
      "step 12900 , validation loss : 0.965841\n",
      "step 12900 , validation  accuracy 0.887879\n",
      "step 12900 , validation loss : 0.404814\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684485912323\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689301013947\n",
      "step 13000 , validation  accuracy 0.50303\n",
      "step 13000 , validation loss : 0.785508\n",
      "step 13000 , validation  accuracy 0.709091\n",
      "step 13000 , validation loss : 0.575137\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685651063919\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684962034225\n",
      "step 13100 , validation  accuracy 0.442424\n",
      "step 13100 , validation loss : 0.793302\n",
      "step 13100 , validation  accuracy 0.727273\n",
      "step 13100 , validation loss : 0.548762\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697011947632\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695014953613\n",
      "step 13200 , validation  accuracy 0.6\n",
      "step 13200 , validation loss : 0.637446\n",
      "step 13200 , validation  accuracy 0.657576\n",
      "step 13200 , validation loss : 0.69426\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679125070572\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683880090714\n",
      "step 13300 , validation  accuracy 0.381818\n",
      "step 13300 , validation loss : 0.976853\n",
      "step 13300 , validation  accuracy 0.793939\n",
      "step 13300 , validation loss : 0.476916\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692001104355\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693614006042\n",
      "step 13400 , validation  accuracy 0.381818\n",
      "step 13400 , validation loss : 0.841313\n",
      "step 13400 , validation  accuracy 0.8\n",
      "step 13400 , validation loss : 0.488454\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678941965103\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696739912033\n",
      "step 13500 , validation  accuracy 0.39697\n",
      "step 13500 , validation loss : 0.7452\n",
      "step 13500 , validation  accuracy 0.818182\n",
      "step 13500 , validation loss : 0.533986\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686163187027\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67865395546\n",
      "step 13600 , validation  accuracy 0.484849\n",
      "step 13600 , validation loss : 0.791368\n",
      "step 13600 , validation  accuracy 0.712121\n",
      "step 13600 , validation loss : 0.552079\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690180063248\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699172973633\n",
      "step 13700 , validation  accuracy 0.369697\n",
      "step 13700 , validation loss : 0.86274\n",
      "step 13700 , validation  accuracy 0.818182\n",
      "step 13700 , validation loss : 0.464613\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693448066711\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69970202446\n",
      "step 13800 , validation  accuracy 0.478788\n",
      "step 13800 , validation loss : 0.739866\n",
      "step 13800 , validation  accuracy 0.790909\n",
      "step 13800 , validation loss : 0.534961\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674732923508\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679189920425\n",
      "step 13900 , validation  accuracy 0.451515\n",
      "step 13900 , validation loss : 0.848187\n",
      "step 13900 , validation  accuracy 0.739394\n",
      "step 13900 , validation loss : 0.519141\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679250001907\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705342054367\n",
      "step 14000 , validation  accuracy 0.493939\n",
      "step 14000 , validation loss : 0.741673\n",
      "step 14000 , validation  accuracy 0.757576\n",
      "step 14000 , validation loss : 0.557156\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.708680868149\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683214187622\n",
      "step 14100 , validation  accuracy 0.330303\n",
      "step 14100 , validation loss : 0.97585\n",
      "step 14100 , validation  accuracy 0.812121\n",
      "step 14100 , validation loss : 0.460943\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680917978287\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679426908493\n",
      "step 14200 , validation  accuracy 0.348485\n",
      "step 14200 , validation loss : 0.936657\n",
      "step 14200 , validation  accuracy 0.839394\n",
      "step 14200 , validation loss : 0.425346\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694931030273\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697744846344\n",
      "step 14300 , validation  accuracy 0.409091\n",
      "step 14300 , validation loss : 0.769782\n",
      "step 14300 , validation  accuracy 0.827273\n",
      "step 14300 , validation loss : 0.495021\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681282043457\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698358058929\n",
      "step 14400 , validation  accuracy 0.327273\n",
      "step 14400 , validation loss : 0.843613\n",
      "step 14400 , validation  accuracy 0.845455\n",
      "step 14400 , validation loss : 0.473662\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68581199646\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697268009186\n",
      "step 14500 , validation  accuracy 0.566667\n",
      "step 14500 , validation loss : 0.644738\n",
      "step 14500 , validation  accuracy 0.7\n",
      "step 14500 , validation loss : 0.59535\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680217981339\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688961982727\n",
      "step 14600 , validation  accuracy 0.393939\n",
      "step 14600 , validation loss : 0.868062\n",
      "step 14600 , validation  accuracy 0.79697\n",
      "step 14600 , validation loss : 0.471228\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.708731174469\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683090925217\n",
      "step 14700 , validation  accuracy 0.30303\n",
      "step 14700 , validation loss : 1.15839\n",
      "step 14700 , validation  accuracy 0.827273\n",
      "step 14700 , validation loss : 0.366373\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682593822479\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690525054932\n",
      "step 14800 , validation  accuracy 0.281818\n",
      "step 14800 , validation loss : 1.0399\n",
      "step 14800 , validation  accuracy 0.893939\n",
      "step 14800 , validation loss : 0.362832\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673845052719\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697432994843\n",
      "step 14900 , validation  accuracy 0.590909\n",
      "step 14900 , validation loss : 0.690412\n",
      "step 14900 , validation  accuracy 0.657576\n",
      "step 14900 , validation loss : 0.638391\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686313867569\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685555934906\n",
      "step 15000 , validation  accuracy 0.451515\n",
      "step 15000 , validation loss : 0.838225\n",
      "step 15000 , validation  accuracy 0.775758\n",
      "step 15000 , validation loss : 0.506767\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684327840805\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690943956375\n",
      "step 15100 , validation  accuracy 0.357576\n",
      "step 15100 , validation loss : 1.12095\n",
      "step 15100 , validation  accuracy 0.824243\n",
      "step 15100 , validation loss : 0.409971\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.711472988129\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683237791061\n",
      "step 15200 , validation  accuracy 0.357576\n",
      "step 15200 , validation loss : 0.91606\n",
      "step 15200 , validation  accuracy 0.812121\n",
      "step 15200 , validation loss : 0.438894\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680207014084\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685338020325\n",
      "step 15300 , validation  accuracy 0.290909\n",
      "step 15300 , validation loss : 1.11064\n",
      "step 15300 , validation  accuracy 0.866667\n",
      "step 15300 , validation loss : 0.367168\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685105800629\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693121910095\n",
      "step 15400 , validation  accuracy 0.309091\n",
      "step 15400 , validation loss : 1.16675\n",
      "step 15400 , validation  accuracy 0.851515\n",
      "step 15400 , validation loss : 0.355713\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.708982944489\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691617012024\n",
      "step 15500 , validation  accuracy 0.378788\n",
      "step 15500 , validation loss : 1.20282\n",
      "step 15500 , validation  accuracy 0.809091\n",
      "step 15500 , validation loss : 0.43278\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699153900146\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685255050659\n",
      "step 15600 , validation  accuracy 0.375758\n",
      "step 15600 , validation loss : 0.867312\n",
      "step 15600 , validation  accuracy 0.79697\n",
      "step 15600 , validation loss : 0.47968\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681866884232\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694795846939\n",
      "step 15700 , validation  accuracy 0.436364\n",
      "step 15700 , validation loss : 0.966383\n",
      "step 15700 , validation  accuracy 0.781818\n",
      "step 15700 , validation loss : 0.488255\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68766283989\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683245897293\n",
      "step 15800 , validation  accuracy 0.469697\n",
      "step 15800 , validation loss : 0.877189\n",
      "step 15800 , validation  accuracy 0.724242\n",
      "step 15800 , validation loss : 0.587211\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688522100449\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683583974838\n",
      "step 15900 , validation  accuracy 0.257576\n",
      "step 15900 , validation loss : 1.08199\n",
      "step 15900 , validation  accuracy 0.906061\n",
      "step 15900 , validation loss : 0.351997\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683843851089\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683502912521\n",
      "step 16000 , validation  accuracy 0.321212\n",
      "step 16000 , validation loss : 0.844145\n",
      "step 16000 , validation  accuracy 0.890909\n",
      "step 16000 , validation loss : 0.439763\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693425893784\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684602022171\n",
      "step 16100 , validation  accuracy 0.442424\n",
      "step 16100 , validation loss : 0.77171\n",
      "step 16100 , validation  accuracy 0.806061\n",
      "step 16100 , validation loss : 0.490132\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694182157516\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683089017868\n",
      "step 16200 , validation  accuracy 0.457576\n",
      "step 16200 , validation loss : 0.834244\n",
      "step 16200 , validation  accuracy 0.781818\n",
      "step 16200 , validation loss : 0.492099\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682718038559\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689221143723\n",
      "step 16300 , validation  accuracy 0.490909\n",
      "step 16300 , validation loss : 0.796683\n",
      "step 16300 , validation  accuracy 0.693939\n",
      "step 16300 , validation loss : 0.596188\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674845933914\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685025930405\n",
      "step 16400 , validation  accuracy 0.366667\n",
      "step 16400 , validation loss : 0.923724\n",
      "step 16400 , validation  accuracy 0.830303\n",
      "step 16400 , validation loss : 0.442446\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685279846191\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700340986252\n",
      "step 16500 , validation  accuracy 0.445455\n",
      "step 16500 , validation loss : 0.771977\n",
      "step 16500 , validation  accuracy 0.809091\n",
      "step 16500 , validation loss : 0.504058\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687783956528\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691236019135\n",
      "step 16600 , validation  accuracy 0.506061\n",
      "step 16600 , validation loss : 0.733817\n",
      "step 16600 , validation  accuracy 0.754545\n",
      "step 16600 , validation loss : 0.51242\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698035001755\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695722103119\n",
      "step 16700 , validation  accuracy 0.448485\n",
      "step 16700 , validation loss : 0.888315\n",
      "step 16700 , validation  accuracy 0.842424\n",
      "step 16700 , validation loss : 0.451982\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684760093689\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689879894257\n",
      "step 16800 , validation  accuracy 0.372727\n",
      "step 16800 , validation loss : 0.990972\n",
      "step 16800 , validation  accuracy 0.851515\n",
      "step 16800 , validation loss : 0.382213\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706665039062\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691366910934\n",
      "step 16900 , validation  accuracy 0.378788\n",
      "step 16900 , validation loss : 0.831672\n",
      "step 16900 , validation  accuracy 0.851515\n",
      "step 16900 , validation loss : 0.434382\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678385019302\n",
      "(11, 30, 300, 300, 3)\n",
      "0.724359035492\n",
      "step 17000 , validation  accuracy 0.442424\n",
      "step 17000 , validation loss : 0.773432\n",
      "step 17000 , validation  accuracy 0.775758\n",
      "step 17000 , validation loss : 0.522755\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688392877579\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687443971634\n",
      "step 17100 , validation  accuracy 0.324242\n",
      "step 17100 , validation loss : 1.02338\n",
      "step 17100 , validation  accuracy 0.866667\n",
      "step 17100 , validation loss : 0.353287\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69720697403\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698319911957\n",
      "step 17200 , validation  accuracy 0.512121\n",
      "step 17200 , validation loss : 0.794953\n",
      "step 17200 , validation  accuracy 0.772727\n",
      "step 17200 , validation loss : 0.537283\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68597984314\n",
      "(11, 30, 300, 300, 3)\n",
      "0.723448038101\n",
      "step 17300 , validation  accuracy 0.454545\n",
      "step 17300 , validation loss : 0.85961\n",
      "step 17300 , validation  accuracy 0.793939\n",
      "step 17300 , validation loss : 0.487344\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684201002121\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688449144363\n",
      "step 17400 , validation  accuracy 0.427273\n",
      "step 17400 , validation loss : 0.943861\n",
      "step 17400 , validation  accuracy 0.833333\n",
      "step 17400 , validation loss : 0.426389\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688361167908\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688767194748\n",
      "step 17500 , validation  accuracy 0.415152\n",
      "step 17500 , validation loss : 0.949304\n",
      "step 17500 , validation  accuracy 0.854546\n",
      "step 17500 , validation loss : 0.405255\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695933103561\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706208944321\n",
      "step 17600 , validation  accuracy 0.363636\n",
      "step 17600 , validation loss : 0.787673\n",
      "step 17600 , validation  accuracy 0.875758\n",
      "step 17600 , validation loss : 0.465141\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692631959915\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689360141754\n",
      "step 17700 , validation  accuracy 0.375758\n",
      "step 17700 , validation loss : 0.991759\n",
      "step 17700 , validation  accuracy 0.863636\n",
      "step 17700 , validation loss : 0.369113\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695717096329\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688647031784\n",
      "step 17800 , validation  accuracy 0.439394\n",
      "step 17800 , validation loss : 1.01454\n",
      "step 17800 , validation  accuracy 0.815152\n",
      "step 17800 , validation loss : 0.402691\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691563844681\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688786029816\n",
      "step 17900 , validation  accuracy 0.421212\n",
      "step 17900 , validation loss : 0.897713\n",
      "step 17900 , validation  accuracy 0.842424\n",
      "step 17900 , validation loss : 0.388406\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692529201508\n",
      "(11, 30, 300, 300, 3)\n",
      "0.704653024673\n",
      "step 18000 , validation  accuracy 0.542424\n",
      "step 18000 , validation loss : 0.812011\n",
      "step 18000 , validation  accuracy 0.790909\n",
      "step 18000 , validation loss : 0.494491\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680331945419\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688084125519\n",
      "step 18100 , validation  accuracy 0.521212\n",
      "step 18100 , validation loss : 0.77641\n",
      "step 18100 , validation  accuracy 0.793939\n",
      "step 18100 , validation loss : 0.454851\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.669659852982\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694902896881\n",
      "step 18200 , validation  accuracy 0.487879\n",
      "step 18200 , validation loss : 0.886878\n",
      "step 18200 , validation  accuracy 0.809091\n",
      "step 18200 , validation loss : 0.460149\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68871307373\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678730964661\n",
      "step 18300 , validation  accuracy 0.584848\n",
      "step 18300 , validation loss : 0.745962\n",
      "step 18300 , validation  accuracy 0.730303\n",
      "step 18300 , validation loss : 0.598441\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673895835876\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687454938889\n",
      "step 18400 , validation  accuracy 0.536364\n",
      "step 18400 , validation loss : 0.862889\n",
      "step 18400 , validation  accuracy 0.775758\n",
      "step 18400 , validation loss : 0.503937\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70477104187\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698287963867\n",
      "step 18500 , validation  accuracy 0.481818\n",
      "step 18500 , validation loss : 0.840432\n",
      "step 18500 , validation  accuracy 0.775758\n",
      "step 18500 , validation loss : 0.493164\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683240890503\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687953948975\n",
      "step 18600 , validation  accuracy 0.606061\n",
      "step 18600 , validation loss : 0.661419\n",
      "step 18600 , validation  accuracy 0.757576\n",
      "step 18600 , validation loss : 0.537045\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702536821365\n",
      "(11, 30, 300, 300, 3)\n",
      "0.712585926056\n",
      "step 18700 , validation  accuracy 0.475758\n",
      "step 18700 , validation loss : 0.845131\n",
      "step 18700 , validation  accuracy 0.8\n",
      "step 18700 , validation loss : 0.472653\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678750038147\n",
      "(11, 30, 300, 300, 3)\n",
      "0.672165155411\n",
      "step 18800 , validation  accuracy 0.524242\n",
      "step 18800 , validation loss : 0.863786\n",
      "step 18800 , validation  accuracy 0.815152\n",
      "step 18800 , validation loss : 0.437607\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703863859177\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687991142273\n",
      "step 18900 , validation  accuracy 0.515152\n",
      "step 18900 , validation loss : 0.75538\n",
      "step 18900 , validation  accuracy 0.821212\n",
      "step 18900 , validation loss : 0.430234\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686917066574\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683079957962\n",
      "step 19000 , validation  accuracy 0.40303\n",
      "step 19000 , validation loss : 1.15917\n",
      "step 19000 , validation  accuracy 0.872727\n",
      "step 19000 , validation loss : 0.327039\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691262960434\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682235002518\n",
      "step 19100 , validation  accuracy 0.472727\n",
      "step 19100 , validation loss : 0.857289\n",
      "step 19100 , validation  accuracy 0.836364\n",
      "step 19100 , validation loss : 0.408951\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681195020676\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685339927673\n",
      "step 19200 , validation  accuracy 0.49697\n",
      "step 19200 , validation loss : 0.925924\n",
      "step 19200 , validation  accuracy 0.875758\n",
      "step 19200 , validation loss : 0.366643\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686300992966\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684292078018\n",
      "step 19300 , validation  accuracy 0.587879\n",
      "step 19300 , validation loss : 0.691022\n",
      "step 19300 , validation  accuracy 0.778788\n",
      "step 19300 , validation loss : 0.514092\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.723607063293\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679054021835\n",
      "step 19400 , validation  accuracy 0.4\n",
      "step 19400 , validation loss : 1.07196\n",
      "step 19400 , validation  accuracy 0.951515\n",
      "step 19400 , validation loss : 0.261619\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687848806381\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689344882965\n",
      "step 19500 , validation  accuracy 0.636364\n",
      "step 19500 , validation loss : 0.591989\n",
      "step 19500 , validation  accuracy 0.733333\n",
      "step 19500 , validation loss : 0.560519\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703399896622\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703448057175\n",
      "step 19600 , validation  accuracy 0.524242\n",
      "step 19600 , validation loss : 0.757005\n",
      "step 19600 , validation  accuracy 0.866667\n",
      "step 19600 , validation loss : 0.395027\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695295095444\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679363965988\n",
      "step 19700 , validation  accuracy 0.515152\n",
      "step 19700 , validation loss : 0.834487\n",
      "step 19700 , validation  accuracy 0.842424\n",
      "step 19700 , validation loss : 0.39879\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700163125992\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68795800209\n",
      "step 19800 , validation  accuracy 0.606061\n",
      "step 19800 , validation loss : 0.743596\n",
      "step 19800 , validation  accuracy 0.748485\n",
      "step 19800 , validation loss : 0.534732\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688338041306\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695913791656\n",
      "step 19900 , validation  accuracy 0.524242\n",
      "step 19900 , validation loss : 0.910357\n",
      "step 19900 , validation  accuracy 0.863636\n",
      "step 19900 , validation loss : 0.361286\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690330982208\n",
      "(11, 30, 300, 300, 3)\n",
      "0.737385988235\n",
      "step 20000 , validation  accuracy 0.590909\n",
      "step 20000 , validation loss : 0.641269\n",
      "step 20000 , validation  accuracy 0.818182\n",
      "step 20000 , validation loss : 0.471515\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676780939102\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67941904068\n",
      "step 20100 , validation  accuracy 0.572727\n",
      "step 20100 , validation loss : 0.851701\n",
      "step 20100 , validation  accuracy 0.836364\n",
      "step 20100 , validation loss : 0.446182\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700331926346\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685218811035\n",
      "step 20200 , validation  accuracy 0.624242\n",
      "step 20200 , validation loss : 0.658596\n",
      "step 20200 , validation  accuracy 0.775758\n",
      "step 20200 , validation loss : 0.5129\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688992023468\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684270143509\n",
      "step 20300 , validation  accuracy 0.633333\n",
      "step 20300 , validation loss : 0.606256\n",
      "step 20300 , validation  accuracy 0.760606\n",
      "step 20300 , validation loss : 0.555197\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676530838013\n",
      "(11, 30, 300, 300, 3)\n",
      "0.7014939785\n",
      "step 20400 , validation  accuracy 0.642424\n",
      "step 20400 , validation loss : 0.650196\n",
      "step 20400 , validation  accuracy 0.79394\n",
      "step 20400 , validation loss : 0.563446\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701101064682\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68882894516\n",
      "step 20500 , validation  accuracy 0.633333\n",
      "step 20500 , validation loss : 0.645474\n",
      "step 20500 , validation  accuracy 0.748485\n",
      "step 20500 , validation loss : 0.486958\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676787853241\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689846992493\n",
      "step 20600 , validation  accuracy 0.563636\n",
      "step 20600 , validation loss : 0.83612\n",
      "step 20600 , validation  accuracy 0.869697\n",
      "step 20600 , validation loss : 0.328514\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700788974762\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696331977844\n",
      "step 20700 , validation  accuracy 0.545455\n",
      "step 20700 , validation loss : 0.707936\n",
      "step 20700 , validation  accuracy 0.878788\n",
      "step 20700 , validation loss : 0.41444\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68349313736\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675799846649\n",
      "step 20800 , validation  accuracy 0.469697\n",
      "step 20800 , validation loss : 1.08281\n",
      "step 20800 , validation  accuracy 0.887879\n",
      "step 20800 , validation loss : 0.302232\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696245908737\n",
      "(11, 30, 300, 300, 3)\n",
      "0.70078086853\n",
      "step 20900 , validation  accuracy 0.575758\n",
      "step 20900 , validation loss : 0.726355\n",
      "step 20900 , validation  accuracy 0.881818\n",
      "step 20900 , validation loss : 0.376085\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690014123917\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684751987457\n",
      "step 21000 , validation  accuracy 0.557576\n",
      "step 21000 , validation loss : 0.799215\n",
      "step 21000 , validation  accuracy 0.872727\n",
      "step 21000 , validation loss : 0.37167\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687119960785\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685737848282\n",
      "step 21100 , validation  accuracy 0.657576\n",
      "step 21100 , validation loss : 0.559513\n",
      "step 21100 , validation  accuracy 0.79394\n",
      "step 21100 , validation loss : 0.527761\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694297075272\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696615934372\n",
      "step 21200 , validation  accuracy 0.627273\n",
      "step 21200 , validation loss : 0.710401\n",
      "step 21200 , validation  accuracy 0.812121\n",
      "step 21200 , validation loss : 0.501224\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680018901825\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693913936615\n",
      "step 21300 , validation  accuracy 0.618182\n",
      "step 21300 , validation loss : 0.798572\n",
      "step 21300 , validation  accuracy 0.857576\n",
      "step 21300 , validation loss : 0.423223\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696423053741\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695746183395\n",
      "step 21400 , validation  accuracy 0.539394\n",
      "step 21400 , validation loss : 0.877455\n",
      "step 21400 , validation  accuracy 0.90303\n",
      "step 21400 , validation loss : 0.328041\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675443887711\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680339097977\n",
      "step 21500 , validation  accuracy 0.60303\n",
      "step 21500 , validation loss : 0.69749\n",
      "step 21500 , validation  accuracy 0.806061\n",
      "step 21500 , validation loss : 0.51543\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692904949188\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674745082855\n",
      "step 21600 , validation  accuracy 0.639394\n",
      "step 21600 , validation loss : 0.637469\n",
      "step 21600 , validation  accuracy 0.833333\n",
      "step 21600 , validation loss : 0.426976\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681942939758\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703350067139\n",
      "step 21700 , validation  accuracy 0.772727\n",
      "step 21700 , validation loss : 0.421251\n",
      "step 21700 , validation  accuracy 0.706061\n",
      "step 21700 , validation loss : 0.689699\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703267097473\n",
      "(11, 30, 300, 300, 3)\n",
      "0.722548961639\n",
      "step 21800 , validation  accuracy 0.587879\n",
      "step 21800 , validation loss : 0.803568\n",
      "step 21800 , validation  accuracy 0.884849\n",
      "step 21800 , validation loss : 0.355166\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675122976303\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693341016769\n",
      "step 21900 , validation  accuracy 0.621212\n",
      "step 21900 , validation loss : 0.810019\n",
      "step 21900 , validation  accuracy 0.878788\n",
      "step 21900 , validation loss : 0.341228\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699289083481\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694169044495\n",
      "step 22000 , validation  accuracy 0.627273\n",
      "step 22000 , validation loss : 0.693802\n",
      "step 22000 , validation  accuracy 0.827273\n",
      "step 22000 , validation loss : 0.442184\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691800832748\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686284065247\n",
      "step 22100 , validation  accuracy 0.612121\n",
      "step 22100 , validation loss : 0.715217\n",
      "step 22100 , validation  accuracy 0.830303\n",
      "step 22100 , validation loss : 0.473391\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702352046967\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685512065887\n",
      "step 22200 , validation  accuracy 0.648485\n",
      "step 22200 , validation loss : 0.758487\n",
      "step 22200 , validation  accuracy 0.863636\n",
      "step 22200 , validation loss : 0.431803\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69638299942\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690834999084\n",
      "step 22300 , validation  accuracy 0.642424\n",
      "step 22300 , validation loss : 0.770657\n",
      "step 22300 , validation  accuracy 0.815152\n",
      "step 22300 , validation loss : 0.488423\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68074297905\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686613082886\n",
      "step 22400 , validation  accuracy 0.630303\n",
      "step 22400 , validation loss : 0.714842\n",
      "step 22400 , validation  accuracy 0.854546\n",
      "step 22400 , validation loss : 0.401153\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701367139816\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686839818954\n",
      "step 22500 , validation  accuracy 0.681818\n",
      "step 22500 , validation loss : 0.699231\n",
      "step 22500 , validation  accuracy 0.842424\n",
      "step 22500 , validation loss : 0.410025\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675653219223\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678547143936\n",
      "step 22600 , validation  accuracy 0.542424\n",
      "step 22600 , validation loss : 0.918351\n",
      "step 22600 , validation  accuracy 0.921212\n",
      "step 22600 , validation loss : 0.292862\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701549053192\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692741155624\n",
      "step 22700 , validation  accuracy 0.715152\n",
      "step 22700 , validation loss : 0.542132\n",
      "step 22700 , validation  accuracy 0.778788\n",
      "step 22700 , validation loss : 0.473445\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67622590065\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679740905762\n",
      "step 22800 , validation  accuracy 0.687879\n",
      "step 22800 , validation loss : 0.602168\n",
      "step 22800 , validation  accuracy 0.80303\n",
      "step 22800 , validation loss : 0.491621\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685832023621\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695293188095\n",
      "step 22900 , validation  accuracy 0.633333\n",
      "step 22900 , validation loss : 0.672879\n",
      "step 22900 , validation  accuracy 0.863636\n",
      "step 22900 , validation loss : 0.439439\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686318159103\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705821037292\n",
      "step 23000 , validation  accuracy 0.663636\n",
      "step 23000 , validation loss : 0.682065\n",
      "step 23000 , validation  accuracy 0.730303\n",
      "step 23000 , validation loss : 0.568835\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697756052017\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686229944229\n",
      "step 23100 , validation  accuracy 0.70303\n",
      "step 23100 , validation loss : 0.607035\n",
      "step 23100 , validation  accuracy 0.787879\n",
      "step 23100 , validation loss : 0.514499\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676985025406\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692946910858\n",
      "step 23200 , validation  accuracy 0.669697\n",
      "step 23200 , validation loss : 0.640414\n",
      "step 23200 , validation  accuracy 0.775758\n",
      "step 23200 , validation loss : 0.526236\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693361997604\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687835931778\n",
      "step 23300 , validation  accuracy 0.706061\n",
      "step 23300 , validation loss : 0.544458\n",
      "step 23300 , validation  accuracy 0.809091\n",
      "step 23300 , validation loss : 0.490832\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696927070618\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695760965347\n",
      "step 23400 , validation  accuracy 0.6\n",
      "step 23400 , validation loss : 0.800771\n",
      "step 23400 , validation  accuracy 0.89697\n",
      "step 23400 , validation loss : 0.328005\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683636903763\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696383953094\n",
      "step 23500 , validation  accuracy 0.7\n",
      "step 23500 , validation loss : 0.664689\n",
      "step 23500 , validation  accuracy 0.80303\n",
      "step 23500 , validation loss : 0.481823\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692926883698\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685222864151\n",
      "step 23600 , validation  accuracy 0.654545\n",
      "step 23600 , validation loss : 0.696913\n",
      "step 23600 , validation  accuracy 0.890909\n",
      "step 23600 , validation loss : 0.370829\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678823947906\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683954954147\n",
      "step 23700 , validation  accuracy 0.627273\n",
      "step 23700 , validation loss : 0.705426\n",
      "step 23700 , validation  accuracy 0.875758\n",
      "step 23700 , validation loss : 0.360415\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682781934738\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69465303421\n",
      "step 23800 , validation  accuracy 0.718182\n",
      "step 23800 , validation loss : 0.537492\n",
      "step 23800 , validation  accuracy 0.815152\n",
      "step 23800 , validation loss : 0.496552\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684532880783\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677105903625\n",
      "step 23900 , validation  accuracy 0.727273\n",
      "step 23900 , validation loss : 0.650993\n",
      "step 23900 , validation  accuracy 0.80303\n",
      "step 23900 , validation loss : 0.502707\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691157102585\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706877946854\n",
      "step 24000 , validation  accuracy 0.660606\n",
      "step 24000 , validation loss : 0.722507\n",
      "step 24000 , validation  accuracy 0.884849\n",
      "step 24000 , validation loss : 0.341552\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681799888611\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689093112946\n",
      "step 24100 , validation  accuracy 0.7\n",
      "step 24100 , validation loss : 0.643074\n",
      "step 24100 , validation  accuracy 0.80303\n",
      "step 24100 , validation loss : 0.524696\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70340013504\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681612968445\n",
      "step 24200 , validation  accuracy 0.739394\n",
      "step 24200 , validation loss : 0.539426\n",
      "step 24200 , validation  accuracy 0.818182\n",
      "step 24200 , validation loss : 0.46581\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674447059631\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695286035538\n",
      "step 24300 , validation  accuracy 0.612121\n",
      "step 24300 , validation loss : 0.749796\n",
      "step 24300 , validation  accuracy 0.906061\n",
      "step 24300 , validation loss : 0.321723\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676503896713\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687434911728\n",
      "step 24400 , validation  accuracy 0.690909\n",
      "step 24400 , validation loss : 0.666156\n",
      "step 24400 , validation  accuracy 0.839394\n",
      "step 24400 , validation loss : 0.392242\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702342987061\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68989109993\n",
      "step 24500 , validation  accuracy 0.672727\n",
      "step 24500 , validation loss : 0.753477\n",
      "step 24500 , validation  accuracy 0.845455\n",
      "step 24500 , validation loss : 0.426098\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68110203743\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679300069809\n",
      "step 24600 , validation  accuracy 0.657576\n",
      "step 24600 , validation loss : 0.792525\n",
      "step 24600 , validation  accuracy 0.872727\n",
      "step 24600 , validation loss : 0.37365\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693536996841\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678771018982\n",
      "step 24700 , validation  accuracy 0.609091\n",
      "step 24700 , validation loss : 0.756589\n",
      "step 24700 , validation  accuracy 0.866667\n",
      "step 24700 , validation loss : 0.346921\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683398008347\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700217962265\n",
      "step 24800 , validation  accuracy 0.709091\n",
      "step 24800 , validation loss : 0.672633\n",
      "step 24800 , validation  accuracy 0.806061\n",
      "step 24800 , validation loss : 0.545798\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689070940018\n",
      "(11, 30, 300, 300, 3)\n",
      "0.664085149765\n",
      "step 24900 , validation  accuracy 0.6\n",
      "step 24900 , validation loss : 0.906021\n",
      "step 24900 , validation  accuracy 0.906061\n",
      "step 24900 , validation loss : 0.29021\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690418958664\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676254034042\n",
      "step 25000 , validation  accuracy 0.684849\n",
      "step 25000 , validation loss : 0.592519\n",
      "step 25000 , validation  accuracy 0.8\n",
      "step 25000 , validation loss : 0.528898\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690680980682\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69970202446\n",
      "step 25100 , validation  accuracy 0.751515\n",
      "step 25100 , validation loss : 0.549632\n",
      "step 25100 , validation  accuracy 0.790909\n",
      "step 25100 , validation loss : 0.530519\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.668067932129\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689158916473\n",
      "step 25200 , validation  accuracy 0.769697\n",
      "step 25200 , validation loss : 0.466935\n",
      "step 25200 , validation  accuracy 0.757576\n",
      "step 25200 , validation loss : 0.694476\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679421901703\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693376064301\n",
      "step 25300 , validation  accuracy 0.654545\n",
      "step 25300 , validation loss : 0.716757\n",
      "step 25300 , validation  accuracy 0.860606\n",
      "step 25300 , validation loss : 0.38043\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688660860062\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693520069122\n",
      "step 25400 , validation  accuracy 0.678788\n",
      "step 25400 , validation loss : 0.709373\n",
      "step 25400 , validation  accuracy 0.860606\n",
      "step 25400 , validation loss : 0.409066\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684741973877\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690515041351\n",
      "step 25500 , validation  accuracy 0.675758\n",
      "step 25500 , validation loss : 0.690694\n",
      "step 25500 , validation  accuracy 0.830303\n",
      "step 25500 , validation loss : 0.439086\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695859909058\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706398963928\n",
      "step 25600 , validation  accuracy 0.657576\n",
      "step 25600 , validation loss : 0.772839\n",
      "step 25600 , validation  accuracy 0.842424\n",
      "step 25600 , validation loss : 0.401685\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678627967834\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686435937881\n",
      "step 25700 , validation  accuracy 0.69697\n",
      "step 25700 , validation loss : 0.686628\n",
      "step 25700 , validation  accuracy 0.839394\n",
      "step 25700 , validation loss : 0.436434\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691507101059\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700402021408\n",
      "step 25800 , validation  accuracy 0.815152\n",
      "step 25800 , validation loss : 0.368856\n",
      "step 25800 , validation  accuracy 0.666667\n",
      "step 25800 , validation loss : 0.81002\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687308073044\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69159913063\n",
      "step 25900 , validation  accuracy 0.669697\n",
      "step 25900 , validation loss : 0.706682\n",
      "step 25900 , validation  accuracy 0.869697\n",
      "step 25900 , validation loss : 0.388997\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696944952011\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683449983597\n",
      "step 26000 , validation  accuracy 0.721212\n",
      "step 26000 , validation loss : 0.594455\n",
      "step 26000 , validation  accuracy 0.8\n",
      "step 26000 , validation loss : 0.49246\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680148839951\n",
      "(11, 30, 300, 300, 3)\n",
      "0.671396970749\n",
      "step 26100 , validation  accuracy 0.706061\n",
      "step 26100 , validation loss : 0.618508\n",
      "step 26100 , validation  accuracy 0.830303\n",
      "step 26100 , validation loss : 0.469714\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693327903748\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689674854279\n",
      "step 26200 , validation  accuracy 0.712121\n",
      "step 26200 , validation loss : 0.605175\n",
      "step 26200 , validation  accuracy 0.79697\n",
      "step 26200 , validation loss : 0.482765\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691695928574\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691447019577\n",
      "step 26300 , validation  accuracy 0.651515\n",
      "step 26300 , validation loss : 0.706459\n",
      "step 26300 , validation  accuracy 0.890909\n",
      "step 26300 , validation loss : 0.367934\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681952953339\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686249017715\n",
      "step 26400 , validation  accuracy 0.675758\n",
      "step 26400 , validation loss : 0.622564\n",
      "step 26400 , validation  accuracy 0.866667\n",
      "step 26400 , validation loss : 0.385886\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693125963211\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687287092209\n",
      "step 26500 , validation  accuracy 0.748485\n",
      "step 26500 , validation loss : 0.563804\n",
      "step 26500 , validation  accuracy 0.793939\n",
      "step 26500 , validation loss : 0.494598\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680208921432\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678594112396\n",
      "step 26600 , validation  accuracy 0.69697\n",
      "step 26600 , validation loss : 0.627528\n",
      "step 26600 , validation  accuracy 0.80303\n",
      "step 26600 , validation loss : 0.443\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67840886116\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683030128479\n",
      "step 26700 , validation  accuracy 0.730303\n",
      "step 26700 , validation loss : 0.499431\n",
      "step 26700 , validation  accuracy 0.809091\n",
      "step 26700 , validation loss : 0.492612\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678433179855\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68613409996\n",
      "step 26800 , validation  accuracy 0.763636\n",
      "step 26800 , validation loss : 0.501542\n",
      "step 26800 , validation  accuracy 0.763636\n",
      "step 26800 , validation loss : 0.617923\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705435991287\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683260917664\n",
      "step 26900 , validation  accuracy 0.609091\n",
      "step 26900 , validation loss : 0.805691\n",
      "step 26900 , validation  accuracy 0.90303\n",
      "step 26900 , validation loss : 0.291873\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686934947968\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697991132736\n",
      "step 27000 , validation  accuracy 0.645455\n",
      "step 27000 , validation loss : 0.660508\n",
      "step 27000 , validation  accuracy 0.863636\n",
      "step 27000 , validation loss : 0.371179\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69664311409\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67862200737\n",
      "step 27100 , validation  accuracy 0.678788\n",
      "step 27100 , validation loss : 0.762579\n",
      "step 27100 , validation  accuracy 0.845455\n",
      "step 27100 , validation loss : 0.398724\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693718910217\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697901964188\n",
      "step 27200 , validation  accuracy 0.748485\n",
      "step 27200 , validation loss : 0.489521\n",
      "step 27200 , validation  accuracy 0.8\n",
      "step 27200 , validation loss : 0.520217\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67968583107\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691241979599\n",
      "step 27300 , validation  accuracy 0.718182\n",
      "step 27300 , validation loss : 0.553204\n",
      "step 27300 , validation  accuracy 0.793939\n",
      "step 27300 , validation loss : 0.504373\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689306020737\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686503887177\n",
      "step 27400 , validation  accuracy 0.778788\n",
      "step 27400 , validation loss : 0.48076\n",
      "step 27400 , validation  accuracy 0.748485\n",
      "step 27400 , validation loss : 0.606704\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673189163208\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690189838409\n",
      "step 27500 , validation  accuracy 0.663636\n",
      "step 27500 , validation loss : 0.746664\n",
      "step 27500 , validation  accuracy 0.887879\n",
      "step 27500 , validation loss : 0.334178\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686336040497\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687005996704\n",
      "step 27600 , validation  accuracy 0.651515\n",
      "step 27600 , validation loss : 0.687898\n",
      "step 27600 , validation  accuracy 0.839394\n",
      "step 27600 , validation loss : 0.430816\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688055992126\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703212976456\n",
      "step 27700 , validation  accuracy 0.730303\n",
      "step 27700 , validation loss : 0.510622\n",
      "step 27700 , validation  accuracy 0.79697\n",
      "step 27700 , validation loss : 0.5464\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694020986557\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692411899567\n",
      "step 27800 , validation  accuracy 0.766667\n",
      "step 27800 , validation loss : 0.441504\n",
      "step 27800 , validation  accuracy 0.742424\n",
      "step 27800 , validation loss : 0.639218\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687573194504\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684714794159\n",
      "step 27900 , validation  accuracy 0.778788\n",
      "step 27900 , validation loss : 0.3851\n",
      "step 27900 , validation  accuracy 0.648485\n",
      "step 27900 , validation loss : 0.817351\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691783905029\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686167001724\n",
      "step 28000 , validation  accuracy 0.784849\n",
      "step 28000 , validation loss : 0.429689\n",
      "step 28000 , validation  accuracy 0.757576\n",
      "step 28000 , validation loss : 0.586353\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684935808182\n",
      "(11, 30, 300, 300, 3)\n",
      "0.720772027969\n",
      "step 28100 , validation  accuracy 0.745455\n",
      "step 28100 , validation loss : 0.553019\n",
      "step 28100 , validation  accuracy 0.80303\n",
      "step 28100 , validation loss : 0.472031\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695090055466\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686578989029\n",
      "step 28200 , validation  accuracy 0.760606\n",
      "step 28200 , validation loss : 0.477438\n",
      "step 28200 , validation  accuracy 0.781818\n",
      "step 28200 , validation loss : 0.551077\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68062210083\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692532062531\n",
      "step 28300 , validation  accuracy 0.79394\n",
      "step 28300 , validation loss : 0.470835\n",
      "step 28300 , validation  accuracy 0.745455\n",
      "step 28300 , validation loss : 0.612227\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691259860992\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689439058304\n",
      "step 28400 , validation  accuracy 0.745455\n",
      "step 28400 , validation loss : 0.659869\n",
      "step 28400 , validation  accuracy 0.80303\n",
      "step 28400 , validation loss : 0.541109\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695965051651\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696819067001\n",
      "step 28500 , validation  accuracy 0.781818\n",
      "step 28500 , validation loss : 0.475228\n",
      "step 28500 , validation  accuracy 0.742424\n",
      "step 28500 , validation loss : 0.595842\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680242061615\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687201976776\n",
      "step 28600 , validation  accuracy 0.675758\n",
      "step 28600 , validation loss : 0.746613\n",
      "step 28600 , validation  accuracy 0.860606\n",
      "step 28600 , validation loss : 0.374562\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.707212924957\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696406126022\n",
      "step 28700 , validation  accuracy 0.690909\n",
      "step 28700 , validation loss : 0.588007\n",
      "step 28700 , validation  accuracy 0.842424\n",
      "step 28700 , validation loss : 0.411068\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682350158691\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68279004097\n",
      "step 28800 , validation  accuracy 0.80303\n",
      "step 28800 , validation loss : 0.406176\n",
      "step 28800 , validation  accuracy 0.727273\n",
      "step 28800 , validation loss : 0.720563\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694498062134\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682401895523\n",
      "step 28900 , validation  accuracy 0.709091\n",
      "step 28900 , validation loss : 0.628207\n",
      "step 28900 , validation  accuracy 0.815152\n",
      "step 28900 , validation loss : 0.451059\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681676864624\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689879894257\n",
      "step 29000 , validation  accuracy 0.687879\n",
      "step 29000 , validation loss : 0.706308\n",
      "step 29000 , validation  accuracy 0.866667\n",
      "step 29000 , validation loss : 0.340699\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6847012043\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678885936737\n",
      "step 29100 , validation  accuracy 0.709091\n",
      "step 29100 , validation loss : 0.599577\n",
      "step 29100 , validation  accuracy 0.845455\n",
      "step 29100 , validation loss : 0.425351\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.669058084488\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690742969513\n",
      "step 29200 , validation  accuracy 0.784849\n",
      "step 29200 , validation loss : 0.438337\n",
      "step 29200 , validation  accuracy 0.784849\n",
      "step 29200 , validation loss : 0.583673\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695301055908\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68387389183\n",
      "step 29300 , validation  accuracy 0.7\n",
      "step 29300 , validation loss : 0.611647\n",
      "step 29300 , validation  accuracy 0.866667\n",
      "step 29300 , validation loss : 0.361433\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67258810997\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678748846054\n",
      "step 29400 , validation  accuracy 0.757576\n",
      "step 29400 , validation loss : 0.499175\n",
      "step 29400 , validation  accuracy 0.8\n",
      "step 29400 , validation loss : 0.488138\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687572002411\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686457157135\n",
      "step 29500 , validation  accuracy 0.70303\n",
      "step 29500 , validation loss : 0.596947\n",
      "step 29500 , validation  accuracy 0.830303\n",
      "step 29500 , validation loss : 0.43366\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689805030823\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679220199585\n",
      "step 29600 , validation  accuracy 0.760606\n",
      "step 29600 , validation loss : 0.48699\n",
      "step 29600 , validation  accuracy 0.790909\n",
      "step 29600 , validation loss : 0.533745\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681674003601\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694590091705\n",
      "step 29700 , validation  accuracy 0.687879\n",
      "step 29700 , validation loss : 0.75106\n",
      "step 29700 , validation  accuracy 0.869697\n",
      "step 29700 , validation loss : 0.397516\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.729202985764\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684075832367\n",
      "step 29800 , validation  accuracy 0.757576\n",
      "step 29800 , validation loss : 0.537619\n",
      "step 29800 , validation  accuracy 0.787879\n",
      "step 29800 , validation loss : 0.543246\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692443132401\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696740150452\n",
      "step 29900 , validation  accuracy 0.742424\n",
      "step 29900 , validation loss : 0.536193\n",
      "step 29900 , validation  accuracy 0.790909\n",
      "step 29900 , validation loss : 0.519844\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680215835571\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699537038803\n",
      "step 30000 , validation  accuracy 0.733333\n",
      "step 30000 , validation loss : 0.608345\n",
      "step 30000 , validation  accuracy 0.842424\n",
      "step 30000 , validation loss : 0.451259\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6790599823\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695033073425\n",
      "step 30100 , validation  accuracy 0.70303\n",
      "step 30100 , validation loss : 0.693049\n",
      "step 30100 , validation  accuracy 0.872727\n",
      "step 30100 , validation loss : 0.368798\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686884880066\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681796073914\n",
      "step 30200 , validation  accuracy 0.715152\n",
      "step 30200 , validation loss : 0.589677\n",
      "step 30200 , validation  accuracy 0.821212\n",
      "step 30200 , validation loss : 0.425526\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685680150986\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681473970413\n",
      "step 30300 , validation  accuracy 0.736364\n",
      "step 30300 , validation loss : 0.509704\n",
      "step 30300 , validation  accuracy 0.8\n",
      "step 30300 , validation loss : 0.505412\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700669050217\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69339799881\n",
      "step 30400 , validation  accuracy 0.739394\n",
      "step 30400 , validation loss : 0.532013\n",
      "step 30400 , validation  accuracy 0.830303\n",
      "step 30400 , validation loss : 0.467993\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686299085617\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679240942001\n",
      "step 30500 , validation  accuracy 0.763636\n",
      "step 30500 , validation loss : 0.46239\n",
      "step 30500 , validation  accuracy 0.763636\n",
      "step 30500 , validation loss : 0.589467\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674073934555\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69637799263\n",
      "step 30600 , validation  accuracy 0.69697\n",
      "step 30600 , validation loss : 0.689028\n",
      "step 30600 , validation  accuracy 0.881818\n",
      "step 30600 , validation loss : 0.34262\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.711991071701\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696519136429\n",
      "step 30700 , validation  accuracy 0.748485\n",
      "step 30700 , validation loss : 0.611435\n",
      "step 30700 , validation  accuracy 0.781818\n",
      "step 30700 , validation loss : 0.569645\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680058002472\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692458868027\n",
      "step 30800 , validation  accuracy 0.769697\n",
      "step 30800 , validation loss : 0.462073\n",
      "step 30800 , validation  accuracy 0.763636\n",
      "step 30800 , validation loss : 0.561993\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693259000778\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680174827576\n",
      "step 30900 , validation  accuracy 0.760606\n",
      "step 30900 , validation loss : 0.503135\n",
      "step 30900 , validation  accuracy 0.8\n",
      "step 30900 , validation loss : 0.518747\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678670883179\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684421062469\n",
      "step 31000 , validation  accuracy 0.657576\n",
      "step 31000 , validation loss : 0.739742\n",
      "step 31000 , validation  accuracy 0.884849\n",
      "step 31000 , validation loss : 0.346327\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688724994659\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686058044434\n",
      "step 31100 , validation  accuracy 0.721212\n",
      "step 31100 , validation loss : 0.566877\n",
      "step 31100 , validation  accuracy 0.854546\n",
      "step 31100 , validation loss : 0.41396\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676531076431\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684916973114\n",
      "step 31200 , validation  accuracy 0.766667\n",
      "step 31200 , validation loss : 0.489195\n",
      "step 31200 , validation  accuracy 0.824243\n",
      "step 31200 , validation loss : 0.503704\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679851055145\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685142993927\n",
      "step 31300 , validation  accuracy 0.793939\n",
      "step 31300 , validation loss : 0.475646\n",
      "step 31300 , validation  accuracy 0.8\n",
      "step 31300 , validation loss : 0.494333\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689680099487\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682078838348\n",
      "step 31400 , validation  accuracy 0.684849\n",
      "step 31400 , validation loss : 0.700573\n",
      "step 31400 , validation  accuracy 0.860606\n",
      "step 31400 , validation loss : 0.387285\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687345027924\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694500923157\n",
      "step 31500 , validation  accuracy 0.715152\n",
      "step 31500 , validation loss : 0.558778\n",
      "step 31500 , validation  accuracy 0.818182\n",
      "step 31500 , validation loss : 0.451331\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689304113388\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681902885437\n",
      "step 31600 , validation  accuracy 0.648485\n",
      "step 31600 , validation loss : 0.775405\n",
      "step 31600 , validation  accuracy 0.893939\n",
      "step 31600 , validation loss : 0.302865\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674557924271\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677377939224\n",
      "step 31700 , validation  accuracy 0.739394\n",
      "step 31700 , validation loss : 0.571922\n",
      "step 31700 , validation  accuracy 0.815152\n",
      "step 31700 , validation loss : 0.449446\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691321134567\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68720293045\n",
      "step 31800 , validation  accuracy 0.769697\n",
      "step 31800 , validation loss : 0.483653\n",
      "step 31800 , validation  accuracy 0.781818\n",
      "step 31800 , validation loss : 0.531231\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679015159607\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694973945618\n",
      "step 31900 , validation  accuracy 0.736364\n",
      "step 31900 , validation loss : 0.714104\n",
      "step 31900 , validation  accuracy 0.833333\n",
      "step 31900 , validation loss : 0.476833\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685834884644\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684318065643\n",
      "step 32000 , validation  accuracy 0.672727\n",
      "step 32000 , validation loss : 0.806943\n",
      "step 32000 , validation  accuracy 0.857576\n",
      "step 32000 , validation loss : 0.372207\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.717198133469\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686902999878\n",
      "step 32100 , validation  accuracy 0.763636\n",
      "step 32100 , validation loss : 0.545565\n",
      "step 32100 , validation  accuracy 0.766667\n",
      "step 32100 , validation loss : 0.611464\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680855989456\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686806201935\n",
      "step 32200 , validation  accuracy 0.772727\n",
      "step 32200 , validation loss : 0.585277\n",
      "step 32200 , validation  accuracy 0.8\n",
      "step 32200 , validation loss : 0.55789\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697910070419\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701140880585\n",
      "step 32300 , validation  accuracy 0.8\n",
      "step 32300 , validation loss : 0.450981\n",
      "step 32300 , validation  accuracy 0.763636\n",
      "step 32300 , validation loss : 0.575586\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67213511467\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682021856308\n",
      "step 32400 , validation  accuracy 0.730303\n",
      "step 32400 , validation loss : 0.567306\n",
      "step 32400 , validation  accuracy 0.815152\n",
      "step 32400 , validation loss : 0.43212\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692509174347\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684085130692\n",
      "step 32500 , validation  accuracy 0.745455\n",
      "step 32500 , validation loss : 0.589446\n",
      "step 32500 , validation  accuracy 0.821212\n",
      "step 32500 , validation loss : 0.493963\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677322149277\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683707952499\n",
      "step 32600 , validation  accuracy 0.724242\n",
      "step 32600 , validation loss : 0.582717\n",
      "step 32600 , validation  accuracy 0.836364\n",
      "step 32600 , validation loss : 0.419078\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69942688942\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682736158371\n",
      "step 32700 , validation  accuracy 0.718182\n",
      "step 32700 , validation loss : 0.582922\n",
      "step 32700 , validation  accuracy 0.839394\n",
      "step 32700 , validation loss : 0.388982\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688889026642\n",
      "(11, 30, 300, 300, 3)\n",
      "0.704774856567\n",
      "step 32800 , validation  accuracy 0.724242\n",
      "step 32800 , validation loss : 0.661672\n",
      "step 32800 , validation  accuracy 0.863636\n",
      "step 32800 , validation loss : 0.389048\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701041936874\n",
      "(11, 30, 300, 300, 3)\n",
      "0.717407941818\n",
      "step 32900 , validation  accuracy 0.712121\n",
      "step 32900 , validation loss : 0.712925\n",
      "step 32900 , validation  accuracy 0.866667\n",
      "step 32900 , validation loss : 0.38306\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68491101265\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680469989777\n",
      "step 33000 , validation  accuracy 0.751515\n",
      "step 33000 , validation loss : 0.562411\n",
      "step 33000 , validation  accuracy 0.809091\n",
      "step 33000 , validation loss : 0.562012\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68533205986\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687761068344\n",
      "step 33100 , validation  accuracy 0.754546\n",
      "step 33100 , validation loss : 0.591706\n",
      "step 33100 , validation  accuracy 0.833333\n",
      "step 33100 , validation loss : 0.414087\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67623591423\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676918029785\n",
      "step 33200 , validation  accuracy 0.669697\n",
      "step 33200 , validation loss : 0.908902\n",
      "step 33200 , validation  accuracy 0.872727\n",
      "step 33200 , validation loss : 0.36529\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678141832352\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685610055923\n",
      "step 33300 , validation  accuracy 0.715152\n",
      "step 33300 , validation loss : 0.627983\n",
      "step 33300 , validation  accuracy 0.836364\n",
      "step 33300 , validation loss : 0.398631\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693526029587\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697212219238\n",
      "step 33400 , validation  accuracy 0.724243\n",
      "step 33400 , validation loss : 0.630942\n",
      "step 33400 , validation  accuracy 0.830303\n",
      "step 33400 , validation loss : 0.434416\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682385921478\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675251960754\n",
      "step 33500 , validation  accuracy 0.730303\n",
      "step 33500 , validation loss : 0.625704\n",
      "step 33500 , validation  accuracy 0.842424\n",
      "step 33500 , validation loss : 0.374743\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696392774582\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684545040131\n",
      "step 33600 , validation  accuracy 0.745455\n",
      "step 33600 , validation loss : 0.553944\n",
      "step 33600 , validation  accuracy 0.827273\n",
      "step 33600 , validation loss : 0.429259\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680818796158\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683835983276\n",
      "step 33700 , validation  accuracy 0.672727\n",
      "step 33700 , validation loss : 0.674782\n",
      "step 33700 , validation  accuracy 0.863636\n",
      "step 33700 , validation loss : 0.359872\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692232131958\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692299127579\n",
      "step 33800 , validation  accuracy 0.80303\n",
      "step 33800 , validation loss : 0.476766\n",
      "step 33800 , validation  accuracy 0.781818\n",
      "step 33800 , validation loss : 0.614721\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686595916748\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686845064163\n",
      "step 33900 , validation  accuracy 0.815152\n",
      "step 33900 , validation loss : 0.502346\n",
      "step 33900 , validation  accuracy 0.748485\n",
      "step 33900 , validation loss : 0.779563\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691313028336\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67604804039\n",
      "step 34000 , validation  accuracy 0.733333\n",
      "step 34000 , validation loss : 0.638554\n",
      "step 34000 , validation  accuracy 0.860606\n",
      "step 34000 , validation loss : 0.364196\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67978310585\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683145046234\n",
      "step 34100 , validation  accuracy 0.733333\n",
      "step 34100 , validation loss : 0.576512\n",
      "step 34100 , validation  accuracy 0.818182\n",
      "step 34100 , validation loss : 0.435071\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677532911301\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684231042862\n",
      "step 34200 , validation  accuracy 0.739394\n",
      "step 34200 , validation loss : 0.570335\n",
      "step 34200 , validation  accuracy 0.854546\n",
      "step 34200 , validation loss : 0.402523\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680500030518\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698249101639\n",
      "step 34300 , validation  accuracy 0.672727\n",
      "step 34300 , validation loss : 0.725044\n",
      "step 34300 , validation  accuracy 0.875758\n",
      "step 34300 , validation loss : 0.31363\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676374912262\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686991930008\n",
      "step 34400 , validation  accuracy 0.809091\n",
      "step 34400 , validation loss : 0.440214\n",
      "step 34400 , validation  accuracy 0.745455\n",
      "step 34400 , validation loss : 0.632568\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694584131241\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685500860214\n",
      "step 34500 , validation  accuracy 0.766667\n",
      "step 34500 , validation loss : 0.496043\n",
      "step 34500 , validation  accuracy 0.793939\n",
      "step 34500 , validation loss : 0.626209\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6827480793\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683264970779\n",
      "step 34600 , validation  accuracy 0.754545\n",
      "step 34600 , validation loss : 0.513565\n",
      "step 34600 , validation  accuracy 0.784848\n",
      "step 34600 , validation loss : 0.552278\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688786029816\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68921995163\n",
      "step 34700 , validation  accuracy 0.736364\n",
      "step 34700 , validation loss : 0.574798\n",
      "step 34700 , validation  accuracy 0.830303\n",
      "step 34700 , validation loss : 0.432143\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686349868774\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694223165512\n",
      "step 34800 , validation  accuracy 0.790909\n",
      "step 34800 , validation loss : 0.503524\n",
      "step 34800 , validation  accuracy 0.772727\n",
      "step 34800 , validation loss : 0.585223\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689337015152\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687298059464\n",
      "step 34900 , validation  accuracy 0.781818\n",
      "step 34900 , validation loss : 0.537288\n",
      "step 34900 , validation  accuracy 0.809091\n",
      "step 34900 , validation loss : 0.503539\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676245927811\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679107904434\n",
      "step 35000 , validation  accuracy 0.748485\n",
      "step 35000 , validation loss : 0.580136\n",
      "step 35000 , validation  accuracy 0.818182\n",
      "step 35000 , validation loss : 0.456868\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67654299736\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700053930283\n",
      "step 35100 , validation  accuracy 0.687879\n",
      "step 35100 , validation loss : 0.805785\n",
      "step 35100 , validation  accuracy 0.89697\n",
      "step 35100 , validation loss : 0.372408\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699513912201\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67946600914\n",
      "step 35200 , validation  accuracy 0.745455\n",
      "step 35200 , validation loss : 0.664777\n",
      "step 35200 , validation  accuracy 0.836364\n",
      "step 35200 , validation loss : 0.502557\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676471948624\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685161113739\n",
      "step 35300 , validation  accuracy 0.7\n",
      "step 35300 , validation loss : 0.732944\n",
      "step 35300 , validation  accuracy 0.887879\n",
      "step 35300 , validation loss : 0.303616\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699834108353\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69802904129\n",
      "step 35400 , validation  accuracy 0.772727\n",
      "step 35400 , validation loss : 0.594149\n",
      "step 35400 , validation  accuracy 0.815152\n",
      "step 35400 , validation loss : 0.50527\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680202960968\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692036867142\n",
      "step 35500 , validation  accuracy 0.721212\n",
      "step 35500 , validation loss : 0.759355\n",
      "step 35500 , validation  accuracy 0.851515\n",
      "step 35500 , validation loss : 0.378625\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.738013029099\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703072071075\n",
      "step 35600 , validation  accuracy 0.751515\n",
      "step 35600 , validation loss : 0.602519\n",
      "step 35600 , validation  accuracy 0.839394\n",
      "step 35600 , validation loss : 0.405102\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685323953629\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680135965347\n",
      "step 35700 , validation  accuracy 0.754546\n",
      "step 35700 , validation loss : 0.536651\n",
      "step 35700 , validation  accuracy 0.812121\n",
      "step 35700 , validation loss : 0.562901\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689166069031\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678638935089\n",
      "step 35800 , validation  accuracy 0.730303\n",
      "step 35800 , validation loss : 0.659789\n",
      "step 35800 , validation  accuracy 0.836364\n",
      "step 35800 , validation loss : 0.458284\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70768404007\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685321092606\n",
      "step 35900 , validation  accuracy 0.748485\n",
      "step 35900 , validation loss : 0.589233\n",
      "step 35900 , validation  accuracy 0.818182\n",
      "step 35900 , validation loss : 0.451531\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679017066956\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684631109238\n",
      "step 36000 , validation  accuracy 0.787879\n",
      "step 36000 , validation loss : 0.496355\n",
      "step 36000 , validation  accuracy 0.760606\n",
      "step 36000 , validation loss : 0.595034\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698367834091\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689718008041\n",
      "step 36100 , validation  accuracy 0.748485\n",
      "step 36100 , validation loss : 0.580935\n",
      "step 36100 , validation  accuracy 0.830303\n",
      "step 36100 , validation loss : 0.467605\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674519062042\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688238859177\n",
      "step 36200 , validation  accuracy 0.727273\n",
      "step 36200 , validation loss : 0.60345\n",
      "step 36200 , validation  accuracy 0.809091\n",
      "step 36200 , validation loss : 0.450841\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679623126984\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681035041809\n",
      "step 36300 , validation  accuracy 0.724242\n",
      "step 36300 , validation loss : 0.654943\n",
      "step 36300 , validation  accuracy 0.842424\n",
      "step 36300 , validation loss : 0.352854\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680323839188\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689903020859\n",
      "step 36400 , validation  accuracy 0.754546\n",
      "step 36400 , validation loss : 0.511716\n",
      "step 36400 , validation  accuracy 0.80303\n",
      "step 36400 , validation loss : 0.519649\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687394857407\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689033985138\n",
      "step 36500 , validation  accuracy 0.766667\n",
      "step 36500 , validation loss : 0.549411\n",
      "step 36500 , validation  accuracy 0.790909\n",
      "step 36500 , validation loss : 0.61542\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686078071594\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680545091629\n",
      "step 36600 , validation  accuracy 0.784849\n",
      "step 36600 , validation loss : 0.479728\n",
      "step 36600 , validation  accuracy 0.79394\n",
      "step 36600 , validation loss : 0.597449\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68915605545\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686368942261\n",
      "step 36700 , validation  accuracy 0.70303\n",
      "step 36700 , validation loss : 0.711462\n",
      "step 36700 , validation  accuracy 0.866667\n",
      "step 36700 , validation loss : 0.371738\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677639007568\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68323802948\n",
      "step 36800 , validation  accuracy 0.690909\n",
      "step 36800 , validation loss : 0.665431\n",
      "step 36800 , validation  accuracy 0.878788\n",
      "step 36800 , validation loss : 0.373206\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68240904808\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676691055298\n",
      "step 36900 , validation  accuracy 0.736364\n",
      "step 36900 , validation loss : 0.615572\n",
      "step 36900 , validation  accuracy 0.809091\n",
      "step 36900 , validation loss : 0.445867\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693995952606\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69699883461\n",
      "step 37000 , validation  accuracy 0.775758\n",
      "step 37000 , validation loss : 0.554247\n",
      "step 37000 , validation  accuracy 0.775758\n",
      "step 37000 , validation loss : 0.629701\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686799049377\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706737995148\n",
      "step 37100 , validation  accuracy 0.784849\n",
      "step 37100 , validation loss : 0.451367\n",
      "step 37100 , validation  accuracy 0.739394\n",
      "step 37100 , validation loss : 0.672586\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690473794937\n",
      "(11, 30, 300, 300, 3)\n",
      "0.716038227081\n",
      "step 37200 , validation  accuracy 0.681818\n",
      "step 37200 , validation loss : 0.708108\n",
      "step 37200 , validation  accuracy 0.854546\n",
      "step 37200 , validation loss : 0.372862\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688810825348\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677177906036\n",
      "step 37300 , validation  accuracy 0.754546\n",
      "step 37300 , validation loss : 0.497564\n",
      "step 37300 , validation  accuracy 0.79697\n",
      "step 37300 , validation loss : 0.508973\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694185018539\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684920787811\n",
      "step 37400 , validation  accuracy 0.787879\n",
      "step 37400 , validation loss : 0.478899\n",
      "step 37400 , validation  accuracy 0.775758\n",
      "step 37400 , validation loss : 0.511457\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686074972153\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679455041885\n",
      "step 37500 , validation  accuracy 0.751515\n",
      "step 37500 , validation loss : 0.654601\n",
      "step 37500 , validation  accuracy 0.812121\n",
      "step 37500 , validation loss : 0.529593\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697441101074\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684007167816\n",
      "step 37600 , validation  accuracy 0.751515\n",
      "step 37600 , validation loss : 0.586387\n",
      "step 37600 , validation  accuracy 0.8\n",
      "step 37600 , validation loss : 0.566937\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679962873459\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677167892456\n",
      "step 37700 , validation  accuracy 0.775758\n",
      "step 37700 , validation loss : 0.640059\n",
      "step 37700 , validation  accuracy 0.790909\n",
      "step 37700 , validation loss : 0.574905\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677893877029\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684273958206\n",
      "step 37800 , validation  accuracy 0.778788\n",
      "step 37800 , validation loss : 0.497486\n",
      "step 37800 , validation  accuracy 0.751515\n",
      "step 37800 , validation loss : 0.578961\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70824098587\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691565990448\n",
      "step 37900 , validation  accuracy 0.778788\n",
      "step 37900 , validation loss : 0.524487\n",
      "step 37900 , validation  accuracy 0.818182\n",
      "step 37900 , validation loss : 0.474346\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677561998367\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680605888367\n",
      "step 38000 , validation  accuracy 0.79697\n",
      "step 38000 , validation loss : 0.545618\n",
      "step 38000 , validation  accuracy 0.812121\n",
      "step 38000 , validation loss : 0.551931\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694956064224\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687026977539\n",
      "step 38100 , validation  accuracy 0.730303\n",
      "step 38100 , validation loss : 0.634686\n",
      "step 38100 , validation  accuracy 0.839394\n",
      "step 38100 , validation loss : 0.431906\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691483020782\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685950994492\n",
      "step 38200 , validation  accuracy 0.778788\n",
      "step 38200 , validation loss : 0.544408\n",
      "step 38200 , validation  accuracy 0.757576\n",
      "step 38200 , validation loss : 0.635749\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699551105499\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688637018204\n",
      "step 38300 , validation  accuracy 0.754545\n",
      "step 38300 , validation loss : 0.550138\n",
      "step 38300 , validation  accuracy 0.806061\n",
      "step 38300 , validation loss : 0.437692\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699520111084\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705805063248\n",
      "step 38400 , validation  accuracy 0.724242\n",
      "step 38400 , validation loss : 0.753901\n",
      "step 38400 , validation  accuracy 0.836364\n",
      "step 38400 , validation loss : 0.446956\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698935031891\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698093175888\n",
      "step 38500 , validation  accuracy 0.718182\n",
      "step 38500 , validation loss : 0.669894\n",
      "step 38500 , validation  accuracy 0.863636\n",
      "step 38500 , validation loss : 0.354828\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675244092941\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686966896057\n",
      "step 38600 , validation  accuracy 0.775758\n",
      "step 38600 , validation loss : 0.499545\n",
      "step 38600 , validation  accuracy 0.787879\n",
      "step 38600 , validation loss : 0.5672\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690802812576\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693357944489\n",
      "step 38700 , validation  accuracy 0.812121\n",
      "step 38700 , validation loss : 0.370065\n",
      "step 38700 , validation  accuracy 0.724242\n",
      "step 38700 , validation loss : 0.634929\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675681114197\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687286138535\n",
      "step 38800 , validation  accuracy 0.751515\n",
      "step 38800 , validation loss : 0.578543\n",
      "step 38800 , validation  accuracy 0.824243\n",
      "step 38800 , validation loss : 0.458717\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682434082031\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691390037537\n",
      "step 38900 , validation  accuracy 0.827273\n",
      "step 38900 , validation loss : 0.436794\n",
      "step 38900 , validation  accuracy 0.757576\n",
      "step 38900 , validation loss : 0.67247\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688670158386\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686825990677\n",
      "step 39000 , validation  accuracy 0.775758\n",
      "step 39000 , validation loss : 0.541349\n",
      "step 39000 , validation  accuracy 0.79697\n",
      "step 39000 , validation loss : 0.487163\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685012102127\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685432195663\n",
      "step 39100 , validation  accuracy 0.715152\n",
      "step 39100 , validation loss : 0.672845\n",
      "step 39100 , validation  accuracy 0.845455\n",
      "step 39100 , validation loss : 0.365993\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687267065048\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691393136978\n",
      "step 39200 , validation  accuracy 0.787879\n",
      "step 39200 , validation loss : 0.455074\n",
      "step 39200 , validation  accuracy 0.739394\n",
      "step 39200 , validation loss : 0.614988\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691828966141\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684818983078\n",
      "step 39300 , validation  accuracy 0.806061\n",
      "step 39300 , validation loss : 0.491853\n",
      "step 39300 , validation  accuracy 0.8\n",
      "step 39300 , validation loss : 0.673145\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69501209259\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690551996231\n",
      "step 39400 , validation  accuracy 0.772727\n",
      "step 39400 , validation loss : 0.48206\n",
      "step 39400 , validation  accuracy 0.79697\n",
      "step 39400 , validation loss : 0.502879\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685894966125\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679651975632\n",
      "step 39500 , validation  accuracy 0.727273\n",
      "step 39500 , validation loss : 0.566914\n",
      "step 39500 , validation  accuracy 0.839394\n",
      "step 39500 , validation loss : 0.390252\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690160036087\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685864925385\n",
      "step 39600 , validation  accuracy 0.733333\n",
      "step 39600 , validation loss : 0.707911\n",
      "step 39600 , validation  accuracy 0.821212\n",
      "step 39600 , validation loss : 0.545723\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68178486824\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685878992081\n",
      "step 39700 , validation  accuracy 0.736364\n",
      "step 39700 , validation loss : 0.566794\n",
      "step 39700 , validation  accuracy 0.848485\n",
      "step 39700 , validation loss : 0.385153\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689856052399\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679513216019\n",
      "step 39800 , validation  accuracy 0.781818\n",
      "step 39800 , validation loss : 0.516825\n",
      "step 39800 , validation  accuracy 0.809091\n",
      "step 39800 , validation loss : 0.418556\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.671268939972\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696225881577\n",
      "step 39900 , validation  accuracy 0.760606\n",
      "step 39900 , validation loss : 0.60454\n",
      "step 39900 , validation  accuracy 0.821212\n",
      "step 39900 , validation loss : 0.455882\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688648939133\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690670013428\n",
      "step 40000 , validation  accuracy 0.687879\n",
      "step 40000 , validation loss : 0.659727\n",
      "step 40000 , validation  accuracy 0.851515\n",
      "step 40000 , validation loss : 0.347847\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686438083649\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673009872437\n",
      "step 40100 , validation  accuracy 0.763636\n",
      "step 40100 , validation loss : 0.681241\n",
      "step 40100 , validation  accuracy 0.821212\n",
      "step 40100 , validation loss : 0.499384\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686046123505\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695716142654\n",
      "step 40200 , validation  accuracy 0.79697\n",
      "step 40200 , validation loss : 0.447037\n",
      "step 40200 , validation  accuracy 0.769697\n",
      "step 40200 , validation loss : 0.567609\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70880484581\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681752920151\n",
      "step 40300 , validation  accuracy 0.760606\n",
      "step 40300 , validation loss : 0.505387\n",
      "step 40300 , validation  accuracy 0.824242\n",
      "step 40300 , validation loss : 0.4971\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686309099197\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689866065979\n",
      "step 40400 , validation  accuracy 0.809091\n",
      "step 40400 , validation loss : 0.465429\n",
      "step 40400 , validation  accuracy 0.760606\n",
      "step 40400 , validation loss : 0.694092\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690316200256\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681807041168\n",
      "step 40500 , validation  accuracy 0.727273\n",
      "step 40500 , validation loss : 0.65457\n",
      "step 40500 , validation  accuracy 0.833333\n",
      "step 40500 , validation loss : 0.451676\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694397926331\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686496019363\n",
      "step 40600 , validation  accuracy 0.79697\n",
      "step 40600 , validation loss : 0.459379\n",
      "step 40600 , validation  accuracy 0.806061\n",
      "step 40600 , validation loss : 0.52454\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681107997894\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678592920303\n",
      "step 40700 , validation  accuracy 0.763636\n",
      "step 40700 , validation loss : 0.469301\n",
      "step 40700 , validation  accuracy 0.815152\n",
      "step 40700 , validation loss : 0.516337\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6708111763\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696905136108\n",
      "step 40800 , validation  accuracy 0.784849\n",
      "step 40800 , validation loss : 0.452215\n",
      "step 40800 , validation  accuracy 0.763636\n",
      "step 40800 , validation loss : 0.562352\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.672274112701\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680038928986\n",
      "step 40900 , validation  accuracy 0.751515\n",
      "step 40900 , validation loss : 0.559368\n",
      "step 40900 , validation  accuracy 0.836364\n",
      "step 40900 , validation loss : 0.422561\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6954870224\n",
      "(11, 30, 300, 300, 3)\n",
      "0.702157020569\n",
      "step 41000 , validation  accuracy 0.757576\n",
      "step 41000 , validation loss : 0.593566\n",
      "step 41000 , validation  accuracy 0.818182\n",
      "step 41000 , validation loss : 0.481333\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675112009048\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685887098312\n",
      "step 41100 , validation  accuracy 0.733333\n",
      "step 41100 , validation loss : 0.690931\n",
      "step 41100 , validation  accuracy 0.845455\n",
      "step 41100 , validation loss : 0.485783\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689231157303\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691187858582\n",
      "step 41200 , validation  accuracy 0.748485\n",
      "step 41200 , validation loss : 0.623443\n",
      "step 41200 , validation  accuracy 0.854546\n",
      "step 41200 , validation loss : 0.404487\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684529066086\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685348987579\n",
      "step 41300 , validation  accuracy 0.8\n",
      "step 41300 , validation loss : 0.454793\n",
      "step 41300 , validation  accuracy 0.787879\n",
      "step 41300 , validation loss : 0.624729\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.707024097443\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69461607933\n",
      "step 41400 , validation  accuracy 0.778788\n",
      "step 41400 , validation loss : 0.492759\n",
      "step 41400 , validation  accuracy 0.818182\n",
      "step 41400 , validation loss : 0.497226\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688475847244\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693588018417\n",
      "step 41500 , validation  accuracy 0.730303\n",
      "step 41500 , validation loss : 0.648819\n",
      "step 41500 , validation  accuracy 0.872727\n",
      "step 41500 , validation loss : 0.36851\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68718290329\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679478168488\n",
      "step 41600 , validation  accuracy 0.730303\n",
      "step 41600 , validation loss : 0.673298\n",
      "step 41600 , validation  accuracy 0.845455\n",
      "step 41600 , validation loss : 0.404136\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674973964691\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69429397583\n",
      "step 41700 , validation  accuracy 0.745455\n",
      "step 41700 , validation loss : 0.581178\n",
      "step 41700 , validation  accuracy 0.836364\n",
      "step 41700 , validation loss : 0.405152\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696018218994\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689238786697\n",
      "step 41800 , validation  accuracy 0.748485\n",
      "step 41800 , validation loss : 0.555135\n",
      "step 41800 , validation  accuracy 0.80303\n",
      "step 41800 , validation loss : 0.489449\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684234857559\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680603027344\n",
      "step 41900 , validation  accuracy 0.787879\n",
      "step 41900 , validation loss : 0.499137\n",
      "step 41900 , validation  accuracy 0.815152\n",
      "step 41900 , validation loss : 0.526756\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675583839417\n",
      "(11, 30, 300, 300, 3)\n",
      "0.70982003212\n",
      "step 42000 , validation  accuracy 0.757576\n",
      "step 42000 , validation loss : 0.574584\n",
      "step 42000 , validation  accuracy 0.821212\n",
      "step 42000 , validation loss : 0.469073\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68240404129\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686496973038\n",
      "step 42100 , validation  accuracy 0.769697\n",
      "step 42100 , validation loss : 0.603096\n",
      "step 42100 , validation  accuracy 0.806061\n",
      "step 42100 , validation loss : 0.526751\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680608034134\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67755484581\n",
      "step 42200 , validation  accuracy 0.79394\n",
      "step 42200 , validation loss : 0.51287\n",
      "step 42200 , validation  accuracy 0.79697\n",
      "step 42200 , validation loss : 0.626499\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687441110611\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681542158127\n",
      "step 42300 , validation  accuracy 0.709091\n",
      "step 42300 , validation loss : 0.694813\n",
      "step 42300 , validation  accuracy 0.854546\n",
      "step 42300 , validation loss : 0.39615\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689990997314\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691129922867\n",
      "step 42400 , validation  accuracy 0.733333\n",
      "step 42400 , validation loss : 0.688085\n",
      "step 42400 , validation  accuracy 0.845455\n",
      "step 42400 , validation loss : 0.407765\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699609041214\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688334941864\n",
      "step 42500 , validation  accuracy 0.721212\n",
      "step 42500 , validation loss : 0.671834\n",
      "step 42500 , validation  accuracy 0.827273\n",
      "step 42500 , validation loss : 0.481353\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682272911072\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689692974091\n",
      "step 42600 , validation  accuracy 0.748485\n",
      "step 42600 , validation loss : 0.56372\n",
      "step 42600 , validation  accuracy 0.821212\n",
      "step 42600 , validation loss : 0.501566\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705811023712\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692193031311\n",
      "step 42700 , validation  accuracy 0.739394\n",
      "step 42700 , validation loss : 0.693377\n",
      "step 42700 , validation  accuracy 0.821212\n",
      "step 42700 , validation loss : 0.497976\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682291030884\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688064813614\n",
      "step 42800 , validation  accuracy 0.727273\n",
      "step 42800 , validation loss : 0.659044\n",
      "step 42800 , validation  accuracy 0.845455\n",
      "step 42800 , validation loss : 0.420548\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682218074799\n",
      "(11, 30, 300, 300, 3)\n",
      "0.70313501358\n",
      "step 42900 , validation  accuracy 0.766667\n",
      "step 42900 , validation loss : 0.545101\n",
      "step 42900 , validation  accuracy 0.778788\n",
      "step 42900 , validation loss : 0.592666\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691721916199\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677304983139\n",
      "step 43000 , validation  accuracy 0.806061\n",
      "step 43000 , validation loss : 0.449403\n",
      "step 43000 , validation  accuracy 0.778788\n",
      "step 43000 , validation loss : 0.554895\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680263996124\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676571130753\n",
      "step 43100 , validation  accuracy 0.763636\n",
      "step 43100 , validation loss : 0.600681\n",
      "step 43100 , validation  accuracy 0.827273\n",
      "step 43100 , validation loss : 0.458562\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700545072556\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687471866608\n",
      "step 43200 , validation  accuracy 0.690909\n",
      "step 43200 , validation loss : 0.761259\n",
      "step 43200 , validation  accuracy 0.851515\n",
      "step 43200 , validation loss : 0.368292\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67108798027\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677047014236\n",
      "step 43300 , validation  accuracy 0.733333\n",
      "step 43300 , validation loss : 0.657187\n",
      "step 43300 , validation  accuracy 0.866667\n",
      "step 43300 , validation loss : 0.348793\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694183826447\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684257984161\n",
      "step 43400 , validation  accuracy 0.721212\n",
      "step 43400 , validation loss : 0.762926\n",
      "step 43400 , validation  accuracy 0.860606\n",
      "step 43400 , validation loss : 0.406834\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.730087995529\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689599990845\n",
      "step 43500 , validation  accuracy 0.730303\n",
      "step 43500 , validation loss : 0.559608\n",
      "step 43500 , validation  accuracy 0.839394\n",
      "step 43500 , validation loss : 0.415808\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688030004501\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685826063156\n",
      "step 43600 , validation  accuracy 0.769697\n",
      "step 43600 , validation loss : 0.529143\n",
      "step 43600 , validation  accuracy 0.836364\n",
      "step 43600 , validation loss : 0.45698\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677075862885\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69132900238\n",
      "step 43700 , validation  accuracy 0.730303\n",
      "step 43700 , validation loss : 0.572645\n",
      "step 43700 , validation  accuracy 0.812121\n",
      "step 43700 , validation loss : 0.481844\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.671521902084\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688155889511\n",
      "step 43800 , validation  accuracy 0.736364\n",
      "step 43800 , validation loss : 0.526843\n",
      "step 43800 , validation  accuracy 0.818182\n",
      "step 43800 , validation loss : 0.460318\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696093082428\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683212995529\n",
      "step 43900 , validation  accuracy 0.736364\n",
      "step 43900 , validation loss : 0.629756\n",
      "step 43900 , validation  accuracy 0.863636\n",
      "step 43900 , validation loss : 0.370806\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679070949554\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683869838715\n",
      "step 44000 , validation  accuracy 0.733333\n",
      "step 44000 , validation loss : 0.603424\n",
      "step 44000 , validation  accuracy 0.839394\n",
      "step 44000 , validation loss : 0.403304\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68869304657\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689194917679\n",
      "step 44100 , validation  accuracy 0.721212\n",
      "step 44100 , validation loss : 0.598207\n",
      "step 44100 , validation  accuracy 0.854546\n",
      "step 44100 , validation loss : 0.375592\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680834054947\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684502124786\n",
      "step 44200 , validation  accuracy 0.836364\n",
      "step 44200 , validation loss : 0.405967\n",
      "step 44200 , validation  accuracy 0.715152\n",
      "step 44200 , validation loss : 0.818142\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695996999741\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688680171967\n",
      "step 44300 , validation  accuracy 0.757576\n",
      "step 44300 , validation loss : 0.554468\n",
      "step 44300 , validation  accuracy 0.806061\n",
      "step 44300 , validation loss : 0.497896\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682363033295\n",
      "(11, 30, 300, 300, 3)\n",
      "0.668845891953\n",
      "step 44400 , validation  accuracy 0.736364\n",
      "step 44400 , validation loss : 0.73734\n",
      "step 44400 , validation  accuracy 0.854546\n",
      "step 44400 , validation loss : 0.395076\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683350086212\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689253091812\n",
      "step 44500 , validation  accuracy 0.727273\n",
      "step 44500 , validation loss : 0.58247\n",
      "step 44500 , validation  accuracy 0.784849\n",
      "step 44500 , validation loss : 0.518955\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680585861206\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673713207245\n",
      "step 44600 , validation  accuracy 0.718182\n",
      "step 44600 , validation loss : 0.576092\n",
      "step 44600 , validation  accuracy 0.839394\n",
      "step 44600 , validation loss : 0.393468\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677148103714\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685319900513\n",
      "step 44700 , validation  accuracy 0.757576\n",
      "step 44700 , validation loss : 0.583234\n",
      "step 44700 , validation  accuracy 0.821212\n",
      "step 44700 , validation loss : 0.444076\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69612288475\n",
      "(11, 30, 300, 300, 3)\n",
      "0.710886001587\n",
      "step 44800 , validation  accuracy 0.763636\n",
      "step 44800 , validation loss : 0.609358\n",
      "step 44800 , validation  accuracy 0.812121\n",
      "step 44800 , validation loss : 0.523938\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680549144745\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690680980682\n",
      "step 44900 , validation  accuracy 0.69697\n",
      "step 44900 , validation loss : 0.771331\n",
      "step 44900 , validation  accuracy 0.884849\n",
      "step 44900 , validation loss : 0.352479\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690841913223\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689689874649\n",
      "step 45000 , validation  accuracy 0.70303\n",
      "step 45000 , validation loss : 0.721328\n",
      "step 45000 , validation  accuracy 0.863636\n",
      "step 45000 , validation loss : 0.342161\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675399065018\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693711996078\n",
      "step 45100 , validation  accuracy 0.757576\n",
      "step 45100 , validation loss : 0.562481\n",
      "step 45100 , validation  accuracy 0.793939\n",
      "step 45100 , validation loss : 0.522627\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689913034439\n",
      "(11, 30, 300, 300, 3)\n",
      "0.725014925003\n",
      "step 45200 , validation  accuracy 0.751515\n",
      "step 45200 , validation loss : 0.576479\n",
      "step 45200 , validation  accuracy 0.836364\n",
      "step 45200 , validation loss : 0.415435\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683069944382\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678196191788\n",
      "step 45300 , validation  accuracy 0.812121\n",
      "step 45300 , validation loss : 0.438508\n",
      "step 45300 , validation  accuracy 0.766667\n",
      "step 45300 , validation loss : 0.626033\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.707019090652\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677849054337\n",
      "step 45400 , validation  accuracy 0.760606\n",
      "step 45400 , validation loss : 0.566776\n",
      "step 45400 , validation  accuracy 0.833333\n",
      "step 45400 , validation loss : 0.423884\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684190034866\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682882070541\n",
      "step 45500 , validation  accuracy 0.766667\n",
      "step 45500 , validation loss : 0.517051\n",
      "step 45500 , validation  accuracy 0.821212\n",
      "step 45500 , validation loss : 0.465052\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681184053421\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693163156509\n",
      "step 45600 , validation  accuracy 0.739394\n",
      "step 45600 , validation loss : 0.618165\n",
      "step 45600 , validation  accuracy 0.824243\n",
      "step 45600 , validation loss : 0.448095\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687710046768\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683828115463\n",
      "step 45700 , validation  accuracy 0.739394\n",
      "step 45700 , validation loss : 0.654734\n",
      "step 45700 , validation  accuracy 0.830303\n",
      "step 45700 , validation loss : 0.431611\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706111192703\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688597917557\n",
      "step 45800 , validation  accuracy 0.763636\n",
      "step 45800 , validation loss : 0.619702\n",
      "step 45800 , validation  accuracy 0.836364\n",
      "step 45800 , validation loss : 0.513058\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687381982803\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688595056534\n",
      "step 45900 , validation  accuracy 0.769697\n",
      "step 45900 , validation loss : 0.542231\n",
      "step 45900 , validation  accuracy 0.8\n",
      "step 45900 , validation loss : 0.551899\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686553001404\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691496133804\n",
      "step 46000 , validation  accuracy 0.790909\n",
      "step 46000 , validation loss : 0.535542\n",
      "step 46000 , validation  accuracy 0.806061\n",
      "step 46000 , validation loss : 0.601178\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699666023254\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684756040573\n",
      "step 46100 , validation  accuracy 0.724242\n",
      "step 46100 , validation loss : 0.692306\n",
      "step 46100 , validation  accuracy 0.860606\n",
      "step 46100 , validation loss : 0.416257\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676975011826\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673884153366\n",
      "step 46200 , validation  accuracy 0.79394\n",
      "step 46200 , validation loss : 0.504313\n",
      "step 46200 , validation  accuracy 0.787879\n",
      "step 46200 , validation loss : 0.604185\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688369989395\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686077833176\n",
      "step 46300 , validation  accuracy 0.775758\n",
      "step 46300 , validation loss : 0.485583\n",
      "step 46300 , validation  accuracy 0.815152\n",
      "step 46300 , validation loss : 0.467788\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6853120327\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697503089905\n",
      "step 46400 , validation  accuracy 0.675758\n",
      "step 46400 , validation loss : 0.73964\n",
      "step 46400 , validation  accuracy 0.887879\n",
      "step 46400 , validation loss : 0.308914\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680941820145\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682614088058\n",
      "step 46500 , validation  accuracy 0.778788\n",
      "step 46500 , validation loss : 0.530521\n",
      "step 46500 , validation  accuracy 0.818182\n",
      "step 46500 , validation loss : 0.49206\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688441991806\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680207967758\n",
      "step 46600 , validation  accuracy 0.79394\n",
      "step 46600 , validation loss : 0.429467\n",
      "step 46600 , validation  accuracy 0.733333\n",
      "step 46600 , validation loss : 0.685342\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676184892654\n",
      "(11, 30, 300, 300, 3)\n",
      "0.720843791962\n",
      "step 46700 , validation  accuracy 0.775758\n",
      "step 46700 , validation loss : 0.494442\n",
      "step 46700 , validation  accuracy 0.839394\n",
      "step 46700 , validation loss : 0.447114\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695213079453\n",
      "(11, 30, 300, 300, 3)\n",
      "0.709779024124\n",
      "step 46800 , validation  accuracy 0.748485\n",
      "step 46800 , validation loss : 0.622204\n",
      "step 46800 , validation  accuracy 0.833333\n",
      "step 46800 , validation loss : 0.464891\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67900800705\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700377941132\n",
      "step 46900 , validation  accuracy 0.727273\n",
      "step 46900 , validation loss : 0.624534\n",
      "step 46900 , validation  accuracy 0.839394\n",
      "step 46900 , validation loss : 0.421504\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687552928925\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691031932831\n",
      "step 47000 , validation  accuracy 0.8\n",
      "step 47000 , validation loss : 0.456349\n",
      "step 47000 , validation  accuracy 0.784849\n",
      "step 47000 , validation loss : 0.639372\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684803962708\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678797006607\n",
      "step 47100 , validation  accuracy 0.724243\n",
      "step 47100 , validation loss : 0.701905\n",
      "step 47100 , validation  accuracy 0.884849\n",
      "step 47100 , validation loss : 0.339079\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69738817215\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688789129257\n",
      "step 47200 , validation  accuracy 0.736364\n",
      "step 47200 , validation loss : 0.592204\n",
      "step 47200 , validation  accuracy 0.860606\n",
      "step 47200 , validation loss : 0.409512\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677846908569\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684280872345\n",
      "step 47300 , validation  accuracy 0.760606\n",
      "step 47300 , validation loss : 0.556922\n",
      "step 47300 , validation  accuracy 0.830303\n",
      "step 47300 , validation loss : 0.448595\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693148136139\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69105887413\n",
      "step 47400 , validation  accuracy 0.790909\n",
      "step 47400 , validation loss : 0.521577\n",
      "step 47400 , validation  accuracy 0.790909\n",
      "step 47400 , validation loss : 0.6171\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689589977264\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677343845367\n",
      "step 47500 , validation  accuracy 0.754546\n",
      "step 47500 , validation loss : 0.579647\n",
      "step 47500 , validation  accuracy 0.821212\n",
      "step 47500 , validation loss : 0.495842\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692205905914\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684223890305\n",
      "step 47600 , validation  accuracy 0.721212\n",
      "step 47600 , validation loss : 0.66385\n",
      "step 47600 , validation  accuracy 0.860606\n",
      "step 47600 , validation loss : 0.386458\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679636001587\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690122127533\n",
      "step 47700 , validation  accuracy 0.781818\n",
      "step 47700 , validation loss : 0.536939\n",
      "step 47700 , validation  accuracy 0.778788\n",
      "step 47700 , validation loss : 0.603888\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688333034515\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679941892624\n",
      "step 47800 , validation  accuracy 0.715152\n",
      "step 47800 , validation loss : 0.77242\n",
      "step 47800 , validation  accuracy 0.860606\n",
      "step 47800 , validation loss : 0.370981\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703419208527\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694122076035\n",
      "step 47900 , validation  accuracy 0.724243\n",
      "step 47900 , validation loss : 0.645135\n",
      "step 47900 , validation  accuracy 0.860606\n",
      "step 47900 , validation loss : 0.381291\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684601783752\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695481061935\n",
      "step 48000 , validation  accuracy 0.769697\n",
      "step 48000 , validation loss : 0.53801\n",
      "step 48000 , validation  accuracy 0.824242\n",
      "step 48000 , validation loss : 0.462608\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705481052399\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683700084686\n",
      "step 48100 , validation  accuracy 0.80303\n",
      "step 48100 , validation loss : 0.479848\n",
      "step 48100 , validation  accuracy 0.827273\n",
      "step 48100 , validation loss : 0.486737\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68870306015\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680859804153\n",
      "step 48200 , validation  accuracy 0.712121\n",
      "step 48200 , validation loss : 0.680489\n",
      "step 48200 , validation  accuracy 0.854546\n",
      "step 48200 , validation loss : 0.381219\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703207015991\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69690990448\n",
      "step 48300 , validation  accuracy 0.790909\n",
      "step 48300 , validation loss : 0.517315\n",
      "step 48300 , validation  accuracy 0.80303\n",
      "step 48300 , validation loss : 0.579463\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676983833313\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695860862732\n",
      "step 48400 , validation  accuracy 0.818182\n",
      "step 48400 , validation loss : 0.482024\n",
      "step 48400 , validation  accuracy 0.775758\n",
      "step 48400 , validation loss : 0.67153\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685050964355\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680785179138\n",
      "step 48500 , validation  accuracy 0.80303\n",
      "step 48500 , validation loss : 0.480778\n",
      "step 48500 , validation  accuracy 0.80303\n",
      "step 48500 , validation loss : 0.533703\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684843063354\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692023992538\n",
      "step 48600 , validation  accuracy 0.778788\n",
      "step 48600 , validation loss : 0.54674\n",
      "step 48600 , validation  accuracy 0.809091\n",
      "step 48600 , validation loss : 0.543021\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674473047256\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679055929184\n",
      "step 48700 , validation  accuracy 0.748485\n",
      "step 48700 , validation loss : 0.562732\n",
      "step 48700 , validation  accuracy 0.845455\n",
      "step 48700 , validation loss : 0.436855\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699957847595\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690546035767\n",
      "step 48800 , validation  accuracy 0.733333\n",
      "step 48800 , validation loss : 0.691153\n",
      "step 48800 , validation  accuracy 0.845455\n",
      "step 48800 , validation loss : 0.438809\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.669774055481\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68501496315\n",
      "step 48900 , validation  accuracy 0.79394\n",
      "step 48900 , validation loss : 0.494855\n",
      "step 48900 , validation  accuracy 0.815152\n",
      "step 48900 , validation loss : 0.525826\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687555074692\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685762166977\n",
      "step 49000 , validation  accuracy 0.712121\n",
      "step 49000 , validation loss : 0.610294\n",
      "step 49000 , validation  accuracy 0.836364\n",
      "step 49000 , validation loss : 0.46378\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693598031998\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684198141098\n",
      "step 49100 , validation  accuracy 0.772727\n",
      "step 49100 , validation loss : 0.608138\n",
      "step 49100 , validation  accuracy 0.812121\n",
      "step 49100 , validation loss : 0.507268\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699414014816\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683669090271\n",
      "step 49200 , validation  accuracy 0.721212\n",
      "step 49200 , validation loss : 0.697166\n",
      "step 49200 , validation  accuracy 0.848485\n",
      "step 49200 , validation loss : 0.405463\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69623708725\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697350025177\n",
      "step 49300 , validation  accuracy 0.812121\n",
      "step 49300 , validation loss : 0.485623\n",
      "step 49300 , validation  accuracy 0.778788\n",
      "step 49300 , validation loss : 0.677591\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68547296524\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692295074463\n",
      "step 49400 , validation  accuracy 0.715152\n",
      "step 49400 , validation loss : 0.706809\n",
      "step 49400 , validation  accuracy 0.857576\n",
      "step 49400 , validation loss : 0.376544\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681297063828\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690448999405\n",
      "step 49500 , validation  accuracy 0.781818\n",
      "step 49500 , validation loss : 0.47342\n",
      "step 49500 , validation  accuracy 0.79697\n",
      "step 49500 , validation loss : 0.510898\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69174695015\n",
      "(11, 30, 300, 300, 3)\n",
      "0.717377901077\n",
      "step 49600 , validation  accuracy 0.715152\n",
      "step 49600 , validation loss : 0.660543\n",
      "step 49600 , validation  accuracy 0.860606\n",
      "step 49600 , validation loss : 0.359051\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685971021652\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683452129364\n",
      "step 49700 , validation  accuracy 0.760606\n",
      "step 49700 , validation loss : 0.645854\n",
      "step 49700 , validation  accuracy 0.821212\n",
      "step 49700 , validation loss : 0.508122\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680431127548\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690495014191\n",
      "step 49800 , validation  accuracy 0.809091\n",
      "step 49800 , validation loss : 0.4499\n",
      "step 49800 , validation  accuracy 0.784849\n",
      "step 49800 , validation loss : 0.555727\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696491956711\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683547019958\n",
      "step 49900 , validation  accuracy 0.715152\n",
      "step 49900 , validation loss : 0.757023\n",
      "step 49900 , validation  accuracy 0.869697\n",
      "step 49900 , validation loss : 0.379244\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683553934097\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679761886597\n",
      "step 50000 , validation  accuracy 0.787879\n",
      "step 50000 , validation loss : 0.574143\n",
      "step 50000 , validation  accuracy 0.833333\n",
      "step 50000 , validation loss : 0.468009\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690228939056\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675689935684\n",
      "step 50100 , validation  accuracy 0.763636\n",
      "step 50100 , validation loss : 0.541018\n",
      "step 50100 , validation  accuracy 0.821212\n",
      "step 50100 , validation loss : 0.49279\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70069694519\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688179016113\n",
      "step 50200 , validation  accuracy 0.787879\n",
      "step 50200 , validation loss : 0.481379\n",
      "step 50200 , validation  accuracy 0.809091\n",
      "step 50200 , validation loss : 0.545949\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687159061432\n",
      "(11, 30, 300, 300, 3)\n",
      "0.670748949051\n",
      "step 50300 , validation  accuracy 0.79697\n",
      "step 50300 , validation loss : 0.45957\n",
      "step 50300 , validation  accuracy 0.787879\n",
      "step 50300 , validation loss : 0.52176\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674551963806\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677080154419\n",
      "step 50400 , validation  accuracy 0.769697\n",
      "step 50400 , validation loss : 0.583502\n",
      "step 50400 , validation  accuracy 0.812121\n",
      "step 50400 , validation loss : 0.534865\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676393985748\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684825897217\n",
      "step 50500 , validation  accuracy 0.733333\n",
      "step 50500 , validation loss : 0.700716\n",
      "step 50500 , validation  accuracy 0.851515\n",
      "step 50500 , validation loss : 0.394947\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.714101791382\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703315019608\n",
      "step 50600 , validation  accuracy 0.766667\n",
      "step 50600 , validation loss : 0.55244\n",
      "step 50600 , validation  accuracy 0.833333\n",
      "step 50600 , validation loss : 0.408952\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682257890701\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703421831131\n",
      "step 50700 , validation  accuracy 0.754546\n",
      "step 50700 , validation loss : 0.591087\n",
      "step 50700 , validation  accuracy 0.836364\n",
      "step 50700 , validation loss : 0.438824\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705091953278\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685384988785\n",
      "step 50800 , validation  accuracy 0.772727\n",
      "step 50800 , validation loss : 0.595901\n",
      "step 50800 , validation  accuracy 0.827273\n",
      "step 50800 , validation loss : 0.485727\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680163145065\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685204982758\n",
      "step 50900 , validation  accuracy 0.712121\n",
      "step 50900 , validation loss : 0.649632\n",
      "step 50900 , validation  accuracy 0.857576\n",
      "step 50900 , validation loss : 0.424175\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691884040833\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689277887344\n",
      "step 51000 , validation  accuracy 0.733333\n",
      "step 51000 , validation loss : 0.624566\n",
      "step 51000 , validation  accuracy 0.851515\n",
      "step 51000 , validation loss : 0.425857\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.704996109009\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693768978119\n",
      "step 51100 , validation  accuracy 0.772727\n",
      "step 51100 , validation loss : 0.576467\n",
      "step 51100 , validation  accuracy 0.845455\n",
      "step 51100 , validation loss : 0.484806\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68507194519\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689259052277\n",
      "step 51200 , validation  accuracy 0.718182\n",
      "step 51200 , validation loss : 0.82468\n",
      "step 51200 , validation  accuracy 0.842424\n",
      "step 51200 , validation loss : 0.46093\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682960033417\n",
      "(11, 30, 300, 300, 3)\n",
      "0.711580991745\n",
      "step 51300 , validation  accuracy 0.769697\n",
      "step 51300 , validation loss : 0.526313\n",
      "step 51300 , validation  accuracy 0.806061\n",
      "step 51300 , validation loss : 0.521644\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679784059525\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690389871597\n",
      "step 51400 , validation  accuracy 0.769697\n",
      "step 51400 , validation loss : 0.57983\n",
      "step 51400 , validation  accuracy 0.836364\n",
      "step 51400 , validation loss : 0.495186\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687310934067\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674009084702\n",
      "step 51500 , validation  accuracy 0.748485\n",
      "step 51500 , validation loss : 0.699005\n",
      "step 51500 , validation  accuracy 0.824242\n",
      "step 51500 , validation loss : 0.569069\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68026804924\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694123029709\n",
      "step 51600 , validation  accuracy 0.772727\n",
      "step 51600 , validation loss : 0.5147\n",
      "step 51600 , validation  accuracy 0.818182\n",
      "step 51600 , validation loss : 0.490276\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687767982483\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683935880661\n",
      "step 51700 , validation  accuracy 0.763636\n",
      "step 51700 , validation loss : 0.545013\n",
      "step 51700 , validation  accuracy 0.8\n",
      "step 51700 , validation loss : 0.566831\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683371067047\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681965112686\n",
      "step 51800 , validation  accuracy 0.79394\n",
      "step 51800 , validation loss : 0.559442\n",
      "step 51800 , validation  accuracy 0.787879\n",
      "step 51800 , validation loss : 0.676861\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70125079155\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687970876694\n",
      "step 51900 , validation  accuracy 0.748485\n",
      "step 51900 , validation loss : 0.560493\n",
      "step 51900 , validation  accuracy 0.860606\n",
      "step 51900 , validation loss : 0.393761\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688672065735\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689432144165\n",
      "step 52000 , validation  accuracy 0.745455\n",
      "step 52000 , validation loss : 0.619491\n",
      "step 52000 , validation  accuracy 0.842424\n",
      "step 52000 , validation loss : 0.507488\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700903892517\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676680088043\n",
      "step 52100 , validation  accuracy 0.754546\n",
      "step 52100 , validation loss : 0.530387\n",
      "step 52100 , validation  accuracy 0.806061\n",
      "step 52100 , validation loss : 0.545034\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678109169006\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692301034927\n",
      "step 52200 , validation  accuracy 0.751515\n",
      "step 52200 , validation loss : 0.784597\n",
      "step 52200 , validation  accuracy 0.857576\n",
      "step 52200 , validation loss : 0.472577\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67893910408\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688767194748\n",
      "step 52300 , validation  accuracy 0.715152\n",
      "step 52300 , validation loss : 0.66001\n",
      "step 52300 , validation  accuracy 0.863636\n",
      "step 52300 , validation loss : 0.37923\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684372901917\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698600053787\n",
      "step 52400 , validation  accuracy 0.809091\n",
      "step 52400 , validation loss : 0.44817\n",
      "step 52400 , validation  accuracy 0.781818\n",
      "step 52400 , validation loss : 0.569002\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689003944397\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689606904984\n",
      "step 52500 , validation  accuracy 0.730303\n",
      "step 52500 , validation loss : 0.703002\n",
      "step 52500 , validation  accuracy 0.818182\n",
      "step 52500 , validation loss : 0.488825\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696038007736\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678146839142\n",
      "step 52600 , validation  accuracy 0.766667\n",
      "step 52600 , validation loss : 0.62377\n",
      "step 52600 , validation  accuracy 0.830303\n",
      "step 52600 , validation loss : 0.526358\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679037094116\n",
      "(11, 30, 300, 300, 3)\n",
      "0.704617023468\n",
      "step 52700 , validation  accuracy 0.751515\n",
      "step 52700 , validation loss : 0.704762\n",
      "step 52700 , validation  accuracy 0.851515\n",
      "step 52700 , validation loss : 0.442616\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689357042313\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684667825699\n",
      "step 52800 , validation  accuracy 0.79697\n",
      "step 52800 , validation loss : 0.660313\n",
      "step 52800 , validation  accuracy 0.809091\n",
      "step 52800 , validation loss : 0.671475\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677927970886\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681385040283\n",
      "step 52900 , validation  accuracy 0.778788\n",
      "step 52900 , validation loss : 0.542559\n",
      "step 52900 , validation  accuracy 0.772727\n",
      "step 52900 , validation loss : 0.633611\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694669008255\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688153028488\n",
      "step 53000 , validation  accuracy 0.79394\n",
      "step 53000 , validation loss : 0.50103\n",
      "step 53000 , validation  accuracy 0.827273\n",
      "step 53000 , validation loss : 0.526551\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675183057785\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690399885178\n",
      "step 53100 , validation  accuracy 0.769697\n",
      "step 53100 , validation loss : 0.705275\n",
      "step 53100 , validation  accuracy 0.842424\n",
      "step 53100 , validation loss : 0.562612\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676247119904\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684947013855\n",
      "step 53200 , validation  accuracy 0.781818\n",
      "step 53200 , validation loss : 0.589528\n",
      "step 53200 , validation  accuracy 0.860606\n",
      "step 53200 , validation loss : 0.455366\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.704594135284\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689445972443\n",
      "step 53300 , validation  accuracy 0.769697\n",
      "step 53300 , validation loss : 0.522597\n",
      "step 53300 , validation  accuracy 0.833333\n",
      "step 53300 , validation loss : 0.433769\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679527997971\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68983912468\n",
      "step 53400 , validation  accuracy 0.772727\n",
      "step 53400 , validation loss : 0.552494\n",
      "step 53400 , validation  accuracy 0.848485\n",
      "step 53400 , validation loss : 0.473808\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689264059067\n",
      "(11, 30, 300, 300, 3)\n",
      "0.717970132828\n",
      "step 53500 , validation  accuracy 0.736364\n",
      "step 53500 , validation loss : 0.630432\n",
      "step 53500 , validation  accuracy 0.851515\n",
      "step 53500 , validation loss : 0.377563\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683273077011\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700170993805\n",
      "step 53600 , validation  accuracy 0.766667\n",
      "step 53600 , validation loss : 0.635952\n",
      "step 53600 , validation  accuracy 0.854546\n",
      "step 53600 , validation loss : 0.428802\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693825960159\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679441928864\n",
      "step 53700 , validation  accuracy 0.757576\n",
      "step 53700 , validation loss : 0.571151\n",
      "step 53700 , validation  accuracy 0.863636\n",
      "step 53700 , validation loss : 0.416022\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681213140488\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693264007568\n",
      "step 53800 , validation  accuracy 0.778788\n",
      "step 53800 , validation loss : 0.528492\n",
      "step 53800 , validation  accuracy 0.79394\n",
      "step 53800 , validation loss : 0.518973\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700989961624\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686499118805\n",
      "step 53900 , validation  accuracy 0.781818\n",
      "step 53900 , validation loss : 0.521755\n",
      "step 53900 , validation  accuracy 0.836364\n",
      "step 53900 , validation loss : 0.460119\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67607998848\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699369907379\n",
      "step 54000 , validation  accuracy 0.733333\n",
      "step 54000 , validation loss : 0.775106\n",
      "step 54000 , validation  accuracy 0.878788\n",
      "step 54000 , validation loss : 0.400792\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700476169586\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690155029297\n",
      "step 54100 , validation  accuracy 0.727273\n",
      "step 54100 , validation loss : 0.593983\n",
      "step 54100 , validation  accuracy 0.857576\n",
      "step 54100 , validation loss : 0.375813\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68075299263\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68830704689\n",
      "step 54200 , validation  accuracy 0.760606\n",
      "step 54200 , validation loss : 0.609364\n",
      "step 54200 , validation  accuracy 0.839394\n",
      "step 54200 , validation loss : 0.442868\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691268920898\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683452129364\n",
      "step 54300 , validation  accuracy 0.784849\n",
      "step 54300 , validation loss : 0.505722\n",
      "step 54300 , validation  accuracy 0.781818\n",
      "step 54300 , validation loss : 0.596925\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69570183754\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690618991852\n",
      "step 54400 , validation  accuracy 0.766667\n",
      "step 54400 , validation loss : 0.702516\n",
      "step 54400 , validation  accuracy 0.848485\n",
      "step 54400 , validation loss : 0.490807\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684680938721\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688768863678\n",
      "step 54500 , validation  accuracy 0.79697\n",
      "step 54500 , validation loss : 0.439792\n",
      "step 54500 , validation  accuracy 0.833333\n",
      "step 54500 , validation loss : 0.510619\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695191144943\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686648845673\n",
      "step 54600 , validation  accuracy 0.772727\n",
      "step 54600 , validation loss : 0.624529\n",
      "step 54600 , validation  accuracy 0.857576\n",
      "step 54600 , validation loss : 0.429684\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682582139969\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683055877686\n",
      "step 54700 , validation  accuracy 0.766667\n",
      "step 54700 , validation loss : 0.596842\n",
      "step 54700 , validation  accuracy 0.848485\n",
      "step 54700 , validation loss : 0.425868\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699739933014\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684736967087\n",
      "step 54800 , validation  accuracy 0.724242\n",
      "step 54800 , validation loss : 0.660883\n",
      "step 54800 , validation  accuracy 0.884849\n",
      "step 54800 , validation loss : 0.347645\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686627864838\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685935020447\n",
      "step 54900 , validation  accuracy 0.790909\n",
      "step 54900 , validation loss : 0.648151\n",
      "step 54900 , validation  accuracy 0.812121\n",
      "step 54900 , validation loss : 0.633833\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690110206604\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689790010452\n",
      "step 55000 , validation  accuracy 0.790909\n",
      "step 55000 , validation loss : 0.585506\n",
      "step 55000 , validation  accuracy 0.809091\n",
      "step 55000 , validation loss : 0.56687\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68793797493\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687185049057\n",
      "step 55100 , validation  accuracy 0.79394\n",
      "step 55100 , validation loss : 0.541872\n",
      "step 55100 , validation  accuracy 0.80303\n",
      "step 55100 , validation loss : 0.654851\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693493843079\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686700105667\n",
      "step 55200 , validation  accuracy 0.769697\n",
      "step 55200 , validation loss : 0.644415\n",
      "step 55200 , validation  accuracy 0.821212\n",
      "step 55200 , validation loss : 0.503099\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679069042206\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680447101593\n",
      "step 55300 , validation  accuracy 0.754546\n",
      "step 55300 , validation loss : 0.654709\n",
      "step 55300 , validation  accuracy 0.857576\n",
      "step 55300 , validation loss : 0.449712\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679397106171\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682538986206\n",
      "step 55400 , validation  accuracy 0.775758\n",
      "step 55400 , validation loss : 0.5747\n",
      "step 55400 , validation  accuracy 0.842424\n",
      "step 55400 , validation loss : 0.477411\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682868003845\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694220066071\n",
      "step 55500 , validation  accuracy 0.748485\n",
      "step 55500 , validation loss : 0.707585\n",
      "step 55500 , validation  accuracy 0.848485\n",
      "step 55500 , validation loss : 0.509455\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678908109665\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698835849762\n",
      "step 55600 , validation  accuracy 0.79394\n",
      "step 55600 , validation loss : 0.54404\n",
      "step 55600 , validation  accuracy 0.809091\n",
      "step 55600 , validation loss : 0.597205\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688807010651\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683765888214\n",
      "step 55700 , validation  accuracy 0.751515\n",
      "step 55700 , validation loss : 0.675331\n",
      "step 55700 , validation  accuracy 0.863636\n",
      "step 55700 , validation loss : 0.40169\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684900045395\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687105178833\n",
      "step 55800 , validation  accuracy 0.730303\n",
      "step 55800 , validation loss : 0.583455\n",
      "step 55800 , validation  accuracy 0.857576\n",
      "step 55800 , validation loss : 0.401058\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691284894943\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69109416008\n",
      "step 55900 , validation  accuracy 0.748485\n",
      "step 55900 , validation loss : 0.672368\n",
      "step 55900 , validation  accuracy 0.848485\n",
      "step 55900 , validation loss : 0.454105\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684373140335\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695881128311\n",
      "step 56000 , validation  accuracy 0.784849\n",
      "step 56000 , validation loss : 0.589192\n",
      "step 56000 , validation  accuracy 0.821212\n",
      "step 56000 , validation loss : 0.484801\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695788145065\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683959007263\n",
      "step 56100 , validation  accuracy 0.706061\n",
      "step 56100 , validation loss : 0.678927\n",
      "step 56100 , validation  accuracy 0.866667\n",
      "step 56100 , validation loss : 0.330168\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687390089035\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684268951416\n",
      "step 56200 , validation  accuracy 0.766667\n",
      "step 56200 , validation loss : 0.593158\n",
      "step 56200 , validation  accuracy 0.848485\n",
      "step 56200 , validation loss : 0.440116\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.704931020737\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69809794426\n",
      "step 56300 , validation  accuracy 0.730303\n",
      "step 56300 , validation loss : 0.709977\n",
      "step 56300 , validation  accuracy 0.890909\n",
      "step 56300 , validation loss : 0.335017\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695604085922\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695490837097\n",
      "step 56400 , validation  accuracy 0.784849\n",
      "step 56400 , validation loss : 0.513605\n",
      "step 56400 , validation  accuracy 0.842424\n",
      "step 56400 , validation loss : 0.466784\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694279193878\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677388906479\n",
      "step 56500 , validation  accuracy 0.809091\n",
      "step 56500 , validation loss : 0.416251\n",
      "step 56500 , validation  accuracy 0.748485\n",
      "step 56500 , validation loss : 0.620291\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695341110229\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696782112122\n",
      "step 56600 , validation  accuracy 0.721212\n",
      "step 56600 , validation loss : 0.783278\n",
      "step 56600 , validation  accuracy 0.869697\n",
      "step 56600 , validation loss : 0.412726\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684982061386\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69228386879\n",
      "step 56700 , validation  accuracy 0.775758\n",
      "step 56700 , validation loss : 0.44466\n",
      "step 56700 , validation  accuracy 0.824243\n",
      "step 56700 , validation loss : 0.481828\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703842163086\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678568124771\n",
      "step 56800 , validation  accuracy 0.781818\n",
      "step 56800 , validation loss : 0.544897\n",
      "step 56800 , validation  accuracy 0.842424\n",
      "step 56800 , validation loss : 0.485392\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685883045197\n",
      "(11, 30, 300, 300, 3)\n",
      "0.704938173294\n",
      "step 56900 , validation  accuracy 0.727273\n",
      "step 56900 , validation loss : 0.757725\n",
      "step 56900 , validation  accuracy 0.872727\n",
      "step 56900 , validation loss : 0.369287\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693704843521\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68232011795\n",
      "step 57000 , validation  accuracy 0.757576\n",
      "step 57000 , validation loss : 0.638647\n",
      "step 57000 , validation  accuracy 0.851515\n",
      "step 57000 , validation loss : 0.463615\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682626008987\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683434009552\n",
      "step 57100 , validation  accuracy 0.760606\n",
      "step 57100 , validation loss : 0.524546\n",
      "step 57100 , validation  accuracy 0.839394\n",
      "step 57100 , validation loss : 0.452218\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693125963211\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67878985405\n",
      "step 57200 , validation  accuracy 0.769697\n",
      "step 57200 , validation loss : 0.586206\n",
      "step 57200 , validation  accuracy 0.836364\n",
      "step 57200 , validation loss : 0.452867\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680516958237\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694791078568\n",
      "step 57300 , validation  accuracy 0.763636\n",
      "step 57300 , validation loss : 0.714723\n",
      "step 57300 , validation  accuracy 0.842424\n",
      "step 57300 , validation loss : 0.524812\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688832998276\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684257984161\n",
      "step 57400 , validation  accuracy 0.760606\n",
      "step 57400 , validation loss : 0.666392\n",
      "step 57400 , validation  accuracy 0.839394\n",
      "step 57400 , validation loss : 0.498694\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685799121857\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682986021042\n",
      "step 57500 , validation  accuracy 0.748485\n",
      "step 57500 , validation loss : 0.638252\n",
      "step 57500 , validation  accuracy 0.851515\n",
      "step 57500 , validation loss : 0.436969\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674490213394\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689234972\n",
      "step 57600 , validation  accuracy 0.775758\n",
      "step 57600 , validation loss : 0.591978\n",
      "step 57600 , validation  accuracy 0.842424\n",
      "step 57600 , validation loss : 0.460232\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687660932541\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67924785614\n",
      "step 57700 , validation  accuracy 0.739394\n",
      "step 57700 , validation loss : 0.724598\n",
      "step 57700 , validation  accuracy 0.857576\n",
      "step 57700 , validation loss : 0.411788\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682202100754\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683171987534\n",
      "step 57800 , validation  accuracy 0.748485\n",
      "step 57800 , validation loss : 0.622473\n",
      "step 57800 , validation  accuracy 0.854545\n",
      "step 57800 , validation loss : 0.414708\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.731585025787\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682279825211\n",
      "step 57900 , validation  accuracy 0.742424\n",
      "step 57900 , validation loss : 0.622129\n",
      "step 57900 , validation  accuracy 0.857576\n",
      "step 57900 , validation loss : 0.380818\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67804813385\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680449008942\n",
      "step 58000 , validation  accuracy 0.727273\n",
      "step 58000 , validation loss : 0.688472\n",
      "step 58000 , validation  accuracy 0.860606\n",
      "step 58000 , validation loss : 0.383887\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688277959824\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67848110199\n",
      "step 58100 , validation  accuracy 0.709091\n",
      "step 58100 , validation loss : 0.808632\n",
      "step 58100 , validation  accuracy 0.857576\n",
      "step 58100 , validation loss : 0.421084\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676893949509\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683530092239\n",
      "step 58200 , validation  accuracy 0.809091\n",
      "step 58200 , validation loss : 0.470986\n",
      "step 58200 , validation  accuracy 0.815152\n",
      "step 58200 , validation loss : 0.599425\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693065166473\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685976982117\n",
      "step 58300 , validation  accuracy 0.745455\n",
      "step 58300 , validation loss : 0.642945\n",
      "step 58300 , validation  accuracy 0.839394\n",
      "step 58300 , validation loss : 0.46715\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690362930298\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685513019562\n",
      "step 58400 , validation  accuracy 0.8\n",
      "step 58400 , validation loss : 0.545985\n",
      "step 58400 , validation  accuracy 0.818182\n",
      "step 58400 , validation loss : 0.598314\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680543899536\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690840959549\n",
      "step 58500 , validation  accuracy 0.763636\n",
      "step 58500 , validation loss : 0.649281\n",
      "step 58500 , validation  accuracy 0.866667\n",
      "step 58500 , validation loss : 0.432261\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690061807632\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69764995575\n",
      "step 58600 , validation  accuracy 0.736364\n",
      "step 58600 , validation loss : 0.594919\n",
      "step 58600 , validation  accuracy 0.833333\n",
      "step 58600 , validation loss : 0.429618\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686216831207\n",
      "(11, 30, 300, 300, 3)\n",
      "0.668023824692\n",
      "step 58700 , validation  accuracy 0.727273\n",
      "step 58700 , validation loss : 0.764674\n",
      "step 58700 , validation  accuracy 0.893939\n",
      "step 58700 , validation loss : 0.381441\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701359033585\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69041800499\n",
      "step 58800 , validation  accuracy 0.730303\n",
      "step 58800 , validation loss : 0.724452\n",
      "step 58800 , validation  accuracy 0.872727\n",
      "step 58800 , validation loss : 0.417263\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682291984558\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68661403656\n",
      "step 58900 , validation  accuracy 0.760606\n",
      "step 58900 , validation loss : 0.615487\n",
      "step 58900 , validation  accuracy 0.848485\n",
      "step 58900 , validation loss : 0.508598\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694877147675\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686418771744\n",
      "step 59000 , validation  accuracy 0.718182\n",
      "step 59000 , validation loss : 0.888401\n",
      "step 59000 , validation  accuracy 0.866667\n",
      "step 59000 , validation loss : 0.347458\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688164949417\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673094987869\n",
      "step 59100 , validation  accuracy 0.730303\n",
      "step 59100 , validation loss : 0.732207\n",
      "step 59100 , validation  accuracy 0.854546\n",
      "step 59100 , validation loss : 0.399432\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693922996521\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68377494812\n",
      "step 59200 , validation  accuracy 0.70303\n",
      "step 59200 , validation loss : 0.869016\n",
      "step 59200 , validation  accuracy 0.890909\n",
      "step 59200 , validation loss : 0.355545\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692914962769\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68648815155\n",
      "step 59300 , validation  accuracy 0.769697\n",
      "step 59300 , validation loss : 0.592726\n",
      "step 59300 , validation  accuracy 0.845455\n",
      "step 59300 , validation loss : 0.452989\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.734862089157\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6917719841\n",
      "step 59400 , validation  accuracy 0.739394\n",
      "step 59400 , validation loss : 0.643658\n",
      "step 59400 , validation  accuracy 0.854546\n",
      "step 59400 , validation loss : 0.393919\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688697099686\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68748998642\n",
      "step 59500 , validation  accuracy 0.775758\n",
      "step 59500 , validation loss : 0.528275\n",
      "step 59500 , validation  accuracy 0.830303\n",
      "step 59500 , validation loss : 0.475314\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690830945969\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686125040054\n",
      "step 59600 , validation  accuracy 0.721212\n",
      "step 59600 , validation loss : 0.780773\n",
      "step 59600 , validation  accuracy 0.887879\n",
      "step 59600 , validation loss : 0.323046\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693336009979\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690749168396\n",
      "step 59700 , validation  accuracy 0.760606\n",
      "step 59700 , validation loss : 0.694865\n",
      "step 59700 , validation  accuracy 0.836364\n",
      "step 59700 , validation loss : 0.489409\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684900999069\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679425954819\n",
      "step 59800 , validation  accuracy 0.736364\n",
      "step 59800 , validation loss : 0.689201\n",
      "step 59800 , validation  accuracy 0.854545\n",
      "step 59800 , validation loss : 0.411813\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698094129562\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694049119949\n",
      "step 59900 , validation  accuracy 0.70303\n",
      "step 59900 , validation loss : 0.764926\n",
      "step 59900 , validation  accuracy 0.887879\n",
      "step 59900 , validation loss : 0.32886\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678107976913\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683424949646\n",
      "step 60000 , validation  accuracy 0.790909\n",
      "step 60000 , validation loss : 0.602477\n",
      "step 60000 , validation  accuracy 0.830303\n",
      "step 60000 , validation loss : 0.537157\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700183868408\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681459903717\n",
      "step 60100 , validation  accuracy 0.763636\n",
      "step 60100 , validation loss : 0.683879\n",
      "step 60100 , validation  accuracy 0.845455\n",
      "step 60100 , validation loss : 0.498182\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674721002579\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681875944138\n",
      "step 60200 , validation  accuracy 0.739394\n",
      "step 60200 , validation loss : 0.667955\n",
      "step 60200 , validation  accuracy 0.845455\n",
      "step 60200 , validation loss : 0.371029\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685687065125\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679534912109\n",
      "step 60300 , validation  accuracy 0.772727\n",
      "step 60300 , validation loss : 0.531842\n",
      "step 60300 , validation  accuracy 0.824243\n",
      "step 60300 , validation loss : 0.453259\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677905797958\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688868999481\n",
      "step 60400 , validation  accuracy 0.727273\n",
      "step 60400 , validation loss : 0.886778\n",
      "step 60400 , validation  accuracy 0.863636\n",
      "step 60400 , validation loss : 0.3714\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681334972382\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693266868591\n",
      "step 60500 , validation  accuracy 0.79697\n",
      "step 60500 , validation loss : 0.573237\n",
      "step 60500 , validation  accuracy 0.812121\n",
      "step 60500 , validation loss : 0.576447\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690917015076\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692013025284\n",
      "step 60600 , validation  accuracy 0.760606\n",
      "step 60600 , validation loss : 0.662234\n",
      "step 60600 , validation  accuracy 0.845455\n",
      "step 60600 , validation loss : 0.465098\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67361998558\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686775922775\n",
      "step 60700 , validation  accuracy 0.772727\n",
      "step 60700 , validation loss : 0.626941\n",
      "step 60700 , validation  accuracy 0.824242\n",
      "step 60700 , validation loss : 0.539487\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694538116455\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678182125092\n",
      "step 60800 , validation  accuracy 0.8\n",
      "step 60800 , validation loss : 0.594699\n",
      "step 60800 , validation  accuracy 0.815152\n",
      "step 60800 , validation loss : 0.578443\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.671402931213\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6837849617\n",
      "step 60900 , validation  accuracy 0.760606\n",
      "step 60900 , validation loss : 0.667638\n",
      "step 60900 , validation  accuracy 0.827273\n",
      "step 60900 , validation loss : 0.508052\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691121101379\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68619799614\n",
      "step 61000 , validation  accuracy 0.775758\n",
      "step 61000 , validation loss : 0.601091\n",
      "step 61000 , validation  accuracy 0.821212\n",
      "step 61000 , validation loss : 0.556304\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682729005814\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68924498558\n",
      "step 61100 , validation  accuracy 0.757576\n",
      "step 61100 , validation loss : 0.685596\n",
      "step 61100 , validation  accuracy 0.833333\n",
      "step 61100 , validation loss : 0.424591\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696244001389\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694130897522\n",
      "step 61200 , validation  accuracy 0.775758\n",
      "step 61200 , validation loss : 0.611467\n",
      "step 61200 , validation  accuracy 0.793939\n",
      "step 61200 , validation loss : 0.563448\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677463054657\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703592061996\n",
      "step 61300 , validation  accuracy 0.766667\n",
      "step 61300 , validation loss : 0.628067\n",
      "step 61300 , validation  accuracy 0.851515\n",
      "step 61300 , validation loss : 0.437351\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678187131882\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695842027664\n",
      "step 61400 , validation  accuracy 0.766667\n",
      "step 61400 , validation loss : 0.582363\n",
      "step 61400 , validation  accuracy 0.845455\n",
      "step 61400 , validation loss : 0.447607\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693153142929\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691864967346\n",
      "step 61500 , validation  accuracy 0.772727\n",
      "step 61500 , validation loss : 0.631181\n",
      "step 61500 , validation  accuracy 0.845455\n",
      "step 61500 , validation loss : 0.485188\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673137187958\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681249856949\n",
      "step 61600 , validation  accuracy 0.742424\n",
      "step 61600 , validation loss : 0.762073\n",
      "step 61600 , validation  accuracy 0.878788\n",
      "step 61600 , validation loss : 0.338776\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689168930054\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687116861343\n",
      "step 61700 , validation  accuracy 0.769697\n",
      "step 61700 , validation loss : 0.695074\n",
      "step 61700 , validation  accuracy 0.848485\n",
      "step 61700 , validation loss : 0.428529\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684669017792\n",
      "(11, 30, 300, 300, 3)\n",
      "0.713160991669\n",
      "step 61800 , validation  accuracy 0.790909\n",
      "step 61800 , validation loss : 0.634089\n",
      "step 61800 , validation  accuracy 0.815152\n",
      "step 61800 , validation loss : 0.575273\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701053142548\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696420907974\n",
      "step 61900 , validation  accuracy 0.790909\n",
      "step 61900 , validation loss : 0.590846\n",
      "step 61900 , validation  accuracy 0.824243\n",
      "step 61900 , validation loss : 0.555838\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.664796113968\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686313867569\n",
      "step 62000 , validation  accuracy 0.760606\n",
      "step 62000 , validation loss : 0.668528\n",
      "step 62000 , validation  accuracy 0.836364\n",
      "step 62000 , validation loss : 0.44832\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684438943863\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6750228405\n",
      "step 62100 , validation  accuracy 0.766667\n",
      "step 62100 , validation loss : 0.649627\n",
      "step 62100 , validation  accuracy 0.848485\n",
      "step 62100 , validation loss : 0.411298\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693903923035\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693750858307\n",
      "step 62200 , validation  accuracy 0.769697\n",
      "step 62200 , validation loss : 0.678176\n",
      "step 62200 , validation  accuracy 0.839394\n",
      "step 62200 , validation loss : 0.511724\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68092083931\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692313909531\n",
      "step 62300 , validation  accuracy 0.787879\n",
      "step 62300 , validation loss : 0.547501\n",
      "step 62300 , validation  accuracy 0.830303\n",
      "step 62300 , validation loss : 0.457959\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687195062637\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696161031723\n",
      "step 62400 , validation  accuracy 0.766667\n",
      "step 62400 , validation loss : 0.566702\n",
      "step 62400 , validation  accuracy 0.845455\n",
      "step 62400 , validation loss : 0.466229\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686683893204\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684260129929\n",
      "step 62500 , validation  accuracy 0.80303\n",
      "step 62500 , validation loss : 0.494198\n",
      "step 62500 , validation  accuracy 0.815152\n",
      "step 62500 , validation loss : 0.530286\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691478967667\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686675071716\n",
      "step 62600 , validation  accuracy 0.809091\n",
      "step 62600 , validation loss : 0.522097\n",
      "step 62600 , validation  accuracy 0.812121\n",
      "step 62600 , validation loss : 0.592657\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681483030319\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677211046219\n",
      "step 62700 , validation  accuracy 0.760606\n",
      "step 62700 , validation loss : 0.646892\n",
      "step 62700 , validation  accuracy 0.851515\n",
      "step 62700 , validation loss : 0.498601\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683393001556\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689360141754\n",
      "step 62800 , validation  accuracy 0.754546\n",
      "step 62800 , validation loss : 0.625843\n",
      "step 62800 , validation  accuracy 0.842424\n",
      "step 62800 , validation loss : 0.439087\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68212890625\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686496973038\n",
      "step 62900 , validation  accuracy 0.751515\n",
      "step 62900 , validation loss : 0.655638\n",
      "step 62900 , validation  accuracy 0.842424\n",
      "step 62900 , validation loss : 0.484166\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684046030045\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687877178192\n",
      "step 63000 , validation  accuracy 0.724243\n",
      "step 63000 , validation loss : 0.892632\n",
      "step 63000 , validation  accuracy 0.875758\n",
      "step 63000 , validation loss : 0.427836\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68073797226\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689285039902\n",
      "step 63100 , validation  accuracy 0.790909\n",
      "step 63100 , validation loss : 0.51653\n",
      "step 63100 , validation  accuracy 0.836364\n",
      "step 63100 , validation loss : 0.505853\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700450897217\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692942857742\n",
      "step 63200 , validation  accuracy 0.787879\n",
      "step 63200 , validation loss : 0.548988\n",
      "step 63200 , validation  accuracy 0.827273\n",
      "step 63200 , validation loss : 0.613968\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675170898438\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687097072601\n",
      "step 63300 , validation  accuracy 0.766667\n",
      "step 63300 , validation loss : 0.681552\n",
      "step 63300 , validation  accuracy 0.839394\n",
      "step 63300 , validation loss : 0.517719\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684407949448\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686504125595\n",
      "step 63400 , validation  accuracy 0.79697\n",
      "step 63400 , validation loss : 0.626859\n",
      "step 63400 , validation  accuracy 0.833333\n",
      "step 63400 , validation loss : 0.555083\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685041189194\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6871778965\n",
      "step 63500 , validation  accuracy 0.745455\n",
      "step 63500 , validation loss : 0.600417\n",
      "step 63500 , validation  accuracy 0.842424\n",
      "step 63500 , validation loss : 0.460475\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677141189575\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684525966644\n",
      "step 63600 , validation  accuracy 0.760606\n",
      "step 63600 , validation loss : 0.584994\n",
      "step 63600 , validation  accuracy 0.833333\n",
      "step 63600 , validation loss : 0.462497\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699476957321\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680356025696\n",
      "step 63700 , validation  accuracy 0.760606\n",
      "step 63700 , validation loss : 0.71576\n",
      "step 63700 , validation  accuracy 0.848485\n",
      "step 63700 , validation loss : 0.474594\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682585000992\n",
      "(11, 30, 300, 300, 3)\n",
      "0.669972896576\n",
      "step 63800 , validation  accuracy 0.736364\n",
      "step 63800 , validation loss : 0.608012\n",
      "step 63800 , validation  accuracy 0.875758\n",
      "step 63800 , validation loss : 0.378256\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690691947937\n",
      "(11, 30, 300, 300, 3)\n",
      "0.703732967377\n",
      "step 63900 , validation  accuracy 0.690909\n",
      "step 63900 , validation loss : 0.682462\n",
      "step 63900 , validation  accuracy 0.884849\n",
      "step 63900 , validation loss : 0.304165\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681041955948\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675126791\n",
      "step 64000 , validation  accuracy 0.730303\n",
      "step 64000 , validation loss : 0.756292\n",
      "step 64000 , validation  accuracy 0.869697\n",
      "step 64000 , validation loss : 0.403023\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688810825348\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697114944458\n",
      "step 64100 , validation  accuracy 0.769697\n",
      "step 64100 , validation loss : 0.654508\n",
      "step 64100 , validation  accuracy 0.869697\n",
      "step 64100 , validation loss : 0.411805\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688561916351\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684839010239\n",
      "step 64200 , validation  accuracy 0.769697\n",
      "step 64200 , validation loss : 0.582181\n",
      "step 64200 , validation  accuracy 0.842424\n",
      "step 64200 , validation loss : 0.473312\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681701183319\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681751966476\n",
      "step 64300 , validation  accuracy 0.772727\n",
      "step 64300 , validation loss : 0.547899\n",
      "step 64300 , validation  accuracy 0.833333\n",
      "step 64300 , validation loss : 0.553131\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.719532966614\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695593118668\n",
      "step 64400 , validation  accuracy 0.769697\n",
      "step 64400 , validation loss : 0.551649\n",
      "step 64400 , validation  accuracy 0.824243\n",
      "step 64400 , validation loss : 0.549355\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686691999435\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692614793777\n",
      "step 64500 , validation  accuracy 0.784849\n",
      "step 64500 , validation loss : 0.529405\n",
      "step 64500 , validation  accuracy 0.806061\n",
      "step 64500 , validation loss : 0.576738\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697571992874\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678452968597\n",
      "step 64600 , validation  accuracy 0.70303\n",
      "step 64600 , validation loss : 0.785735\n",
      "step 64600 , validation  accuracy 0.854546\n",
      "step 64600 , validation loss : 0.397338\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.671501159668\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68453001976\n",
      "step 64700 , validation  accuracy 0.733333\n",
      "step 64700 , validation loss : 0.682931\n",
      "step 64700 , validation  accuracy 0.839394\n",
      "step 64700 , validation loss : 0.518329\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702475070953\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682353973389\n",
      "step 64800 , validation  accuracy 0.721212\n",
      "step 64800 , validation loss : 0.713929\n",
      "step 64800 , validation  accuracy 0.845455\n",
      "step 64800 , validation loss : 0.436493\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687613010406\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689110994339\n",
      "step 64900 , validation  accuracy 0.787879\n",
      "step 64900 , validation loss : 0.480458\n",
      "step 64900 , validation  accuracy 0.80303\n",
      "step 64900 , validation loss : 0.463517\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694226026535\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690757036209\n",
      "step 65000 , validation  accuracy 0.815152\n",
      "step 65000 , validation loss : 0.449523\n",
      "step 65000 , validation  accuracy 0.787879\n",
      "step 65000 , validation loss : 0.746129\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688874006271\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696217060089\n",
      "step 65100 , validation  accuracy 0.754546\n",
      "step 65100 , validation loss : 0.593524\n",
      "step 65100 , validation  accuracy 0.827273\n",
      "step 65100 , validation loss : 0.47463\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682209014893\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680615901947\n",
      "step 65200 , validation  accuracy 0.775758\n",
      "step 65200 , validation loss : 0.649502\n",
      "step 65200 , validation  accuracy 0.821212\n",
      "step 65200 , validation loss : 0.625385\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681777954102\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690979003906\n",
      "step 65300 , validation  accuracy 0.775758\n",
      "step 65300 , validation loss : 0.644031\n",
      "step 65300 , validation  accuracy 0.827273\n",
      "step 65300 , validation loss : 0.602649\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.672219991684\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691545009613\n",
      "step 65400 , validation  accuracy 0.745455\n",
      "step 65400 , validation loss : 0.711504\n",
      "step 65400 , validation  accuracy 0.863636\n",
      "step 65400 , validation loss : 0.456921\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690893173218\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696484088898\n",
      "step 65500 , validation  accuracy 0.760606\n",
      "step 65500 , validation loss : 0.622969\n",
      "step 65500 , validation  accuracy 0.830303\n",
      "step 65500 , validation loss : 0.554878\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673298835754\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687784910202\n",
      "step 65600 , validation  accuracy 0.757576\n",
      "step 65600 , validation loss : 0.680742\n",
      "step 65600 , validation  accuracy 0.833333\n",
      "step 65600 , validation loss : 0.49775\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684117078781\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675611019135\n",
      "step 65700 , validation  accuracy 0.790909\n",
      "step 65700 , validation loss : 0.612985\n",
      "step 65700 , validation  accuracy 0.812121\n",
      "step 65700 , validation loss : 0.571056\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686774015427\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689383029938\n",
      "step 65800 , validation  accuracy 0.769697\n",
      "step 65800 , validation loss : 0.636351\n",
      "step 65800 , validation  accuracy 0.830303\n",
      "step 65800 , validation loss : 0.510437\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701384067535\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687174081802\n",
      "step 65900 , validation  accuracy 0.790909\n",
      "step 65900 , validation loss : 0.49922\n",
      "step 65900 , validation  accuracy 0.812121\n",
      "step 65900 , validation loss : 0.502021\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687620162964\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686381101608\n",
      "step 66000 , validation  accuracy 0.757576\n",
      "step 66000 , validation loss : 0.580312\n",
      "step 66000 , validation  accuracy 0.836364\n",
      "step 66000 , validation loss : 0.549549\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685585975647\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685528993607\n",
      "step 66100 , validation  accuracy 0.766667\n",
      "step 66100 , validation loss : 0.562695\n",
      "step 66100 , validation  accuracy 0.836364\n",
      "step 66100 , validation loss : 0.56185\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698939085007\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677878856659\n",
      "step 66200 , validation  accuracy 0.748485\n",
      "step 66200 , validation loss : 0.657522\n",
      "step 66200 , validation  accuracy 0.851515\n",
      "step 66200 , validation loss : 0.428727\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682751893997\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693892002106\n",
      "step 66300 , validation  accuracy 0.733333\n",
      "step 66300 , validation loss : 0.616955\n",
      "step 66300 , validation  accuracy 0.866667\n",
      "step 66300 , validation loss : 0.407187\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684772014618\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686674833298\n",
      "step 66400 , validation  accuracy 0.760606\n",
      "step 66400 , validation loss : 0.636278\n",
      "step 66400 , validation  accuracy 0.830303\n",
      "step 66400 , validation loss : 0.496386\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69370508194\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686948060989\n",
      "step 66500 , validation  accuracy 0.775758\n",
      "step 66500 , validation loss : 0.562753\n",
      "step 66500 , validation  accuracy 0.827273\n",
      "step 66500 , validation loss : 0.511589\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691685914993\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698698043823\n",
      "step 66600 , validation  accuracy 0.730303\n",
      "step 66600 , validation loss : 0.69801\n",
      "step 66600 , validation  accuracy 0.842424\n",
      "step 66600 , validation loss : 0.457079\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678000926971\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690496921539\n",
      "step 66700 , validation  accuracy 0.754546\n",
      "step 66700 , validation loss : 0.665883\n",
      "step 66700 , validation  accuracy 0.839394\n",
      "step 66700 , validation loss : 0.528884\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69820690155\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679404020309\n",
      "step 66800 , validation  accuracy 0.778788\n",
      "step 66800 , validation loss : 0.563214\n",
      "step 66800 , validation  accuracy 0.821212\n",
      "step 66800 , validation loss : 0.627426\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.670940876007\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673683166504\n",
      "step 66900 , validation  accuracy 0.751515\n",
      "step 66900 , validation loss : 0.538334\n",
      "step 66900 , validation  accuracy 0.845455\n",
      "step 66900 , validation loss : 0.460063\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688431024551\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694632053375\n",
      "step 67000 , validation  accuracy 0.739394\n",
      "step 67000 , validation loss : 0.69269\n",
      "step 67000 , validation  accuracy 0.854546\n",
      "step 67000 , validation loss : 0.458881\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676051855087\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696979045868\n",
      "step 67100 , validation  accuracy 0.751515\n",
      "step 67100 , validation loss : 0.654841\n",
      "step 67100 , validation  accuracy 0.863636\n",
      "step 67100 , validation loss : 0.464128\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.703779935837\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690155982971\n",
      "step 67200 , validation  accuracy 0.739394\n",
      "step 67200 , validation loss : 0.614275\n",
      "step 67200 , validation  accuracy 0.860606\n",
      "step 67200 , validation loss : 0.400761\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691830158234\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678553104401\n",
      "step 67300 , validation  accuracy 0.736364\n",
      "step 67300 , validation loss : 0.701121\n",
      "step 67300 , validation  accuracy 0.866667\n",
      "step 67300 , validation loss : 0.405159\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686975002289\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681574106216\n",
      "step 67400 , validation  accuracy 0.781818\n",
      "step 67400 , validation loss : 0.631795\n",
      "step 67400 , validation  accuracy 0.815152\n",
      "step 67400 , validation loss : 0.549975\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.710065841675\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682659864426\n",
      "step 67500 , validation  accuracy 0.784849\n",
      "step 67500 , validation loss : 0.57941\n",
      "step 67500 , validation  accuracy 0.830303\n",
      "step 67500 , validation loss : 0.512442\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678194999695\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67856502533\n",
      "step 67600 , validation  accuracy 0.781818\n",
      "step 67600 , validation loss : 0.532106\n",
      "step 67600 , validation  accuracy 0.833333\n",
      "step 67600 , validation loss : 0.543774\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.717224121094\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689692974091\n",
      "step 67700 , validation  accuracy 0.766667\n",
      "step 67700 , validation loss : 0.651767\n",
      "step 67700 , validation  accuracy 0.827273\n",
      "step 67700 , validation loss : 0.55455\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682012081146\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6799659729\n",
      "step 67800 , validation  accuracy 0.736364\n",
      "step 67800 , validation loss : 0.679821\n",
      "step 67800 , validation  accuracy 0.857576\n",
      "step 67800 , validation loss : 0.419982\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692519903183\n",
      "(11, 30, 300, 300, 3)\n",
      "0.702250003815\n",
      "step 67900 , validation  accuracy 0.763637\n",
      "step 67900 , validation loss : 0.600256\n",
      "step 67900 , validation  accuracy 0.848485\n",
      "step 67900 , validation loss : 0.434683\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67685508728\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696119785309\n",
      "step 68000 , validation  accuracy 0.766667\n",
      "step 68000 , validation loss : 0.621161\n",
      "step 68000 , validation  accuracy 0.809091\n",
      "step 68000 , validation loss : 0.550946\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684712171555\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695780992508\n",
      "step 68100 , validation  accuracy 0.79394\n",
      "step 68100 , validation loss : 0.551288\n",
      "step 68100 , validation  accuracy 0.793939\n",
      "step 68100 , validation loss : 0.596413\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.705201148987\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700877904892\n",
      "step 68200 , validation  accuracy 0.730303\n",
      "step 68200 , validation loss : 0.769793\n",
      "step 68200 , validation  accuracy 0.872727\n",
      "step 68200 , validation loss : 0.394889\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684189081192\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674628973007\n",
      "step 68300 , validation  accuracy 0.733333\n",
      "step 68300 , validation loss : 0.733897\n",
      "step 68300 , validation  accuracy 0.872727\n",
      "step 68300 , validation loss : 0.397198\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6861140728\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687810182571\n",
      "step 68400 , validation  accuracy 0.781818\n",
      "step 68400 , validation loss : 0.584452\n",
      "step 68400 , validation  accuracy 0.845455\n",
      "step 68400 , validation loss : 0.499736\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673222064972\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688176870346\n",
      "step 68500 , validation  accuracy 0.757576\n",
      "step 68500 , validation loss : 0.634717\n",
      "step 68500 , validation  accuracy 0.854546\n",
      "step 68500 , validation loss : 0.406455\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696224927902\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685266017914\n",
      "step 68600 , validation  accuracy 0.769697\n",
      "step 68600 , validation loss : 0.521013\n",
      "step 68600 , validation  accuracy 0.809091\n",
      "step 68600 , validation loss : 0.581333\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686962127686\n",
      "(11, 30, 300, 300, 3)\n",
      "0.72386097908\n",
      "step 68700 , validation  accuracy 0.751515\n",
      "step 68700 , validation loss : 0.679953\n",
      "step 68700 , validation  accuracy 0.845455\n",
      "step 68700 , validation loss : 0.443675\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700144052505\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688202857971\n",
      "step 68800 , validation  accuracy 0.745455\n",
      "step 68800 , validation loss : 0.661038\n",
      "step 68800 , validation  accuracy 0.875758\n",
      "step 68800 , validation loss : 0.382878\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683032035828\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682914018631\n",
      "step 68900 , validation  accuracy 0.778788\n",
      "step 68900 , validation loss : 0.616031\n",
      "step 68900 , validation  accuracy 0.821212\n",
      "step 68900 , validation loss : 0.526538\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680866003036\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701208114624\n",
      "step 69000 , validation  accuracy 0.760606\n",
      "step 69000 , validation loss : 0.618698\n",
      "step 69000 , validation  accuracy 0.836364\n",
      "step 69000 , validation loss : 0.516831\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689301013947\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681375026703\n",
      "step 69100 , validation  accuracy 0.806061\n",
      "step 69100 , validation loss : 0.634264\n",
      "step 69100 , validation  accuracy 0.818182\n",
      "step 69100 , validation loss : 0.691679\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698263883591\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705171108246\n",
      "step 69200 , validation  accuracy 0.769697\n",
      "step 69200 , validation loss : 0.58853\n",
      "step 69200 , validation  accuracy 0.836364\n",
      "step 69200 , validation loss : 0.484188\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690074920654\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680788040161\n",
      "step 69300 , validation  accuracy 0.793939\n",
      "step 69300 , validation loss : 0.598579\n",
      "step 69300 , validation  accuracy 0.827273\n",
      "step 69300 , validation loss : 0.593683\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678599119186\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674381971359\n",
      "step 69400 , validation  accuracy 0.645455\n",
      "step 69400 , validation loss : 0.777264\n",
      "step 69400 , validation  accuracy 0.89697\n",
      "step 69400 , validation loss : 0.267315\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688336849213\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689274072647\n",
      "step 69500 , validation  accuracy 0.763636\n",
      "step 69500 , validation loss : 0.752723\n",
      "step 69500 , validation  accuracy 0.842424\n",
      "step 69500 , validation loss : 0.481025\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684525966644\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687536001205\n",
      "step 69600 , validation  accuracy 0.715152\n",
      "step 69600 , validation loss : 0.677036\n",
      "step 69600 , validation  accuracy 0.851515\n",
      "step 69600 , validation loss : 0.399004\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682965993881\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68096113205\n",
      "step 69700 , validation  accuracy 0.715152\n",
      "step 69700 , validation loss : 0.670088\n",
      "step 69700 , validation  accuracy 0.875758\n",
      "step 69700 , validation loss : 0.372161\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692549228668\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692625999451\n",
      "step 69800 , validation  accuracy 0.751515\n",
      "step 69800 , validation loss : 0.67396\n",
      "step 69800 , validation  accuracy 0.824243\n",
      "step 69800 , validation loss : 0.455719\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690483093262\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684023857117\n",
      "step 69900 , validation  accuracy 0.772727\n",
      "step 69900 , validation loss : 0.730045\n",
      "step 69900 , validation  accuracy 0.812121\n",
      "step 69900 , validation loss : 0.562534\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678516864777\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695796966553\n",
      "step 70000 , validation  accuracy 0.757576\n",
      "step 70000 , validation loss : 0.601155\n",
      "step 70000 , validation  accuracy 0.821212\n",
      "step 70000 , validation loss : 0.488941\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689136981964\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679592132568\n",
      "step 70100 , validation  accuracy 0.721212\n",
      "step 70100 , validation loss : 0.737787\n",
      "step 70100 , validation  accuracy 0.875758\n",
      "step 70100 , validation loss : 0.409772\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687890052795\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694388866425\n",
      "step 70200 , validation  accuracy 0.760606\n",
      "step 70200 , validation loss : 0.667065\n",
      "step 70200 , validation  accuracy 0.848485\n",
      "step 70200 , validation loss : 0.387277\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681066036224\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691622972488\n",
      "step 70300 , validation  accuracy 0.760606\n",
      "step 70300 , validation loss : 0.630903\n",
      "step 70300 , validation  accuracy 0.836364\n",
      "step 70300 , validation loss : 0.447023\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702700138092\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685485124588\n",
      "step 70400 , validation  accuracy 0.778788\n",
      "step 70400 , validation loss : 0.594488\n",
      "step 70400 , validation  accuracy 0.839394\n",
      "step 70400 , validation loss : 0.447193\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697946071625\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681452035904\n",
      "step 70500 , validation  accuracy 0.757576\n",
      "step 70500 , validation loss : 0.694526\n",
      "step 70500 , validation  accuracy 0.863636\n",
      "step 70500 , validation loss : 0.463132\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699279785156\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685575008392\n",
      "step 70600 , validation  accuracy 0.775758\n",
      "step 70600 , validation loss : 0.624011\n",
      "step 70600 , validation  accuracy 0.845455\n",
      "step 70600 , validation loss : 0.459937\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684980154037\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676717996597\n",
      "step 70700 , validation  accuracy 0.763637\n",
      "step 70700 , validation loss : 0.711557\n",
      "step 70700 , validation  accuracy 0.866667\n",
      "step 70700 , validation loss : 0.379094\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700433015823\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686201095581\n",
      "step 70800 , validation  accuracy 0.745455\n",
      "step 70800 , validation loss : 0.674421\n",
      "step 70800 , validation  accuracy 0.845455\n",
      "step 70800 , validation loss : 0.411734\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689205884933\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696773052216\n",
      "step 70900 , validation  accuracy 0.748485\n",
      "step 70900 , validation loss : 0.732953\n",
      "step 70900 , validation  accuracy 0.857576\n",
      "step 70900 , validation loss : 0.430558\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690582036972\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690341949463\n",
      "step 71000 , validation  accuracy 0.790909\n",
      "step 71000 , validation loss : 0.510852\n",
      "step 71000 , validation  accuracy 0.818182\n",
      "step 71000 , validation loss : 0.488286\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687227964401\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68137383461\n",
      "step 71100 , validation  accuracy 0.748485\n",
      "step 71100 , validation loss : 0.767846\n",
      "step 71100 , validation  accuracy 0.833333\n",
      "step 71100 , validation loss : 0.453538\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684370040894\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684503078461\n",
      "step 71200 , validation  accuracy 0.775758\n",
      "step 71200 , validation loss : 0.730682\n",
      "step 71200 , validation  accuracy 0.851515\n",
      "step 71200 , validation loss : 0.504231\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700055122375\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694612979889\n",
      "step 71300 , validation  accuracy 0.772727\n",
      "step 71300 , validation loss : 0.670164\n",
      "step 71300 , validation  accuracy 0.833333\n",
      "step 71300 , validation loss : 0.446688\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.668814897537\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687262058258\n",
      "step 71400 , validation  accuracy 0.751515\n",
      "step 71400 , validation loss : 0.611231\n",
      "step 71400 , validation  accuracy 0.872727\n",
      "step 71400 , validation loss : 0.354788\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69550204277\n",
      "(11, 30, 300, 300, 3)\n",
      "0.720859050751\n",
      "step 71500 , validation  accuracy 0.754546\n",
      "step 71500 , validation loss : 0.749227\n",
      "step 71500 , validation  accuracy 0.854546\n",
      "step 71500 , validation loss : 0.434395\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682414054871\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693084001541\n",
      "step 71600 , validation  accuracy 0.742424\n",
      "step 71600 , validation loss : 0.699481\n",
      "step 71600 , validation  accuracy 0.866667\n",
      "step 71600 , validation loss : 0.4033\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682168960571\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677242994308\n",
      "step 71700 , validation  accuracy 0.742424\n",
      "step 71700 , validation loss : 0.768493\n",
      "step 71700 , validation  accuracy 0.851515\n",
      "step 71700 , validation loss : 0.423035\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683927059174\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697170972824\n",
      "step 71800 , validation  accuracy 0.742424\n",
      "step 71800 , validation loss : 0.715072\n",
      "step 71800 , validation  accuracy 0.863636\n",
      "step 71800 , validation loss : 0.410422\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695458173752\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678901910782\n",
      "step 71900 , validation  accuracy 0.706061\n",
      "step 71900 , validation loss : 0.762896\n",
      "step 71900 , validation  accuracy 0.869697\n",
      "step 71900 , validation loss : 0.40145\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677994012833\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684325218201\n",
      "step 72000 , validation  accuracy 0.772727\n",
      "step 72000 , validation loss : 0.65598\n",
      "step 72000 , validation  accuracy 0.833333\n",
      "step 72000 , validation loss : 0.540447\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689908027649\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678231954575\n",
      "step 72100 , validation  accuracy 0.715152\n",
      "step 72100 , validation loss : 0.890392\n",
      "step 72100 , validation  accuracy 0.875758\n",
      "step 72100 , validation loss : 0.359698\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681216001511\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688806056976\n",
      "step 72200 , validation  accuracy 0.769697\n",
      "step 72200 , validation loss : 0.608405\n",
      "step 72200 , validation  accuracy 0.812121\n",
      "step 72200 , validation loss : 0.556576\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674979925156\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684720993042\n",
      "step 72300 , validation  accuracy 0.754545\n",
      "step 72300 , validation loss : 0.74579\n",
      "step 72300 , validation  accuracy 0.863636\n",
      "step 72300 , validation loss : 0.457583\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692373991013\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685159921646\n",
      "step 72400 , validation  accuracy 0.757576\n",
      "step 72400 , validation loss : 0.709946\n",
      "step 72400 , validation  accuracy 0.836364\n",
      "step 72400 , validation loss : 0.482888\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677453994751\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69086098671\n",
      "step 72500 , validation  accuracy 0.760606\n",
      "step 72500 , validation loss : 0.720589\n",
      "step 72500 , validation  accuracy 0.839394\n",
      "step 72500 , validation loss : 0.526718\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691956996918\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701250076294\n",
      "step 72600 , validation  accuracy 0.763636\n",
      "step 72600 , validation loss : 0.80546\n",
      "step 72600 , validation  accuracy 0.851515\n",
      "step 72600 , validation loss : 0.522604\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673596143723\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679162025452\n",
      "step 72700 , validation  accuracy 0.775758\n",
      "step 72700 , validation loss : 0.46936\n",
      "step 72700 , validation  accuracy 0.812121\n",
      "step 72700 , validation loss : 0.477261\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685963869095\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701151132584\n",
      "step 72800 , validation  accuracy 0.751515\n",
      "step 72800 , validation loss : 0.686894\n",
      "step 72800 , validation  accuracy 0.848485\n",
      "step 72800 , validation loss : 0.469919\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695355176926\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689540147781\n",
      "step 72900 , validation  accuracy 0.748485\n",
      "step 72900 , validation loss : 0.61865\n",
      "step 72900 , validation  accuracy 0.842424\n",
      "step 72900 , validation loss : 0.468439\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693300008774\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694690942764\n",
      "step 73000 , validation  accuracy 0.751515\n",
      "step 73000 , validation loss : 0.613742\n",
      "step 73000 , validation  accuracy 0.851515\n",
      "step 73000 , validation loss : 0.416416\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683125972748\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684302091599\n",
      "step 73100 , validation  accuracy 0.772727\n",
      "step 73100 , validation loss : 0.733958\n",
      "step 73100 , validation  accuracy 0.827273\n",
      "step 73100 , validation loss : 0.484087\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694684028625\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693310022354\n",
      "step 73200 , validation  accuracy 0.736364\n",
      "step 73200 , validation loss : 0.814796\n",
      "step 73200 , validation  accuracy 0.860606\n",
      "step 73200 , validation loss : 0.435061\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687333106995\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677536964417\n",
      "step 73300 , validation  accuracy 0.781818\n",
      "step 73300 , validation loss : 0.631385\n",
      "step 73300 , validation  accuracy 0.824242\n",
      "step 73300 , validation loss : 0.503962\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686733007431\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692329883575\n",
      "step 73400 , validation  accuracy 0.769697\n",
      "step 73400 , validation loss : 0.704954\n",
      "step 73400 , validation  accuracy 0.827273\n",
      "step 73400 , validation loss : 0.521146\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70273900032\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68905210495\n",
      "step 73500 , validation  accuracy 0.806061\n",
      "step 73500 , validation loss : 0.625831\n",
      "step 73500 , validation  accuracy 0.845455\n",
      "step 73500 , validation loss : 0.496882\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676078081131\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678724050522\n",
      "step 73600 , validation  accuracy 0.754546\n",
      "step 73600 , validation loss : 0.640686\n",
      "step 73600 , validation  accuracy 0.833333\n",
      "step 73600 , validation loss : 0.49536\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696989059448\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688765048981\n",
      "step 73700 , validation  accuracy 0.745455\n",
      "step 73700 , validation loss : 0.629196\n",
      "step 73700 , validation  accuracy 0.863636\n",
      "step 73700 , validation loss : 0.411295\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681383132935\n",
      "(11, 30, 300, 300, 3)\n",
      "0.725740909576\n",
      "step 73800 , validation  accuracy 0.751515\n",
      "step 73800 , validation loss : 0.647656\n",
      "step 73800 , validation  accuracy 0.830303\n",
      "step 73800 , validation loss : 0.462362\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684661865234\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677098035812\n",
      "step 73900 , validation  accuracy 0.787879\n",
      "step 73900 , validation loss : 0.56869\n",
      "step 73900 , validation  accuracy 0.79394\n",
      "step 73900 , validation loss : 0.565396\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706517934799\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677653074265\n",
      "step 74000 , validation  accuracy 0.730303\n",
      "step 74000 , validation loss : 0.853843\n",
      "step 74000 , validation  accuracy 0.854546\n",
      "step 74000 , validation loss : 0.510869\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686583995819\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689029932022\n",
      "step 74100 , validation  accuracy 0.769697\n",
      "step 74100 , validation loss : 0.755092\n",
      "step 74100 , validation  accuracy 0.842424\n",
      "step 74100 , validation loss : 0.492493\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685148954391\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690810918808\n",
      "step 74200 , validation  accuracy 0.778788\n",
      "step 74200 , validation loss : 0.656557\n",
      "step 74200 , validation  accuracy 0.836364\n",
      "step 74200 , validation loss : 0.543301\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695187807083\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690973043442\n",
      "step 74300 , validation  accuracy 0.766667\n",
      "step 74300 , validation loss : 0.744984\n",
      "step 74300 , validation  accuracy 0.830303\n",
      "step 74300 , validation loss : 0.558001\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685841083527\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685621976852\n",
      "step 74400 , validation  accuracy 0.781818\n",
      "step 74400 , validation loss : 0.649925\n",
      "step 74400 , validation  accuracy 0.815152\n",
      "step 74400 , validation loss : 0.689408\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676999092102\n",
      "(11, 30, 300, 300, 3)\n",
      "0.707090854645\n",
      "step 74500 , validation  accuracy 0.784849\n",
      "step 74500 , validation loss : 0.651709\n",
      "step 74500 , validation  accuracy 0.824242\n",
      "step 74500 , validation loss : 0.515674\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689888000488\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690397977829\n",
      "step 74600 , validation  accuracy 0.772727\n",
      "step 74600 , validation loss : 0.644064\n",
      "step 74600 , validation  accuracy 0.842424\n",
      "step 74600 , validation loss : 0.452377\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678292036057\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677705049515\n",
      "step 74700 , validation  accuracy 0.763636\n",
      "step 74700 , validation loss : 0.746003\n",
      "step 74700 , validation  accuracy 0.830303\n",
      "step 74700 , validation loss : 0.554629\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702006816864\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690468072891\n",
      "step 74800 , validation  accuracy 0.769697\n",
      "step 74800 , validation loss : 0.680688\n",
      "step 74800 , validation  accuracy 0.839394\n",
      "step 74800 , validation loss : 0.481849\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683937072754\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681103944778\n",
      "step 74900 , validation  accuracy 0.727273\n",
      "step 74900 , validation loss : 0.819008\n",
      "step 74900 , validation  accuracy 0.851515\n",
      "step 74900 , validation loss : 0.417593\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698365926743\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692690134048\n",
      "step 75000 , validation  accuracy 0.742424\n",
      "step 75000 , validation loss : 0.876269\n",
      "step 75000 , validation  accuracy 0.845455\n",
      "step 75000 , validation loss : 0.516868\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674842119217\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67956495285\n",
      "step 75100 , validation  accuracy 0.739394\n",
      "step 75100 , validation loss : 0.635848\n",
      "step 75100 , validation  accuracy 0.845455\n",
      "step 75100 , validation loss : 0.416799\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699340105057\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690694093704\n",
      "step 75200 , validation  accuracy 0.784849\n",
      "step 75200 , validation loss : 0.598899\n",
      "step 75200 , validation  accuracy 0.827273\n",
      "step 75200 , validation loss : 0.571225\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68411898613\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688256978989\n",
      "step 75300 , validation  accuracy 0.775758\n",
      "step 75300 , validation loss : 0.607152\n",
      "step 75300 , validation  accuracy 0.818182\n",
      "step 75300 , validation loss : 0.514851\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692229986191\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687318086624\n",
      "step 75400 , validation  accuracy 0.775758\n",
      "step 75400 , validation loss : 0.573918\n",
      "step 75400 , validation  accuracy 0.806061\n",
      "step 75400 , validation loss : 0.511613\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686527967453\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68644618988\n",
      "step 75500 , validation  accuracy 0.709091\n",
      "step 75500 , validation loss : 0.780763\n",
      "step 75500 , validation  accuracy 0.866667\n",
      "step 75500 , validation loss : 0.373259\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681108951569\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695124864578\n",
      "step 75600 , validation  accuracy 0.766667\n",
      "step 75600 , validation loss : 0.656935\n",
      "step 75600 , validation  accuracy 0.821212\n",
      "step 75600 , validation loss : 0.498262\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692471027374\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688051939011\n",
      "step 75700 , validation  accuracy 0.760606\n",
      "step 75700 , validation loss : 0.716891\n",
      "step 75700 , validation  accuracy 0.839394\n",
      "step 75700 , validation loss : 0.458477\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674038171768\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688529014587\n",
      "step 75800 , validation  accuracy 0.766667\n",
      "step 75800 , validation loss : 0.719079\n",
      "step 75800 , validation  accuracy 0.848485\n",
      "step 75800 , validation loss : 0.482447\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690100908279\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686593055725\n",
      "step 75900 , validation  accuracy 0.748485\n",
      "step 75900 , validation loss : 0.575391\n",
      "step 75900 , validation  accuracy 0.866667\n",
      "step 75900 , validation loss : 0.412619\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.672373056412\n",
      "(11, 30, 300, 300, 3)\n",
      "0.714359045029\n",
      "step 76000 , validation  accuracy 0.693939\n",
      "step 76000 , validation loss : 0.829956\n",
      "step 76000 , validation  accuracy 0.884849\n",
      "step 76000 , validation loss : 0.391355\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677937030792\n",
      "(11, 30, 300, 300, 3)\n",
      "0.672710895538\n",
      "step 76100 , validation  accuracy 0.742424\n",
      "step 76100 , validation loss : 0.708032\n",
      "step 76100 , validation  accuracy 0.848485\n",
      "step 76100 , validation loss : 0.483354\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68249297142\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698220014572\n",
      "step 76200 , validation  accuracy 0.821212\n",
      "step 76200 , validation loss : 0.526458\n",
      "step 76200 , validation  accuracy 0.736364\n",
      "step 76200 , validation loss : 0.794694\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698093891144\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681534051895\n",
      "step 76300 , validation  accuracy 0.8\n",
      "step 76300 , validation loss : 0.569918\n",
      "step 76300 , validation  accuracy 0.79394\n",
      "step 76300 , validation loss : 0.583211\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.672650098801\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684659957886\n",
      "step 76400 , validation  accuracy 0.781818\n",
      "step 76400 , validation loss : 0.541022\n",
      "step 76400 , validation  accuracy 0.818182\n",
      "step 76400 , validation loss : 0.524227\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679815769196\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692441940308\n",
      "step 76500 , validation  accuracy 0.748485\n",
      "step 76500 , validation loss : 0.603463\n",
      "step 76500 , validation  accuracy 0.839394\n",
      "step 76500 , validation loss : 0.452992\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688364982605\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68659901619\n",
      "step 76600 , validation  accuracy 0.772727\n",
      "step 76600 , validation loss : 0.542458\n",
      "step 76600 , validation  accuracy 0.833333\n",
      "step 76600 , validation loss : 0.522347\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678218126297\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692016839981\n",
      "step 76700 , validation  accuracy 0.742424\n",
      "step 76700 , validation loss : 0.67334\n",
      "step 76700 , validation  accuracy 0.875758\n",
      "step 76700 , validation loss : 0.418114\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694339990616\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68497800827\n",
      "step 76800 , validation  accuracy 0.736364\n",
      "step 76800 , validation loss : 0.630183\n",
      "step 76800 , validation  accuracy 0.866667\n",
      "step 76800 , validation loss : 0.42178\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699029922485\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695590019226\n",
      "step 76900 , validation  accuracy 0.754546\n",
      "step 76900 , validation loss : 0.705914\n",
      "step 76900 , validation  accuracy 0.842424\n",
      "step 76900 , validation loss : 0.529049\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702233076096\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695987939835\n",
      "step 77000 , validation  accuracy 0.748485\n",
      "step 77000 , validation loss : 0.745834\n",
      "step 77000 , validation  accuracy 0.854546\n",
      "step 77000 , validation loss : 0.473843\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695195198059\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688092947006\n",
      "step 77100 , validation  accuracy 0.748485\n",
      "step 77100 , validation loss : 0.657103\n",
      "step 77100 , validation  accuracy 0.848485\n",
      "step 77100 , validation loss : 0.46242\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702417850494\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696967840195\n",
      "step 77200 , validation  accuracy 0.790909\n",
      "step 77200 , validation loss : 0.553674\n",
      "step 77200 , validation  accuracy 0.821212\n",
      "step 77200 , validation loss : 0.570448\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678383827209\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688701152802\n",
      "step 77300 , validation  accuracy 0.763636\n",
      "step 77300 , validation loss : 0.70068\n",
      "step 77300 , validation  accuracy 0.836364\n",
      "step 77300 , validation loss : 0.517841\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677119970322\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695462942123\n",
      "step 77400 , validation  accuracy 0.763636\n",
      "step 77400 , validation loss : 0.59529\n",
      "step 77400 , validation  accuracy 0.860606\n",
      "step 77400 , validation loss : 0.398903\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685752153397\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680514097214\n",
      "step 77500 , validation  accuracy 0.748485\n",
      "step 77500 , validation loss : 0.782467\n",
      "step 77500 , validation  accuracy 0.857576\n",
      "step 77500 , validation loss : 0.399449\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680851221085\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693289995193\n",
      "step 77600 , validation  accuracy 0.766667\n",
      "step 77600 , validation loss : 0.708592\n",
      "step 77600 , validation  accuracy 0.839394\n",
      "step 77600 , validation loss : 0.447103\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688219070435\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682875156403\n",
      "step 77700 , validation  accuracy 0.763636\n",
      "step 77700 , validation loss : 0.731801\n",
      "step 77700 , validation  accuracy 0.830303\n",
      "step 77700 , validation loss : 0.492781\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685831069946\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687198877335\n",
      "step 77800 , validation  accuracy 0.733333\n",
      "step 77800 , validation loss : 0.691549\n",
      "step 77800 , validation  accuracy 0.866667\n",
      "step 77800 , validation loss : 0.403069\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683389902115\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685034036636\n",
      "step 77900 , validation  accuracy 0.784849\n",
      "step 77900 , validation loss : 0.581192\n",
      "step 77900 , validation  accuracy 0.821212\n",
      "step 77900 , validation loss : 0.624232\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686626195908\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680779933929\n",
      "step 78000 , validation  accuracy 0.718182\n",
      "step 78000 , validation loss : 0.647579\n",
      "step 78000 , validation  accuracy 0.878788\n",
      "step 78000 , validation loss : 0.371461\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701464891434\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692150115967\n",
      "step 78100 , validation  accuracy 0.790909\n",
      "step 78100 , validation loss : 0.660433\n",
      "step 78100 , validation  accuracy 0.830303\n",
      "step 78100 , validation loss : 0.543345\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688087940216\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693988800049\n",
      "step 78200 , validation  accuracy 0.727273\n",
      "step 78200 , validation loss : 0.717366\n",
      "step 78200 , validation  accuracy 0.848485\n",
      "step 78200 , validation loss : 0.423346\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682252883911\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6719789505\n",
      "step 78300 , validation  accuracy 0.754546\n",
      "step 78300 , validation loss : 0.646644\n",
      "step 78300 , validation  accuracy 0.860606\n",
      "step 78300 , validation loss : 0.407158\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69578909874\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69436788559\n",
      "step 78400 , validation  accuracy 0.781818\n",
      "step 78400 , validation loss : 0.569459\n",
      "step 78400 , validation  accuracy 0.827273\n",
      "step 78400 , validation loss : 0.452689\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678596019745\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688930988312\n",
      "step 78500 , validation  accuracy 0.778788\n",
      "step 78500 , validation loss : 0.557284\n",
      "step 78500 , validation  accuracy 0.839394\n",
      "step 78500 , validation loss : 0.460862\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690127134323\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686187028885\n",
      "step 78600 , validation  accuracy 0.781818\n",
      "step 78600 , validation loss : 0.582951\n",
      "step 78600 , validation  accuracy 0.827273\n",
      "step 78600 , validation loss : 0.542704\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674869060516\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681801795959\n",
      "step 78700 , validation  accuracy 0.790909\n",
      "step 78700 , validation loss : 0.543496\n",
      "step 78700 , validation  accuracy 0.818182\n",
      "step 78700 , validation loss : 0.544822\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684321880341\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687616825104\n",
      "step 78800 , validation  accuracy 0.751515\n",
      "step 78800 , validation loss : 0.802636\n",
      "step 78800 , validation  accuracy 0.857576\n",
      "step 78800 , validation loss : 0.462855\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696849107742\n",
      "(11, 30, 300, 300, 3)\n",
      "0.73074889183\n",
      "step 78900 , validation  accuracy 0.778788\n",
      "step 78900 , validation loss : 0.651511\n",
      "step 78900 , validation  accuracy 0.833333\n",
      "step 78900 , validation loss : 0.477563\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689200162888\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686670064926\n",
      "step 79000 , validation  accuracy 0.772727\n",
      "step 79000 , validation loss : 0.674398\n",
      "step 79000 , validation  accuracy 0.830303\n",
      "step 79000 , validation loss : 0.519042\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677437067032\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693825006485\n",
      "step 79100 , validation  accuracy 0.763636\n",
      "step 79100 , validation loss : 0.684747\n",
      "step 79100 , validation  accuracy 0.836364\n",
      "step 79100 , validation loss : 0.465514\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677904844284\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689069986343\n",
      "step 79200 , validation  accuracy 0.775758\n",
      "step 79200 , validation loss : 0.575275\n",
      "step 79200 , validation  accuracy 0.824242\n",
      "step 79200 , validation loss : 0.485711\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685436010361\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700283050537\n",
      "step 79300 , validation  accuracy 0.763636\n",
      "step 79300 , validation loss : 0.643537\n",
      "step 79300 , validation  accuracy 0.836364\n",
      "step 79300 , validation loss : 0.498305\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67454791069\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680292129517\n",
      "step 79400 , validation  accuracy 0.809091\n",
      "step 79400 , validation loss : 0.529984\n",
      "step 79400 , validation  accuracy 0.790909\n",
      "step 79400 , validation loss : 0.674634\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685371160507\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684015989304\n",
      "step 79500 , validation  accuracy 0.769697\n",
      "step 79500 , validation loss : 0.587536\n",
      "step 79500 , validation  accuracy 0.824243\n",
      "step 79500 , validation loss : 0.512343\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675707817078\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688792943954\n",
      "step 79600 , validation  accuracy 0.830303\n",
      "step 79600 , validation loss : 0.569994\n",
      "step 79600 , validation  accuracy 0.784848\n",
      "step 79600 , validation loss : 0.757218\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685729980469\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690720081329\n",
      "step 79700 , validation  accuracy 0.730303\n",
      "step 79700 , validation loss : 0.678847\n",
      "step 79700 , validation  accuracy 0.851515\n",
      "step 79700 , validation loss : 0.441396\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678784132004\n",
      "(11, 30, 300, 300, 3)\n",
      "0.671226024628\n",
      "step 79800 , validation  accuracy 0.751515\n",
      "step 79800 , validation loss : 0.876493\n",
      "step 79800 , validation  accuracy 0.842424\n",
      "step 79800 , validation loss : 0.541946\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697201967239\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675427913666\n",
      "step 79900 , validation  accuracy 0.812121\n",
      "step 79900 , validation loss : 0.496243\n",
      "step 79900 , validation  accuracy 0.806061\n",
      "step 79900 , validation loss : 0.572974\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676952123642\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694176197052\n",
      "step 80000 , validation  accuracy 0.778788\n",
      "step 80000 , validation loss : 0.695957\n",
      "step 80000 , validation  accuracy 0.833333\n",
      "step 80000 , validation loss : 0.561835\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689668178558\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698203086853\n",
      "step 80100 , validation  accuracy 0.70303\n",
      "step 80100 , validation loss : 0.75479\n",
      "step 80100 , validation  accuracy 0.875758\n",
      "step 80100 , validation loss : 0.305798\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685398817062\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690399885178\n",
      "step 80200 , validation  accuracy 0.757576\n",
      "step 80200 , validation loss : 0.681261\n",
      "step 80200 , validation  accuracy 0.857576\n",
      "step 80200 , validation loss : 0.403384\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675316810608\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690570116043\n",
      "step 80300 , validation  accuracy 0.769697\n",
      "step 80300 , validation loss : 0.573994\n",
      "step 80300 , validation  accuracy 0.827273\n",
      "step 80300 , validation loss : 0.483696\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689291000366\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694562196732\n",
      "step 80400 , validation  accuracy 0.724242\n",
      "step 80400 , validation loss : 0.693443\n",
      "step 80400 , validation  accuracy 0.854546\n",
      "step 80400 , validation loss : 0.404825\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674011945724\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691894054413\n",
      "step 80500 , validation  accuracy 0.781818\n",
      "step 80500 , validation loss : 0.641915\n",
      "step 80500 , validation  accuracy 0.836364\n",
      "step 80500 , validation loss : 0.48833\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.702370882034\n",
      "(11, 30, 300, 300, 3)\n",
      "0.713099002838\n",
      "step 80600 , validation  accuracy 0.757576\n",
      "step 80600 , validation loss : 0.634089\n",
      "step 80600 , validation  accuracy 0.851515\n",
      "step 80600 , validation loss : 0.411843\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687370061874\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680086135864\n",
      "step 80700 , validation  accuracy 0.772727\n",
      "step 80700 , validation loss : 0.708625\n",
      "step 80700 , validation  accuracy 0.812121\n",
      "step 80700 , validation loss : 0.49288\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698230028152\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674426078796\n",
      "step 80800 , validation  accuracy 0.760606\n",
      "step 80800 , validation loss : 0.57883\n",
      "step 80800 , validation  accuracy 0.824242\n",
      "step 80800 , validation loss : 0.467279\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67284989357\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687479019165\n",
      "step 80900 , validation  accuracy 0.769697\n",
      "step 80900 , validation loss : 0.651581\n",
      "step 80900 , validation  accuracy 0.824243\n",
      "step 80900 , validation loss : 0.45127\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688966989517\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693511009216\n",
      "step 81000 , validation  accuracy 0.727273\n",
      "step 81000 , validation loss : 0.785284\n",
      "step 81000 , validation  accuracy 0.833333\n",
      "step 81000 , validation loss : 0.454362\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686527013779\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681109905243\n",
      "step 81100 , validation  accuracy 0.784849\n",
      "step 81100 , validation loss : 0.533676\n",
      "step 81100 , validation  accuracy 0.833333\n",
      "step 81100 , validation loss : 0.484208\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67518901825\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685772180557\n",
      "step 81200 , validation  accuracy 0.775758\n",
      "step 81200 , validation loss : 0.597224\n",
      "step 81200 , validation  accuracy 0.830303\n",
      "step 81200 , validation loss : 0.457632\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701143026352\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695657014847\n",
      "step 81300 , validation  accuracy 0.79697\n",
      "step 81300 , validation loss : 0.656585\n",
      "step 81300 , validation  accuracy 0.851515\n",
      "step 81300 , validation loss : 0.473464\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69047999382\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673256874084\n",
      "step 81400 , validation  accuracy 0.79697\n",
      "step 81400 , validation loss : 0.622946\n",
      "step 81400 , validation  accuracy 0.824242\n",
      "step 81400 , validation loss : 0.602897\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69940495491\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690135002136\n",
      "step 81500 , validation  accuracy 0.815152\n",
      "step 81500 , validation loss : 0.576527\n",
      "step 81500 , validation  accuracy 0.809091\n",
      "step 81500 , validation loss : 0.685762\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691107988358\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685647964478\n",
      "step 81600 , validation  accuracy 0.79394\n",
      "step 81600 , validation loss : 0.602573\n",
      "step 81600 , validation  accuracy 0.830303\n",
      "step 81600 , validation loss : 0.525064\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700493097305\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677011966705\n",
      "step 81700 , validation  accuracy 0.727273\n",
      "step 81700 , validation loss : 0.707762\n",
      "step 81700 , validation  accuracy 0.866667\n",
      "step 81700 , validation loss : 0.37599\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684787034988\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696068048477\n",
      "step 81800 , validation  accuracy 0.766667\n",
      "step 81800 , validation loss : 0.595042\n",
      "step 81800 , validation  accuracy 0.830303\n",
      "step 81800 , validation loss : 0.477146\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.726051092148\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695291996002\n",
      "step 81900 , validation  accuracy 0.754546\n",
      "step 81900 , validation loss : 0.624654\n",
      "step 81900 , validation  accuracy 0.845455\n",
      "step 81900 , validation loss : 0.427824\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678687095642\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686398983002\n",
      "step 82000 , validation  accuracy 0.772727\n",
      "step 82000 , validation loss : 0.658313\n",
      "step 82000 , validation  accuracy 0.824242\n",
      "step 82000 , validation loss : 0.579609\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691064119339\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691488027573\n",
      "step 82100 , validation  accuracy 0.742424\n",
      "step 82100 , validation loss : 0.722398\n",
      "step 82100 , validation  accuracy 0.836364\n",
      "step 82100 , validation loss : 0.498412\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673971891403\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682012081146\n",
      "step 82200 , validation  accuracy 0.806061\n",
      "step 82200 , validation loss : 0.517505\n",
      "step 82200 , validation  accuracy 0.806061\n",
      "step 82200 , validation loss : 0.52074\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686527013779\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690150022507\n",
      "step 82300 , validation  accuracy 0.69697\n",
      "step 82300 , validation loss : 0.74675\n",
      "step 82300 , validation  accuracy 0.869697\n",
      "step 82300 , validation loss : 0.34651\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698358058929\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688906908035\n",
      "step 82400 , validation  accuracy 0.730303\n",
      "step 82400 , validation loss : 0.731622\n",
      "step 82400 , validation  accuracy 0.860606\n",
      "step 82400 , validation loss : 0.414324\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678713083267\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684340000153\n",
      "step 82500 , validation  accuracy 0.718182\n",
      "step 82500 , validation loss : 0.772368\n",
      "step 82500 , validation  accuracy 0.875758\n",
      "step 82500 , validation loss : 0.326512\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.704526901245\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690155982971\n",
      "step 82600 , validation  accuracy 0.79697\n",
      "step 82600 , validation loss : 0.543403\n",
      "step 82600 , validation  accuracy 0.815152\n",
      "step 82600 , validation loss : 0.520211\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679474115372\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688861131668\n",
      "step 82700 , validation  accuracy 0.730303\n",
      "step 82700 , validation loss : 0.71319\n",
      "step 82700 , validation  accuracy 0.860606\n",
      "step 82700 , validation loss : 0.378951\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684791088104\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691905021667\n",
      "step 82800 , validation  accuracy 0.742424\n",
      "step 82800 , validation loss : 0.753913\n",
      "step 82800 , validation  accuracy 0.857576\n",
      "step 82800 , validation loss : 0.394532\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687668085098\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685496091843\n",
      "step 82900 , validation  accuracy 0.766667\n",
      "step 82900 , validation loss : 0.649755\n",
      "step 82900 , validation  accuracy 0.851515\n",
      "step 82900 , validation loss : 0.432252\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706062078476\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696436882019\n",
      "step 83000 , validation  accuracy 0.784849\n",
      "step 83000 , validation loss : 0.634523\n",
      "step 83000 , validation  accuracy 0.839394\n",
      "step 83000 , validation loss : 0.519594\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676940917969\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683128118515\n",
      "step 83100 , validation  accuracy 0.769697\n",
      "step 83100 , validation loss : 0.633361\n",
      "step 83100 , validation  accuracy 0.839394\n",
      "step 83100 , validation loss : 0.472122\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677505016327\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688258886337\n",
      "step 83200 , validation  accuracy 0.745455\n",
      "step 83200 , validation loss : 0.697701\n",
      "step 83200 , validation  accuracy 0.875758\n",
      "step 83200 , validation loss : 0.382101\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698593139648\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692737102509\n",
      "step 83300 , validation  accuracy 0.775758\n",
      "step 83300 , validation loss : 0.645606\n",
      "step 83300 , validation  accuracy 0.851515\n",
      "step 83300 , validation loss : 0.452539\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679620027542\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689856052399\n",
      "step 83400 , validation  accuracy 0.751515\n",
      "step 83400 , validation loss : 0.755617\n",
      "step 83400 , validation  accuracy 0.848485\n",
      "step 83400 , validation loss : 0.440005\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698735952377\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686148881912\n",
      "step 83500 , validation  accuracy 0.754545\n",
      "step 83500 , validation loss : 0.720786\n",
      "step 83500 , validation  accuracy 0.833333\n",
      "step 83500 , validation loss : 0.432874\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68284702301\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68697309494\n",
      "step 83600 , validation  accuracy 0.818182\n",
      "step 83600 , validation loss : 0.562276\n",
      "step 83600 , validation  accuracy 0.812121\n",
      "step 83600 , validation loss : 0.578668\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694058895111\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685466051102\n",
      "step 83700 , validation  accuracy 0.760606\n",
      "step 83700 , validation loss : 0.788113\n",
      "step 83700 , validation  accuracy 0.851515\n",
      "step 83700 , validation loss : 0.460313\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676107168198\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68427491188\n",
      "step 83800 , validation  accuracy 0.751515\n",
      "step 83800 , validation loss : 0.790885\n",
      "step 83800 , validation  accuracy 0.851515\n",
      "step 83800 , validation loss : 0.469387\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.699540138245\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691583156586\n",
      "step 83900 , validation  accuracy 0.754545\n",
      "step 83900 , validation loss : 0.680673\n",
      "step 83900 , validation  accuracy 0.854546\n",
      "step 83900 , validation loss : 0.419729\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687750816345\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677599906921\n",
      "step 84000 , validation  accuracy 0.781818\n",
      "step 84000 , validation loss : 0.582104\n",
      "step 84000 , validation  accuracy 0.8\n",
      "step 84000 , validation loss : 0.570414\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683434009552\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681931018829\n",
      "step 84100 , validation  accuracy 0.784849\n",
      "step 84100 , validation loss : 0.536777\n",
      "step 84100 , validation  accuracy 0.79697\n",
      "step 84100 , validation loss : 0.550737\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677870988846\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689121961594\n",
      "step 84200 , validation  accuracy 0.766667\n",
      "step 84200 , validation loss : 0.728783\n",
      "step 84200 , validation  accuracy 0.836364\n",
      "step 84200 , validation loss : 0.473621\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681622028351\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687157154083\n",
      "step 84300 , validation  accuracy 0.772727\n",
      "step 84300 , validation loss : 0.619428\n",
      "step 84300 , validation  accuracy 0.827273\n",
      "step 84300 , validation loss : 0.451121\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693073034286\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690137863159\n",
      "step 84400 , validation  accuracy 0.769697\n",
      "step 84400 , validation loss : 0.565569\n",
      "step 84400 , validation  accuracy 0.824243\n",
      "step 84400 , validation loss : 0.459855\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683213949203\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699210882187\n",
      "step 84500 , validation  accuracy 0.784849\n",
      "step 84500 , validation loss : 0.661413\n",
      "step 84500 , validation  accuracy 0.848485\n",
      "step 84500 , validation loss : 0.469698\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70333313942\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69557595253\n",
      "step 84600 , validation  accuracy 0.757576\n",
      "step 84600 , validation loss : 0.722065\n",
      "step 84600 , validation  accuracy 0.851515\n",
      "step 84600 , validation loss : 0.532478\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689716815948\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691606998444\n",
      "step 84700 , validation  accuracy 0.742424\n",
      "step 84700 , validation loss : 0.718412\n",
      "step 84700 , validation  accuracy 0.860606\n",
      "step 84700 , validation loss : 0.375372\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69460606575\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685348033905\n",
      "step 84800 , validation  accuracy 0.775758\n",
      "step 84800 , validation loss : 0.607798\n",
      "step 84800 , validation  accuracy 0.851515\n",
      "step 84800 , validation loss : 0.46008\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677338123322\n",
      "(11, 30, 300, 300, 3)\n",
      "0.705259799957\n",
      "step 84900 , validation  accuracy 0.745455\n",
      "step 84900 , validation loss : 0.673772\n",
      "step 84900 , validation  accuracy 0.848485\n",
      "step 84900 , validation loss : 0.432487\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70571398735\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691817045212\n",
      "step 85000 , validation  accuracy 0.778788\n",
      "step 85000 , validation loss : 0.688864\n",
      "step 85000 , validation  accuracy 0.842424\n",
      "step 85000 , validation loss : 0.519145\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685519933701\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69776391983\n",
      "step 85100 , validation  accuracy 0.781818\n",
      "step 85100 , validation loss : 0.591074\n",
      "step 85100 , validation  accuracy 0.824242\n",
      "step 85100 , validation loss : 0.513783\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676119089127\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696162939072\n",
      "step 85200 , validation  accuracy 0.763636\n",
      "step 85200 , validation loss : 0.635898\n",
      "step 85200 , validation  accuracy 0.842424\n",
      "step 85200 , validation loss : 0.514664\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678297996521\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684614896774\n",
      "step 85300 , validation  accuracy 0.709091\n",
      "step 85300 , validation loss : 0.89169\n",
      "step 85300 , validation  accuracy 0.878788\n",
      "step 85300 , validation loss : 0.421262\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678629159927\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674335956573\n",
      "step 85400 , validation  accuracy 0.784849\n",
      "step 85400 , validation loss : 0.702064\n",
      "step 85400 , validation  accuracy 0.845455\n",
      "step 85400 , validation loss : 0.47274\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688366174698\n",
      "(11, 30, 300, 300, 3)\n",
      "0.707927942276\n",
      "step 85500 , validation  accuracy 0.781818\n",
      "step 85500 , validation loss : 0.641833\n",
      "step 85500 , validation  accuracy 0.839394\n",
      "step 85500 , validation loss : 0.492584\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677112102509\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677863121033\n",
      "step 85600 , validation  accuracy 0.736364\n",
      "step 85600 , validation loss : 0.801484\n",
      "step 85600 , validation  accuracy 0.869697\n",
      "step 85600 , validation loss : 0.39928\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686882019043\n",
      "(11, 30, 300, 300, 3)\n",
      "0.702144861221\n",
      "step 85700 , validation  accuracy 0.757576\n",
      "step 85700 , validation loss : 0.640253\n",
      "step 85700 , validation  accuracy 0.848485\n",
      "step 85700 , validation loss : 0.450093\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687763929367\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690940856934\n",
      "step 85800 , validation  accuracy 0.733333\n",
      "step 85800 , validation loss : 0.659817\n",
      "step 85800 , validation  accuracy 0.863636\n",
      "step 85800 , validation loss : 0.411444\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693511962891\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690710783005\n",
      "step 85900 , validation  accuracy 0.784849\n",
      "step 85900 , validation loss : 0.57034\n",
      "step 85900 , validation  accuracy 0.848485\n",
      "step 85900 , validation loss : 0.466897\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677667140961\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688045978546\n",
      "step 86000 , validation  accuracy 0.757576\n",
      "step 86000 , validation loss : 0.62674\n",
      "step 86000 , validation  accuracy 0.854546\n",
      "step 86000 , validation loss : 0.405561\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.722772121429\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691155910492\n",
      "step 86100 , validation  accuracy 0.778788\n",
      "step 86100 , validation loss : 0.702241\n",
      "step 86100 , validation  accuracy 0.848485\n",
      "step 86100 , validation loss : 0.437681\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697340011597\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673520088196\n",
      "step 86200 , validation  accuracy 0.642424\n",
      "step 86200 , validation loss : 1.11247\n",
      "step 86200 , validation  accuracy 0.89697\n",
      "step 86200 , validation loss : 0.278482\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688500881195\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689900159836\n",
      "step 86300 , validation  accuracy 0.766667\n",
      "step 86300 , validation loss : 0.646798\n",
      "step 86300 , validation  accuracy 0.833333\n",
      "step 86300 , validation loss : 0.495249\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692302942276\n",
      "(11, 30, 300, 300, 3)\n",
      "0.695754051208\n",
      "step 86400 , validation  accuracy 0.751515\n",
      "step 86400 , validation loss : 0.627734\n",
      "step 86400 , validation  accuracy 0.839394\n",
      "step 86400 , validation loss : 0.438334\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684094905853\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693547010422\n",
      "step 86500 , validation  accuracy 0.751515\n",
      "step 86500 , validation loss : 0.594305\n",
      "step 86500 , validation  accuracy 0.863636\n",
      "step 86500 , validation loss : 0.394981\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690144062042\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696228981018\n",
      "step 86600 , validation  accuracy 0.733333\n",
      "step 86600 , validation loss : 0.854554\n",
      "step 86600 , validation  accuracy 0.869697\n",
      "step 86600 , validation loss : 0.475944\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679208040237\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683382987976\n",
      "step 86700 , validation  accuracy 0.724243\n",
      "step 86700 , validation loss : 0.76454\n",
      "step 86700 , validation  accuracy 0.866667\n",
      "step 86700 , validation loss : 0.343344\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.735811948776\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697283983231\n",
      "step 86800 , validation  accuracy 0.772727\n",
      "step 86800 , validation loss : 0.686447\n",
      "step 86800 , validation  accuracy 0.824242\n",
      "step 86800 , validation loss : 0.535546\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684033155441\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687123775482\n",
      "step 86900 , validation  accuracy 0.742424\n",
      "step 86900 , validation loss : 0.719773\n",
      "step 86900 , validation  accuracy 0.860606\n",
      "step 86900 , validation loss : 0.46014\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68831205368\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698679924011\n",
      "step 87000 , validation  accuracy 0.70303\n",
      "step 87000 , validation loss : 0.859517\n",
      "step 87000 , validation  accuracy 0.866667\n",
      "step 87000 , validation loss : 0.453414\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682041883469\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696952104568\n",
      "step 87100 , validation  accuracy 0.760606\n",
      "step 87100 , validation loss : 0.64176\n",
      "step 87100 , validation  accuracy 0.833333\n",
      "step 87100 , validation loss : 0.455383\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688330888748\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686727046967\n",
      "step 87200 , validation  accuracy 0.763636\n",
      "step 87200 , validation loss : 0.697639\n",
      "step 87200 , validation  accuracy 0.830303\n",
      "step 87200 , validation loss : 0.553953\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.724875926971\n",
      "(11, 30, 300, 300, 3)\n",
      "0.694956064224\n",
      "step 87300 , validation  accuracy 0.739394\n",
      "step 87300 , validation loss : 0.695431\n",
      "step 87300 , validation  accuracy 0.848485\n",
      "step 87300 , validation loss : 0.375453\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680913925171\n",
      "(11, 30, 300, 300, 3)\n",
      "0.719437122345\n",
      "step 87400 , validation  accuracy 0.745455\n",
      "step 87400 , validation loss : 0.848375\n",
      "step 87400 , validation  accuracy 0.848485\n",
      "step 87400 , validation loss : 0.458372\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687963962555\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683489084244\n",
      "step 87500 , validation  accuracy 0.754546\n",
      "step 87500 , validation loss : 0.686307\n",
      "step 87500 , validation  accuracy 0.821212\n",
      "step 87500 , validation loss : 0.475443\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693451881409\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673018932343\n",
      "step 87600 , validation  accuracy 0.684849\n",
      "step 87600 , validation loss : 0.867676\n",
      "step 87600 , validation  accuracy 0.893939\n",
      "step 87600 , validation loss : 0.362948\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.70512509346\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696089029312\n",
      "step 87700 , validation  accuracy 0.706061\n",
      "step 87700 , validation loss : 0.881372\n",
      "step 87700 , validation  accuracy 0.890909\n",
      "step 87700 , validation loss : 0.340757\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683068990707\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675218105316\n",
      "step 87800 , validation  accuracy 0.739394\n",
      "step 87800 , validation loss : 0.624878\n",
      "step 87800 , validation  accuracy 0.875758\n",
      "step 87800 , validation loss : 0.394342\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695249080658\n",
      "(11, 30, 300, 300, 3)\n",
      "0.700217962265\n",
      "step 87900 , validation  accuracy 0.754546\n",
      "step 87900 , validation loss : 0.639931\n",
      "step 87900 , validation  accuracy 0.851515\n",
      "step 87900 , validation loss : 0.446357\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677577018738\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68184709549\n",
      "step 88000 , validation  accuracy 0.760606\n",
      "step 88000 , validation loss : 0.746329\n",
      "step 88000 , validation  accuracy 0.845455\n",
      "step 88000 , validation loss : 0.459823\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686031103134\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69811797142\n",
      "step 88100 , validation  accuracy 0.733333\n",
      "step 88100 , validation loss : 0.709289\n",
      "step 88100 , validation  accuracy 0.881818\n",
      "step 88100 , validation loss : 0.38266\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700557947159\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685477018356\n",
      "step 88200 , validation  accuracy 0.769697\n",
      "step 88200 , validation loss : 0.726178\n",
      "step 88200 , validation  accuracy 0.836364\n",
      "step 88200 , validation loss : 0.572701\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683346033096\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681478023529\n",
      "step 88300 , validation  accuracy 0.827273\n",
      "step 88300 , validation loss : 0.504104\n",
      "step 88300 , validation  accuracy 0.772727\n",
      "step 88300 , validation loss : 0.747297\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687332868576\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676290988922\n",
      "step 88400 , validation  accuracy 0.775758\n",
      "step 88400 , validation loss : 0.696883\n",
      "step 88400 , validation  accuracy 0.857576\n",
      "step 88400 , validation loss : 0.549398\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689599990845\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690476894379\n",
      "step 88500 , validation  accuracy 0.727273\n",
      "step 88500 , validation loss : 0.764245\n",
      "step 88500 , validation  accuracy 0.860606\n",
      "step 88500 , validation loss : 0.423005\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691949129105\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696788072586\n",
      "step 88600 , validation  accuracy 0.763636\n",
      "step 88600 , validation loss : 0.80289\n",
      "step 88600 , validation  accuracy 0.857576\n",
      "step 88600 , validation loss : 0.503124\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.685225963593\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706364870071\n",
      "step 88700 , validation  accuracy 0.742424\n",
      "step 88700 , validation loss : 0.663562\n",
      "step 88700 , validation  accuracy 0.854545\n",
      "step 88700 , validation loss : 0.415907\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689018964767\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67737197876\n",
      "step 88800 , validation  accuracy 0.748485\n",
      "step 88800 , validation loss : 0.704648\n",
      "step 88800 , validation  accuracy 0.845455\n",
      "step 88800 , validation loss : 0.525164\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683342218399\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683928966522\n",
      "step 88900 , validation  accuracy 0.739394\n",
      "step 88900 , validation loss : 0.830524\n",
      "step 88900 , validation  accuracy 0.872727\n",
      "step 88900 , validation loss : 0.419697\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678811788559\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696430921555\n",
      "step 89000 , validation  accuracy 0.751515\n",
      "step 89000 , validation loss : 0.62164\n",
      "step 89000 , validation  accuracy 0.839394\n",
      "step 89000 , validation loss : 0.478179\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696808099747\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683706998825\n",
      "step 89100 , validation  accuracy 0.8\n",
      "step 89100 , validation loss : 0.511435\n",
      "step 89100 , validation  accuracy 0.827273\n",
      "step 89100 , validation loss : 0.529786\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683666944504\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681231975555\n",
      "step 89200 , validation  accuracy 0.79697\n",
      "step 89200 , validation loss : 0.580146\n",
      "step 89200 , validation  accuracy 0.824243\n",
      "step 89200 , validation loss : 0.561336\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688790082932\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675189971924\n",
      "step 89300 , validation  accuracy 0.763637\n",
      "step 89300 , validation loss : 0.720003\n",
      "step 89300 , validation  accuracy 0.851515\n",
      "step 89300 , validation loss : 0.477296\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68723988533\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685101985931\n",
      "step 89400 , validation  accuracy 0.775758\n",
      "step 89400 , validation loss : 0.819449\n",
      "step 89400 , validation  accuracy 0.836364\n",
      "step 89400 , validation loss : 0.559977\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691308021545\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686631202698\n",
      "step 89500 , validation  accuracy 0.772727\n",
      "step 89500 , validation loss : 0.677614\n",
      "step 89500 , validation  accuracy 0.836364\n",
      "step 89500 , validation loss : 0.520066\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680629014969\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683350086212\n",
      "step 89600 , validation  accuracy 0.769697\n",
      "step 89600 , validation loss : 0.78274\n",
      "step 89600 , validation  accuracy 0.845455\n",
      "step 89600 , validation loss : 0.466954\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69002199173\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687771081924\n",
      "step 89700 , validation  accuracy 0.787879\n",
      "step 89700 , validation loss : 0.571857\n",
      "step 89700 , validation  accuracy 0.842424\n",
      "step 89700 , validation loss : 0.461611\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681344032288\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697098016739\n",
      "step 89800 , validation  accuracy 0.730303\n",
      "step 89800 , validation loss : 0.767417\n",
      "step 89800 , validation  accuracy 0.875758\n",
      "step 89800 , validation loss : 0.388835\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677031040192\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680214881897\n",
      "step 89900 , validation  accuracy 0.709091\n",
      "step 89900 , validation loss : 0.742958\n",
      "step 89900 , validation  accuracy 0.878788\n",
      "step 89900 , validation loss : 0.344904\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697146177292\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689860105515\n",
      "step 90000 , validation  accuracy 0.809091\n",
      "step 90000 , validation loss : 0.561711\n",
      "step 90000 , validation  accuracy 0.806061\n",
      "step 90000 , validation loss : 0.583569\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68360710144\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680981874466\n",
      "step 90100 , validation  accuracy 0.733333\n",
      "step 90100 , validation loss : 0.806546\n",
      "step 90100 , validation  accuracy 0.857576\n",
      "step 90100 , validation loss : 0.471336\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.697558164597\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688579082489\n",
      "step 90200 , validation  accuracy 0.772727\n",
      "step 90200 , validation loss : 0.626179\n",
      "step 90200 , validation  accuracy 0.842424\n",
      "step 90200 , validation loss : 0.423258\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686282157898\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697006940842\n",
      "step 90300 , validation  accuracy 0.790909\n",
      "step 90300 , validation loss : 0.576248\n",
      "step 90300 , validation  accuracy 0.827273\n",
      "step 90300 , validation loss : 0.492682\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.710193157196\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690531015396\n",
      "step 90400 , validation  accuracy 0.781818\n",
      "step 90400 , validation loss : 0.571419\n",
      "step 90400 , validation  accuracy 0.842424\n",
      "step 90400 , validation loss : 0.462412\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683291912079\n",
      "(11, 30, 300, 300, 3)\n",
      "0.683129072189\n",
      "step 90500 , validation  accuracy 0.754546\n",
      "step 90500 , validation loss : 0.647512\n",
      "step 90500 , validation  accuracy 0.818182\n",
      "step 90500 , validation loss : 0.525883\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686516046524\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684218883514\n",
      "step 90600 , validation  accuracy 0.775758\n",
      "step 90600 , validation loss : 0.771758\n",
      "step 90600 , validation  accuracy 0.845455\n",
      "step 90600 , validation loss : 0.518995\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.669886112213\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674587011337\n",
      "step 90700 , validation  accuracy 0.818182\n",
      "step 90700 , validation loss : 0.558416\n",
      "step 90700 , validation  accuracy 0.821212\n",
      "step 90700 , validation loss : 0.554156\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698235988617\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69155216217\n",
      "step 90800 , validation  accuracy 0.769697\n",
      "step 90800 , validation loss : 0.623718\n",
      "step 90800 , validation  accuracy 0.857576\n",
      "step 90800 , validation loss : 0.428912\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676375150681\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677639007568\n",
      "step 90900 , validation  accuracy 0.79697\n",
      "step 90900 , validation loss : 0.511071\n",
      "step 90900 , validation  accuracy 0.815152\n",
      "step 90900 , validation loss : 0.51739\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681548118591\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684350013733\n",
      "step 91000 , validation  accuracy 0.781818\n",
      "step 91000 , validation loss : 0.732484\n",
      "step 91000 , validation  accuracy 0.845455\n",
      "step 91000 , validation loss : 0.451154\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694045066833\n",
      "(11, 30, 300, 300, 3)\n",
      "0.713148832321\n",
      "step 91100 , validation  accuracy 0.754546\n",
      "step 91100 , validation loss : 0.766539\n",
      "step 91100 , validation  accuracy 0.830303\n",
      "step 91100 , validation loss : 0.482338\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.675415992737\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682166099548\n",
      "step 91200 , validation  accuracy 0.781818\n",
      "step 91200 , validation loss : 0.707857\n",
      "step 91200 , validation  accuracy 0.842424\n",
      "step 91200 , validation loss : 0.503619\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692096948624\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688633918762\n",
      "step 91300 , validation  accuracy 0.781818\n",
      "step 91300 , validation loss : 0.700586\n",
      "step 91300 , validation  accuracy 0.848485\n",
      "step 91300 , validation loss : 0.497013\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673539876938\n",
      "(11, 30, 300, 300, 3)\n",
      "0.713961839676\n",
      "step 91400 , validation  accuracy 0.80303\n",
      "step 91400 , validation loss : 0.613957\n",
      "step 91400 , validation  accuracy 0.787879\n",
      "step 91400 , validation loss : 0.628588\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681778907776\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688494205475\n",
      "step 91500 , validation  accuracy 0.8\n",
      "step 91500 , validation loss : 0.700098\n",
      "step 91500 , validation  accuracy 0.833333\n",
      "step 91500 , validation loss : 0.516529\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.676838159561\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689975976944\n",
      "step 91600 , validation  accuracy 0.754546\n",
      "step 91600 , validation loss : 0.655357\n",
      "step 91600 , validation  accuracy 0.830303\n",
      "step 91600 , validation loss : 0.412156\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693434000015\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68486905098\n",
      "step 91700 , validation  accuracy 0.763636\n",
      "step 91700 , validation loss : 0.548558\n",
      "step 91700 , validation  accuracy 0.845455\n",
      "step 91700 , validation loss : 0.421482\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.673043012619\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693327903748\n",
      "step 91800 , validation  accuracy 0.769697\n",
      "step 91800 , validation loss : 0.708554\n",
      "step 91800 , validation  accuracy 0.830303\n",
      "step 91800 , validation loss : 0.55321\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687211990356\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675252914429\n",
      "step 91900 , validation  accuracy 0.787879\n",
      "step 91900 , validation loss : 0.575307\n",
      "step 91900 , validation  accuracy 0.839394\n",
      "step 91900 , validation loss : 0.507825\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680114030838\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687151908875\n",
      "step 92000 , validation  accuracy 0.784849\n",
      "step 92000 , validation loss : 0.610003\n",
      "step 92000 , validation  accuracy 0.833333\n",
      "step 92000 , validation loss : 0.545724\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.708786010742\n",
      "(11, 30, 300, 300, 3)\n",
      "0.701455116272\n",
      "step 92100 , validation  accuracy 0.784849\n",
      "step 92100 , validation loss : 0.714153\n",
      "step 92100 , validation  accuracy 0.818182\n",
      "step 92100 , validation loss : 0.591022\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.689054965973\n",
      "(11, 30, 300, 300, 3)\n",
      "0.717946052551\n",
      "step 92200 , validation  accuracy 0.769697\n",
      "step 92200 , validation loss : 0.656073\n",
      "step 92200 , validation  accuracy 0.851515\n",
      "step 92200 , validation loss : 0.423979\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683101177216\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681715011597\n",
      "step 92300 , validation  accuracy 0.781818\n",
      "step 92300 , validation loss : 0.613523\n",
      "step 92300 , validation  accuracy 0.851515\n",
      "step 92300 , validation loss : 0.429267\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68928694725\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681934118271\n",
      "step 92400 , validation  accuracy 0.772727\n",
      "step 92400 , validation loss : 0.611215\n",
      "step 92400 , validation  accuracy 0.857576\n",
      "step 92400 , validation loss : 0.431409\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.706224918365\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679243087769\n",
      "step 92500 , validation  accuracy 0.815152\n",
      "step 92500 , validation loss : 0.469039\n",
      "step 92500 , validation  accuracy 0.80303\n",
      "step 92500 , validation loss : 0.544523\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692759037018\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687766075134\n",
      "step 92600 , validation  accuracy 0.809091\n",
      "step 92600 , validation loss : 0.620764\n",
      "step 92600 , validation  accuracy 0.827273\n",
      "step 92600 , validation loss : 0.517208\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680269956589\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680744886398\n",
      "step 92700 , validation  accuracy 0.760606\n",
      "step 92700 , validation loss : 0.737999\n",
      "step 92700 , validation  accuracy 0.839394\n",
      "step 92700 , validation loss : 0.466677\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683780908585\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67480301857\n",
      "step 92800 , validation  accuracy 0.790909\n",
      "step 92800 , validation loss : 0.7764\n",
      "step 92800 , validation  accuracy 0.845455\n",
      "step 92800 , validation loss : 0.533347\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680025100708\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681679964066\n",
      "step 92900 , validation  accuracy 0.80303\n",
      "step 92900 , validation loss : 0.537827\n",
      "step 92900 , validation  accuracy 0.827273\n",
      "step 92900 , validation loss : 0.499016\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679145097733\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685799837112\n",
      "step 93000 , validation  accuracy 0.806061\n",
      "step 93000 , validation loss : 0.533828\n",
      "step 93000 , validation  accuracy 0.830303\n",
      "step 93000 , validation loss : 0.453886\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.700685977936\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688801050186\n",
      "step 93100 , validation  accuracy 0.778788\n",
      "step 93100 , validation loss : 0.659522\n",
      "step 93100 , validation  accuracy 0.845455\n",
      "step 93100 , validation loss : 0.479779\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677742958069\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680581092834\n",
      "step 93200 , validation  accuracy 0.781818\n",
      "step 93200 , validation loss : 0.724064\n",
      "step 93200 , validation  accuracy 0.842424\n",
      "step 93200 , validation loss : 0.526345\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684540987015\n",
      "(11, 30, 300, 300, 3)\n",
      "0.67870092392\n",
      "step 93300 , validation  accuracy 0.754545\n",
      "step 93300 , validation loss : 0.71586\n",
      "step 93300 , validation  accuracy 0.851515\n",
      "step 93300 , validation loss : 0.456462\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681474924088\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688587188721\n",
      "step 93400 , validation  accuracy 0.8\n",
      "step 93400 , validation loss : 0.599943\n",
      "step 93400 , validation  accuracy 0.815152\n",
      "step 93400 , validation loss : 0.530139\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698705911636\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692004919052\n",
      "step 93500 , validation  accuracy 0.793939\n",
      "step 93500 , validation loss : 0.556466\n",
      "step 93500 , validation  accuracy 0.839394\n",
      "step 93500 , validation loss : 0.487785\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690997838974\n",
      "(11, 30, 300, 300, 3)\n",
      "0.704326868057\n",
      "step 93600 , validation  accuracy 0.778788\n",
      "step 93600 , validation loss : 0.711504\n",
      "step 93600 , validation  accuracy 0.839394\n",
      "step 93600 , validation loss : 0.551396\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698042869568\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681446075439\n",
      "step 93700 , validation  accuracy 0.733333\n",
      "step 93700 , validation loss : 0.836637\n",
      "step 93700 , validation  accuracy 0.875758\n",
      "step 93700 , validation loss : 0.371288\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.674700021744\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69384598732\n",
      "step 93800 , validation  accuracy 0.754546\n",
      "step 93800 , validation loss : 0.639839\n",
      "step 93800 , validation  accuracy 0.827273\n",
      "step 93800 , validation loss : 0.526404\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696370840073\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690874099731\n",
      "step 93900 , validation  accuracy 0.690909\n",
      "step 93900 , validation loss : 0.912203\n",
      "step 93900 , validation  accuracy 0.884849\n",
      "step 93900 , validation loss : 0.318381\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679398059845\n",
      "(11, 30, 300, 300, 3)\n",
      "0.676275968552\n",
      "step 94000 , validation  accuracy 0.766667\n",
      "step 94000 , validation loss : 0.609317\n",
      "step 94000 , validation  accuracy 0.836364\n",
      "step 94000 , validation loss : 0.481864\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682720899582\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684599876404\n",
      "step 94100 , validation  accuracy 0.787879\n",
      "step 94100 , validation loss : 0.678789\n",
      "step 94100 , validation  accuracy 0.845455\n",
      "step 94100 , validation loss : 0.46613\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695487976074\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682428836823\n",
      "step 94200 , validation  accuracy 0.790909\n",
      "step 94200 , validation loss : 0.73847\n",
      "step 94200 , validation  accuracy 0.848485\n",
      "step 94200 , validation loss : 0.567315\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678194999695\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685431003571\n",
      "step 94300 , validation  accuracy 0.772727\n",
      "step 94300 , validation loss : 0.669082\n",
      "step 94300 , validation  accuracy 0.839394\n",
      "step 94300 , validation loss : 0.441196\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687424182892\n",
      "(11, 30, 300, 300, 3)\n",
      "0.685994148254\n",
      "step 94400 , validation  accuracy 0.748485\n",
      "step 94400 , validation loss : 0.853057\n",
      "step 94400 , validation  accuracy 0.854546\n",
      "step 94400 , validation loss : 0.396439\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.669349193573\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690227985382\n",
      "step 94500 , validation  accuracy 0.778788\n",
      "step 94500 , validation loss : 0.621339\n",
      "step 94500 , validation  accuracy 0.830303\n",
      "step 94500 , validation loss : 0.492692\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695549964905\n",
      "(11, 30, 300, 300, 3)\n",
      "0.711045026779\n",
      "step 94600 , validation  accuracy 0.745455\n",
      "step 94600 , validation loss : 0.742564\n",
      "step 94600 , validation  accuracy 0.881818\n",
      "step 94600 , validation loss : 0.346731\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678822994232\n",
      "(11, 30, 300, 300, 3)\n",
      "0.681859970093\n",
      "step 94700 , validation  accuracy 0.778788\n",
      "step 94700 , validation loss : 0.595831\n",
      "step 94700 , validation  accuracy 0.854546\n",
      "step 94700 , validation loss : 0.464164\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696659088135\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673914909363\n",
      "step 94800 , validation  accuracy 0.784849\n",
      "step 94800 , validation loss : 0.573309\n",
      "step 94800 , validation  accuracy 0.836364\n",
      "step 94800 , validation loss : 0.438415\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.669754981995\n",
      "(11, 30, 300, 300, 3)\n",
      "0.682713985443\n",
      "step 94900 , validation  accuracy 0.79697\n",
      "step 94900 , validation loss : 0.655942\n",
      "step 94900 , validation  accuracy 0.827273\n",
      "step 94900 , validation loss : 0.583882\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678241968155\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68648982048\n",
      "step 95000 , validation  accuracy 0.769697\n",
      "step 95000 , validation loss : 0.690955\n",
      "step 95000 , validation  accuracy 0.833333\n",
      "step 95000 , validation loss : 0.520793\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682229042053\n",
      "(11, 30, 300, 300, 3)\n",
      "0.6733751297\n",
      "step 95100 , validation  accuracy 0.772727\n",
      "step 95100 , validation loss : 0.604335\n",
      "step 95100 , validation  accuracy 0.824242\n",
      "step 95100 , validation loss : 0.490682\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68238902092\n",
      "(11, 30, 300, 300, 3)\n",
      "0.678357124329\n",
      "step 95200 , validation  accuracy 0.806061\n",
      "step 95200 , validation loss : 0.630211\n",
      "step 95200 , validation  accuracy 0.8\n",
      "step 95200 , validation loss : 0.675458\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687850952148\n",
      "(11, 30, 300, 300, 3)\n",
      "0.71728181839\n",
      "step 95300 , validation  accuracy 0.730303\n",
      "step 95300 , validation loss : 0.683817\n",
      "step 95300 , validation  accuracy 0.848485\n",
      "step 95300 , validation loss : 0.428323\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683614969254\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684710025787\n",
      "step 95400 , validation  accuracy 0.787879\n",
      "step 95400 , validation loss : 0.585972\n",
      "step 95400 , validation  accuracy 0.812121\n",
      "step 95400 , validation loss : 0.556398\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68751502037\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680135011673\n",
      "step 95500 , validation  accuracy 0.772727\n",
      "step 95500 , validation loss : 0.673006\n",
      "step 95500 , validation  accuracy 0.851515\n",
      "step 95500 , validation loss : 0.477252\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678943157196\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693840026855\n",
      "step 95600 , validation  accuracy 0.787879\n",
      "step 95600 , validation loss : 0.592587\n",
      "step 95600 , validation  accuracy 0.80303\n",
      "step 95600 , validation loss : 0.600793\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.701311826706\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693343877792\n",
      "step 95700 , validation  accuracy 0.748485\n",
      "step 95700 , validation loss : 0.729537\n",
      "step 95700 , validation  accuracy 0.836364\n",
      "step 95700 , validation loss : 0.526734\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.67955994606\n",
      "(11, 30, 300, 300, 3)\n",
      "0.723442077637\n",
      "step 95800 , validation  accuracy 0.706061\n",
      "step 95800 , validation loss : 0.847359\n",
      "step 95800 , validation  accuracy 0.872727\n",
      "step 95800 , validation loss : 0.37946\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68957400322\n",
      "(11, 30, 300, 300, 3)\n",
      "0.690186977386\n",
      "step 95900 , validation  accuracy 0.751515\n",
      "step 95900 , validation loss : 0.810743\n",
      "step 95900 , validation  accuracy 0.842424\n",
      "step 95900 , validation loss : 0.513485\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68981385231\n",
      "(11, 30, 300, 300, 3)\n",
      "0.702023029327\n",
      "step 96000 , validation  accuracy 0.79697\n",
      "step 96000 , validation loss : 0.600493\n",
      "step 96000 , validation  accuracy 0.824242\n",
      "step 96000 , validation loss : 0.615184\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.691176891327\n",
      "(11, 30, 300, 300, 3)\n",
      "0.698040008545\n",
      "step 96100 , validation  accuracy 0.742424\n",
      "step 96100 , validation loss : 0.652494\n",
      "step 96100 , validation  accuracy 0.860606\n",
      "step 96100 , validation loss : 0.365921\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.686207056046\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697327852249\n",
      "step 96200 , validation  accuracy 0.69697\n",
      "step 96200 , validation loss : 0.831968\n",
      "step 96200 , validation  accuracy 0.872727\n",
      "step 96200 , validation loss : 0.352901\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68207192421\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687906980515\n",
      "step 96300 , validation  accuracy 0.742424\n",
      "step 96300 , validation loss : 0.724113\n",
      "step 96300 , validation  accuracy 0.860606\n",
      "step 96300 , validation loss : 0.451562\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.698410987854\n",
      "(11, 30, 300, 300, 3)\n",
      "0.692935943604\n",
      "step 96400 , validation  accuracy 0.769697\n",
      "step 96400 , validation loss : 0.79346\n",
      "step 96400 , validation  accuracy 0.851515\n",
      "step 96400 , validation loss : 0.50075\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684455871582\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68088388443\n",
      "step 96500 , validation  accuracy 0.754546\n",
      "step 96500 , validation loss : 0.688097\n",
      "step 96500 , validation  accuracy 0.860606\n",
      "step 96500 , validation loss : 0.368729\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690041065216\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68829202652\n",
      "step 96600 , validation  accuracy 0.724242\n",
      "step 96600 , validation loss : 0.765399\n",
      "step 96600 , validation  accuracy 0.851515\n",
      "step 96600 , validation loss : 0.410381\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69181895256\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680949926376\n",
      "step 96700 , validation  accuracy 0.772727\n",
      "step 96700 , validation loss : 0.634891\n",
      "step 96700 , validation  accuracy 0.824242\n",
      "step 96700 , validation loss : 0.487054\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692482948303\n",
      "(11, 30, 300, 300, 3)\n",
      "0.687633037567\n",
      "step 96800 , validation  accuracy 0.751515\n",
      "step 96800 , validation loss : 0.641093\n",
      "step 96800 , validation  accuracy 0.854546\n",
      "step 96800 , validation loss : 0.480595\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677643060684\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686676025391\n",
      "step 96900 , validation  accuracy 0.79394\n",
      "step 96900 , validation loss : 0.557571\n",
      "step 96900 , validation  accuracy 0.806061\n",
      "step 96900 , validation loss : 0.55033\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.680638074875\n",
      "(11, 30, 300, 300, 3)\n",
      "0.66933298111\n",
      "step 97000 , validation  accuracy 0.784849\n",
      "step 97000 , validation loss : 0.560426\n",
      "step 97000 , validation  accuracy 0.833333\n",
      "step 97000 , validation loss : 0.502119\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.688090085983\n",
      "(11, 30, 300, 300, 3)\n",
      "0.679064035416\n",
      "step 97100 , validation  accuracy 0.730303\n",
      "step 97100 , validation loss : 0.805451\n",
      "step 97100 , validation  accuracy 0.854546\n",
      "step 97100 , validation loss : 0.413421\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678923845291\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68457698822\n",
      "step 97200 , validation  accuracy 0.751515\n",
      "step 97200 , validation loss : 0.668596\n",
      "step 97200 , validation  accuracy 0.827273\n",
      "step 97200 , validation loss : 0.580882\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69673204422\n",
      "(11, 30, 300, 300, 3)\n",
      "0.699828863144\n",
      "step 97300 , validation  accuracy 0.812121\n",
      "step 97300 , validation loss : 0.588877\n",
      "step 97300 , validation  accuracy 0.833333\n",
      "step 97300 , validation loss : 0.521018\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.670797109604\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686625957489\n",
      "step 97400 , validation  accuracy 0.754545\n",
      "step 97400 , validation loss : 0.786084\n",
      "step 97400 , validation  accuracy 0.866667\n",
      "step 97400 , validation loss : 0.44577\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.684866905212\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693650960922\n",
      "step 97500 , validation  accuracy 0.748485\n",
      "step 97500 , validation loss : 0.824408\n",
      "step 97500 , validation  accuracy 0.851515\n",
      "step 97500 , validation loss : 0.472317\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679623126984\n",
      "(11, 30, 300, 300, 3)\n",
      "0.696181058884\n",
      "step 97600 , validation  accuracy 0.766667\n",
      "step 97600 , validation loss : 0.660823\n",
      "step 97600 , validation  accuracy 0.866667\n",
      "step 97600 , validation loss : 0.437547\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678817033768\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677926063538\n",
      "step 97700 , validation  accuracy 0.781818\n",
      "step 97700 , validation loss : 0.695415\n",
      "step 97700 , validation  accuracy 0.830303\n",
      "step 97700 , validation loss : 0.646434\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.678988933563\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686887979507\n",
      "step 97800 , validation  accuracy 0.733333\n",
      "step 97800 , validation loss : 0.686789\n",
      "step 97800 , validation  accuracy 0.878788\n",
      "step 97800 , validation loss : 0.37673\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687316894531\n",
      "(11, 30, 300, 300, 3)\n",
      "0.691740989685\n",
      "step 97900 , validation  accuracy 0.772727\n",
      "step 97900 , validation loss : 0.665\n",
      "step 97900 , validation  accuracy 0.848485\n",
      "step 97900 , validation loss : 0.444029\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696615934372\n",
      "(11, 30, 300, 300, 3)\n",
      "0.704454898834\n",
      "step 98000 , validation  accuracy 0.775758\n",
      "step 98000 , validation loss : 0.707785\n",
      "step 98000 , validation  accuracy 0.836364\n",
      "step 98000 , validation loss : 0.533234\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.681089162827\n",
      "(11, 30, 300, 300, 3)\n",
      "0.684942960739\n",
      "step 98100 , validation  accuracy 0.745455\n",
      "step 98100 , validation loss : 0.845538\n",
      "step 98100 , validation  accuracy 0.845455\n",
      "step 98100 , validation loss : 0.44905\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.683910131454\n",
      "(11, 30, 300, 300, 3)\n",
      "0.674735069275\n",
      "step 98200 , validation  accuracy 0.718182\n",
      "step 98200 , validation loss : 0.852552\n",
      "step 98200 , validation  accuracy 0.881818\n",
      "step 98200 , validation loss : 0.3481\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.694443941116\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686386108398\n",
      "step 98300 , validation  accuracy 0.766667\n",
      "step 98300 , validation loss : 0.795744\n",
      "step 98300 , validation  accuracy 0.839394\n",
      "step 98300 , validation loss : 0.54283\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.696544885635\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688749790192\n",
      "step 98400 , validation  accuracy 0.760606\n",
      "step 98400 , validation loss : 0.773998\n",
      "step 98400 , validation  accuracy 0.845455\n",
      "step 98400 , validation loss : 0.595266\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.6761469841\n",
      "(11, 30, 300, 300, 3)\n",
      "0.673995018005\n",
      "step 98500 , validation  accuracy 0.787879\n",
      "step 98500 , validation loss : 0.631653\n",
      "step 98500 , validation  accuracy 0.833333\n",
      "step 98500 , validation loss : 0.614738\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692755937576\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688784122467\n",
      "step 98600 , validation  accuracy 0.754545\n",
      "step 98600 , validation loss : 0.573448\n",
      "step 98600 , validation  accuracy 0.860606\n",
      "step 98600 , validation loss : 0.412058\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.68536400795\n",
      "(11, 30, 300, 300, 3)\n",
      "0.680954933167\n",
      "step 98700 , validation  accuracy 0.784849\n",
      "step 98700 , validation loss : 0.57985\n",
      "step 98700 , validation  accuracy 0.824243\n",
      "step 98700 , validation loss : 0.517059\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.693116903305\n",
      "(11, 30, 300, 300, 3)\n",
      "0.697216033936\n",
      "step 98800 , validation  accuracy 0.778788\n",
      "step 98800 , validation loss : 0.657178\n",
      "step 98800 , validation  accuracy 0.821212\n",
      "step 98800 , validation loss : 0.529274\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.677808046341\n",
      "(11, 30, 300, 300, 3)\n",
      "0.675316095352\n",
      "step 98900 , validation  accuracy 0.775758\n",
      "step 98900 , validation loss : 0.739375\n",
      "step 98900 , validation  accuracy 0.824243\n",
      "step 98900 , validation loss : 0.599877\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.668772935867\n",
      "(11, 30, 300, 300, 3)\n",
      "0.677587985992\n",
      "step 99000 , validation  accuracy 0.736364\n",
      "step 99000 , validation loss : 0.748726\n",
      "step 99000 , validation  accuracy 0.878788\n",
      "step 99000 , validation loss : 0.374091\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.690793037415\n",
      "(11, 30, 300, 300, 3)\n",
      "0.688629865646\n",
      "step 99100 , validation  accuracy 0.739394\n",
      "step 99100 , validation loss : 0.917498\n",
      "step 99100 , validation  accuracy 0.851515\n",
      "step 99100 , validation loss : 0.463325\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.679836988449\n",
      "(11, 30, 300, 300, 3)\n",
      "0.69494509697\n",
      "step 99200 , validation  accuracy 0.769697\n",
      "step 99200 , validation loss : 0.75831\n",
      "step 99200 , validation  accuracy 0.857576\n",
      "step 99200 , validation loss : 0.435907\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.692093849182\n",
      "(11, 30, 300, 300, 3)\n",
      "0.686542034149\n",
      "step 99300 , validation  accuracy 0.766667\n",
      "step 99300 , validation loss : 0.735042\n",
      "step 99300 , validation  accuracy 0.851515\n",
      "step 99300 , validation loss : 0.517762\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.671436071396\n",
      "(11, 30, 300, 300, 3)\n",
      "0.707976102829\n",
      "step 99400 , validation  accuracy 0.766667\n",
      "step 99400 , validation loss : 0.698228\n",
      "step 99400 , validation  accuracy 0.824243\n",
      "step 99400 , validation loss : 0.520083\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.687432050705\n",
      "(11, 30, 300, 300, 3)\n",
      "0.706268072128\n",
      "step 99500 , validation  accuracy 0.787879\n",
      "step 99500 , validation loss : 0.609031\n",
      "step 99500 , validation  accuracy 0.833333\n",
      "step 99500 , validation loss : 0.512489\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.69336605072\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68333697319\n",
      "step 99600 , validation  accuracy 0.79697\n",
      "step 99600 , validation loss : 0.62008\n",
      "step 99600 , validation  accuracy 0.827273\n",
      "step 99600 , validation loss : 0.59457\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.695681810379\n",
      "(11, 30, 300, 300, 3)\n",
      "0.689647912979\n",
      "step 99700 , validation  accuracy 0.763637\n",
      "step 99700 , validation loss : 0.71535\n",
      "step 99700 , validation  accuracy 0.848485\n",
      "step 99700 , validation loss : 0.478568\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.682649850845\n",
      "(11, 30, 300, 300, 3)\n",
      "0.68343091011\n",
      "step 99800 , validation  accuracy 0.772727\n",
      "step 99800 , validation loss : 0.695607\n",
      "step 99800 , validation  accuracy 0.854546\n",
      "step 99800 , validation loss : 0.560462\n",
      "-Progress : 99/100(11, 30, 300, 300, 3)\n",
      "0.711053133011\n",
      "(11, 30, 300, 300, 3)\n",
      "0.693545103073\n",
      "step 99900 , validation  accuracy 0.769697\n",
      "step 99900 , validation loss : 0.65968\n",
      "step 99900 , validation  accuracy 0.863636\n",
      "step 99900 , validation loss : 0.457337\n",
      "-Progress : 99/100"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/ssd/n_vs_ab/type1/1/test_img.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-eb4b5b93a951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#tensorboard_info=OPEN_TENSORBOARD(sess ,tensor_info ,logdir) for tensorboard slow down ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#fp,dirname=make_logdir(dirname)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mBATCH_TRAINING_RANDOM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mtensor_info\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mplace_info\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msave_folder\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrestore_path\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-61-0d34d7045b07>\u001b[0m in \u001b[0;36mBATCH_TRAINING_RANDOM\u001b[0;34m(maxiter, tensor_info, place_info, save_folder, restore_path, tensorboard_info, val_img_lab, test_img_lab)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mbatch_xs\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mret_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormal_1_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mTRAINING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_xs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplace_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTESTING\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkbie\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-7b729813ef20>\u001b[0m in \u001b[0;36mload_test\u001b[0;34m(test_imgs, test_labs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtest_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_locate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'test_img.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mtest_lab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_locate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'test_lab.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mval_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_img\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mval_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/ssd/n_vs_ab/type1/1/test_img.npy'"
     ]
    }
   ],
   "source": [
    "#tensorboard_info=OPEN_TENSORBOARD(sess ,tensor_info ,logdir) for tensorboard slow down ?\n",
    "#fp,dirname=make_logdir(dirname)\n",
    "BATCH_TRAINING_RANDOM(100000 ,tensor_info , place_info ,save_folder , restore_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
